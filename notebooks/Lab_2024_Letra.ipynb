{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141_gIDbKDD2"
      },
      "source": [
        "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural (2024)\n",
        "\n",
        "**Grupo**: PG01\n",
        "\n",
        "**Integrantes**: Emiliano Viotti\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "En este laboratorio vamos a poner en práctica algunos de los conceptos vistos en el curso, como la *mínima distancia de edición* para medir la cercanía entre dos tiras, los *embeddings* como representación semántica de los textos, los *modelos de n-gramas* para generar texto y un problema de clasificación de tres clases.\n",
        "\n",
        "Los ejercicios que tienen que resolver están señalizados por números del 0️⃣al 7️⃣. Los resultados y conclusiones que surjan de esos ejercicios los van a comunicar en un informe (con un **máximo de 6 páginas**). En la sección \"¿Qué se espera del informe?\" de la letra del laboratorio van a encontrar una guía para escribirlo.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL5ExO6_R3p3"
      },
      "source": [
        "Antes que nada, vamos a instalar e importar NLTK y descargar [\"Cuentos de Amor de Locura y de Muerte\"](https://es.wikipedia.org/wiki/Cuentos_de_amor_de_locura_y_de_muerte) de Horacio Quiroga del [repositorio Gutemberg](https://www.gutenberg.org/ebooks/13507). Esto ya está implementado, y el libro va a quedar guardado en la variable `quiroga_raw`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KGxxKdjB2-kq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "\n",
        "!wget https://www.gutenberg.org/cache/epub/13507/pg13507.txt\n",
        "with open(\"pg13507.txt\",\"r\") as f:\n",
        "    quiroga_raw = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8D1kdiz8Zj"
      },
      "source": [
        "## 0️⃣Limpieza básica del corpus\n",
        "\n",
        "Si examinamos el string cargado en `quiroga_raw`, vemos que al inicio y al final hay texto en inglés, además de que algunos saltos de línea ocurren a mitad de las oraciones.\n",
        "\n",
        "Como primer paso, diseñe expesiones regulares que limpien `quiroga_raw` para que:\n",
        "\n",
        "\n",
        "* quede solamente el texto que está entre \"#Cuentos de Amor de Locura y de Muerte#\" y \"FIN\\n\"\n",
        "* saquen aquellos saltos de línea que tengan a su derecha una palabra que comience con letra minúscula  \n",
        "\n",
        "El texto limpio resultante deberá quedar guardado en la variable `quiroga`. Más adelante van a poder probar con otros preprocesamientos complementarios a esta limpieza básica.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "xkn6j08tV9Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c933449-6613-460f-a2fc-e575c1a4167e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 312980 caracteres. \n",
            "Texto extraído: 293434 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de línea en sentencias...\n",
            "Texto original: 293434 caracteres. \n",
            "Texto extraído: 293434 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            "HORACIO QUIROGA\n",
            "\n",
            "1917\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#INDICE#\n",
            "\n",
            "\n",
            "Una estación de amor\n",
            "Los ojos sombríos\n",
            "El solitario\n",
            "La muerte de Isolda\n",
            "El infierno artificial\n",
            "La gallina degollada\n",
            "Los buques suicidantes\n",
            "El almohadón de pluma\n",
            "El perro rabioso\n",
            "A la deriva\n",
            "La insolación\n",
            "El alambre de púa\n",
            "Los Mensú\n",
            "Yaguaí\n",
            "Los pescadores de vigas\n",
            "La miel silvestre\n",
            "Nuestro primer cigarro\n",
            "La meningitis y su sombra\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#UNA ESTACION DE AMOR#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#Primavera#\n",
            "\n",
            "\n",
            "Era el martes de carnaval. Nébel acababa de entrar en el corso, ya al oscurecer, y mientras deshacía un paquete de serpentinas, miró al carruaje de delante. Extrañado de una cara que no había visto la tarde anterior, preguntó a sus compañeros:\n",
            "\n",
            "\n",
            "--¿Quién es? No parece fea.\n",
            "\n",
            "--¡Un demonio! Es lindísima. Creo que sobrina, o cosa así, del doctor\n",
            "Arrizabalaga. Llegó ayer, me parece...\n",
            "\n",
            "Nébel fijó entonces atentamente los ojos en la hermosa criatura. Era una chica muy joven aún, acaso no más de catorce años, pero completamente núbil. Tenía, bajo el cabello muy oscuro, un rostro de \n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignación para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "\n",
        "# 1. Extracción del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "quiroga_text_extract_pattern = r\"#Cuentos de Amor de Locura y de Muerte#(.*)FIN\\n\"  # Expresion regular\n",
        "match = re.search(quiroga_text_extract_pattern, quiroga_raw, re.DOTALL)\n",
        "if match:\n",
        "    quiroga_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(quiroga_raw)} caracteres. \\nTexto extraído: {len(quiroga_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de línea\n",
        "print(\"\\n\\nLimpiando saltos de línea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "quiroga = re.sub(breakline_lowercase_pattern, r\" \\1\", quiroga_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(quiroga_text)} caracteres. \\nTexto extraído: {len(quiroga)} caracteres.\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(quiroga[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2qociraM_qD"
      },
      "source": [
        "## Primera parte: Modelos de lenguaje de n-gramas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVvptUo5Sz2t"
      },
      "source": [
        "Ahora que tenemos el texto más limpio, vamos a entrenar modelos de lenguaje de n-gramas sobre él. Para eso, les vamos a dar definidas e implementadas las funciones:\n",
        "- `train_language_model`, que dado un natural `n` y un `corpus`, entrena un modelo de lenguaje basado en n-gramas. El parámetro `n` tiene el valor 4 por defecto.\n",
        "- `language_model_inference`, que dado un modelo de lenguaje ya entrenado y una `prompt`, da como salida tantos tokens sucesivos como indique la variable `length`. Este largo tiene por defecto el valor 25, y la semilla `seed` tiene por defecto el valor 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hGg_YS617cXP"
      },
      "outputs": [],
      "source": [
        "def train_language_model (corpus, n = 4):\n",
        "  padded_tokens = [list(nltk.lm.preprocessing.pad_both_ends(nltk.tokenize.word_tokenize(corpus, language='spanish'), n=n))]\n",
        "\n",
        "  train, vocab = nltk.lm.preprocessing.padded_everygram_pipeline(n, padded_tokens)\n",
        "\n",
        "  language_model = nltk.lm.MLE(n)\n",
        "  language_model.fit(train,vocab)\n",
        "\n",
        "  return language_model\n",
        "\n",
        "def language_model_inference (language_model, prompt, length = 25, seed = 2024):\n",
        "  tokens = language_model.generate(length, text_seed=nltk.tokenize.word_tokenize(prompt), random_seed=seed)\n",
        "  return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmhOy1TrYA6q"
      },
      "source": [
        "### 1️⃣Entrenamiento e inferencia\n",
        "\n",
        "Ahora que ya están definidas las funciones de entrenamiento e inferencia de los modelos de lenguaje, entrenen diferentes modelos variando:\n",
        "- el parámetro `n`, por ejemplo con `n=3`, `n=2` y el valor por defecto, `n=4`\n",
        "- el parámetro `corpus`, que se consigue al probar con diferentes pipelines de preprocesamieto. Pueden intentar pasar todo a minúsculas, sustituir los saltos de línea por espacios en blanco y todo lo que tengan ganas de probar. También pueden incluir el experimento de no preprocesar; es decir, que el pipeline de preprocesamiento sea la identidad.\n",
        "\n",
        "Luego, con cada uno de esos modelos, generen texto pasándole como `prompt`,  \"las vacas\", \"el cielo\", y una opción más que encuentren interesante. Aunque no es necesario, pueden probar otros valores de `length` y `seed`, más allá de los que están por defecto.\n",
        "\n",
        "💡 Les recomendamos que cada pipeline de preprocesamiento sea una función independiente. De esa manera, se facilita la reproducibilidad de los experimentos y su comparación, e.g. `n=3` preprocesando con `pipeline1()`, `n=3` con `pipeline2()`, `n=2` con `pipeline1()` y `n=2` con `pipeline2()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-procesamientos a probar\n",
        "\n",
        "Se propone experimentar con los siguientes pipelines de datos, que combinan diferentes pre procesamientos y parámetros en la etapa de vectorización del texto.\n",
        "\n",
        "| Nombre      | Parámetros                                      | Objetivo                                           |\n",
        "|-------------|-------------------------------------------------|----------------------------------------------------|\n",
        "| pipeline_1  | n=4                                             | Probar el efecto de n grande                       |\n",
        "| pipeline_2  | n=3                                             | Probar el efecto reducir n                         |\n",
        "| pipeline_3  | n=2                                             | Probar el efecto reducir n                         |\n",
        "| pipeline_4  | n=5                                             | Probar el efecto n más grande                      |\n",
        "| pipeline_5  | n=4, lowercase()                                | Para un n fijo, agregar convertir a minúsculas                     |\n",
        "| pipeline_6  | n=4, lowercase(), replace(“\\n”, “ ”)            | Para un n fijo, agregar eliminar todos los saltos                  |\n",
        "| pipeline_7  | n=4, lowercase(), replace(“\\n”, “ ”), replace(punc_symbols, “ “) | Para un n fijo, además eliminar símbolos de puntuación y caracteres especiales |\n"
      ],
      "metadata": {
        "id": "SsIiNkGz1Nlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_1q_yvT_IVyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69901ee7-8375-4b79-94af-c486f603e91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_1 -- Parámetros: n=4, pre-process=None\n",
            "pipeline_2 -- Parámetros: n=3, pre-process=None\n",
            "pipeline_3 -- Parámetros: n=2, pre-process=None\n",
            "pipeline_4 -- Parámetros: n=5, pre-process=None\n",
            "pipeline_5 -- Parámetros: n=4, pre-process=lowercase()\n",
            "pipeline_6 -- Parámetros: n=4, pre-process=[lowercase(), replace(\n",
            ", ' ')]\n",
            "pipeline_7 -- Parámetros: n=4, pre-process=[lowercase(), replace([\n",
            ", pubc_symbols], ' ')]\n",
            "\n",
            "Generando para text='las vacas'\n",
            "model='pipeline_1' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'está', 'conmigo', ',', 'entonces', 'no', 'aparta', 'los', 'ojos', 'de', 'mi', 'mujer', 'y', 'yo', ',', 'con']\n",
            "model='pipeline_2' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'en', 'el', 'patio', 'y', 'Alfonso', 'la', 'llamó', 'en', 'silencio', '.', 'Pasábanse', 'horas', 'sin', 'oir', 'el', 'angustioso']\n",
            "model='pipeline_3' output=['dormitaban', 'al', 'fin', 'se', 'había', 'reforzado', 'su', 'corazón', 'siempre', 'en', 'la', 'pipa', 'y', 'el', 'perro', 'había', 'retirado', '.', 'A', 'media', 'hora', 'en', 'tierra', ',', 'del']\n",
            "model='pipeline_4' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'los', 'pobres', 'caballos', 'pasaron', 'por', 'el', 'camino', ',', 'ellas', 'abrieron', 'los', 'ojos', 'despreciativas', ':', '--']\n",
            "model='pipeline_5' output=['estaban', 'inmóviles', ',', 'mirando', 'fijamente', 'el', 'verde', 'paraíso', 'inalcanzable', '.', '--', '¿por', 'qué', '?', '¿qué', 'le', 'pasa', '?', '--', 'nada', ',', 'sino', 'que', 'está', 'bien']\n",
            "model='pipeline_6' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'está', 'conmigo', ',', 'entonces', 'no', 'aparta', 'los', 'ojos', 'de', 'mi', 'mujer', 'y', 'yo', ',', 'con']\n",
            "model='pipeline_7' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', 'rumiando', 'Pero', 'cuando', 'los', 'pobres', 'caballos', 'pasaron', 'por', 'el', 'camino', 'ellas', 'abrieron', 'los', 'ojos', 'despreciativas', 'Son', 'los', 'caballos', 'Los', 'alambres']\n",
            "\n",
            "Generando para text='el cielo'\n",
            "model='pipeline_1' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provocáronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Había', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_2' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provocáronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'no', 'vaya', 'yo', 'jamás', 'a', 'explicarme', 'qué', 'combinaciones', 'de', 'visitas', ',', 'casamientos', 'y', 'garden']\n",
            "model='pipeline_3' output=['de', 'que', 'está', 'todo', 'el', 'piso', '.', 'Alrededor', 'del', 'menguante', '.', 'Pero', 'yo', 'con', 'sorpresa', '.', 'Pero', 'éste', ':', 'la', 'loma', ',', 'y', 'bajo', 'el']\n",
            "model='pipeline_4' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provocáronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Había', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_5' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provocáronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'había', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_6' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provocáronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Había', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_7' output=['fijo', 'en', 'sequía', 'con', 'chubascos', 'de', 'cinco', 'minutos', 'se', 'descomponía', 'por', 'fin', 'en', 'las', 'lagartijas', 'Aún', 'en', 'noviembre', 'cuando', 'tenía', 'ya', 'en', 'jaque', 'a', 'todas']\n",
            "\n",
            "Generando para text='Esteban Podeley'\n",
            "model='pipeline_1' output=[',', 'peones', 'de', 'obraje', ',', 'volvían', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compañeros', '.', 'Podeley', ',', 'cuya', 'fiebre', 'anterior', 'había', 'tenido', 'honrado', 'y']\n",
            "model='pipeline_2' output=[',', 'más', 'ansiosa', 'aún', '.', 'Recurrió', 'entonces', 'a', 'un', 'hombre', 'discreto', '.', 'Véase', ':', 'Fuí', 'a', 'lo', 'que', 'es', 'patrimonio', 'específico', 'de', 'los', 'corazones', 'inferiores']\n",
            "model='pipeline_3' output=['bajaron', 'tambaleantes', 'de', 'todo', 'el', 'piso', '.', 'Alrededor', 'del', 'menguante', '.', 'Pero', 'yo', 'con', 'sorpresa', '.', 'Pero', 'éste', ':', 'la', 'loma', ',', 'y', 'bajo', 'el']\n",
            "model='pipeline_4' output=[',', 'peones', 'de', 'obraje', ',', 'volvían', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compañeros', '.', 'Podeley', ',', 'labrador', 'de', 'madera', ',', 'tornaba', 'a', 'los']\n",
            "model='pipeline_5' output=['esperaba', 'una', 'lluvia', ',', 'y', 'salté', 'de', 'costado', ',', 'con', 'las', 'rodillas', 'recogidas', 'hasta', 'el', 'pecho', '.', '¿qué', 'sería', '?', 'y', 'la', 'respiración', 'también', '...']\n",
            "model='pipeline_6' output=[',', 'peones', 'de', 'obraje', ',', 'volvían', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compañeros', '.', 'Podeley', ',', 'cuya', 'fiebre', 'anterior', 'había', 'tenido', 'honrado', 'y']\n",
            "model='pipeline_7' output=['peones', 'de', 'obraje', 'volvían', 'a', 'Posadas', 'en', 'el', '_Silex_', 'con', 'quince', 'compañeros', 'Podeley', 'labrador', 'de', 'madera', 'tornaba', 'a', 'los', 'nueve', 'meses', 'la', 'contrata', 'concluída', 'y']\n"
          ]
        }
      ],
      "source": [
        "#Completar con los diferentes experimentos, llamando a las funciones train_language_model y language_model_inference\n",
        "\n",
        "\"\"\"\n",
        "Experimentos a realizar:\n",
        "\n",
        "1. Variar n en [4, 3, 2]\n",
        "2. Jugar con pre-procesamientos.\n",
        "\n",
        "Pre-procesamientos:\n",
        "1. Nada\n",
        "2. lowercase\n",
        "3. replace(\\n, \" \")\n",
        "\"\"\"\n",
        "\n",
        "def pipeline_1():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=4 y sin pre-procesamiento al corpus (más allá del inicial).\n",
        "  Esto nos permite observar la capacidad del modelo cuando se toman n-gramas de a cuatro palabras, lo cual por el\n",
        "  tamaño del corpus, es probable que genere sobre ajustes.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_1 -- Parámetros: n={4}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_2():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=3 y sin pre-procesamiento al corpus (más allá del inicial).\n",
        "  Esto nos permite observar como el modelo gana generalidad al no sobre ajustarse tanto pero seguramente\n",
        "  pierde capacidad de generación al tomar contexto de palabras reducido.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_2 -- Parámetros: n={3}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=3)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_3():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=2 y sin pre-procesamiento al corpus (más allá del inicial).\n",
        "  Similar al anterior.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_3 -- Parámetros: n={2}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=2)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_4():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=5 y sin pre-procesamiento al corpus (más allá del inicial).\n",
        "  Esto nos permite terminar de afianzar la idea de que se está sobre ajustando el modelo al texto provisto.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_4 -- Parámetros: n={5}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=5)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_5():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=4 y lowercase al corpus\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_5 -- Parámetros: n={4}, pre-process=lowercase()\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.lower()\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_6():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo combinando: n=4, lowercase y replace(\\n, \" \").\n",
        "\n",
        "  Al ser un texto pequeño, pasar a minúsculas y eliminar saltos de línea nos permite manejar\n",
        "  varias palabras como la misma, mejorando la capacidad de comprensión de un modelo simple como n-gramas.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_6 -- Parámetros: n={4}, pre-process=[lowercase(), replace(\\n, ' ')]\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.replace(\"\\n\", \" \")\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_7():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo combinando: n=4, lowercase y replace(\\n, \" \").\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_7 -- Parámetros: n={4}, pre-process=[lowercase(), replace([\\n, pubc_symbols], ' ')]\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.replace(\"\\n\", \" \")  # Elimino saltos de línea\n",
        "  pre_process_corpus = re.sub(r\"[^\\w\\s]\", \" \", pre_process_corpus)  # Elimino símbolos de puntuación\n",
        "  pre_process_corpus = re.sub(r\"\\s+\", \" \", pre_process_corpus).strip()  # Elimino espacios en blanco repetidos\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "\n",
        "# Generamos los language models\n",
        "models = [pipeline_1(), pipeline_2(), pipeline_3(), pipeline_4(), pipeline_5(), pipeline_6(), pipeline_7()]\n",
        "#models = [pipeline_5()]\n",
        "\n",
        "# Generamos textos\n",
        "results = []\n",
        "texts = [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]\n",
        "#texts = [\"las vacas\"]\n",
        "\n",
        "for text in texts:\n",
        "\n",
        "  print(f\"\\nGenerando para text='{text}'\")\n",
        "  text_results = []\n",
        "  for i, model in enumerate(models):\n",
        "    output_tokens = language_model_inference(language_model=model, prompt=text)\n",
        "    model_name = f\"pipeline_{i+1}\"\n",
        "    print(f\"model='{model_name}' output={output_tokens}\")\n",
        "    results.append({\"pipeline\": model_name, \"prompt\": text, \"output\": \" \".join(output_tokens)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestro los resultados en un dataframe para visualizarlos en formato tabla\n",
        "df_1 = pd.DataFrame(results)\n",
        "df_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "EpPn6kPtu80i",
        "outputId": "c4cbe7fb-43fb-4687-f6c7-ddf8ea1e4561"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pipeline           prompt  \\\n",
              "0   pipeline_1        las vacas   \n",
              "1   pipeline_2        las vacas   \n",
              "2   pipeline_3        las vacas   \n",
              "3   pipeline_4        las vacas   \n",
              "4   pipeline_5        las vacas   \n",
              "5   pipeline_6        las vacas   \n",
              "6   pipeline_7        las vacas   \n",
              "7   pipeline_1         el cielo   \n",
              "8   pipeline_2         el cielo   \n",
              "9   pipeline_3         el cielo   \n",
              "10  pipeline_4         el cielo   \n",
              "11  pipeline_5         el cielo   \n",
              "12  pipeline_6         el cielo   \n",
              "13  pipeline_7         el cielo   \n",
              "14  pipeline_1  Esteban Podeley   \n",
              "15  pipeline_2  Esteban Podeley   \n",
              "16  pipeline_3  Esteban Podeley   \n",
              "17  pipeline_4  Esteban Podeley   \n",
              "18  pipeline_5  Esteban Podeley   \n",
              "19  pipeline_6  Esteban Podeley   \n",
              "20  pipeline_7  Esteban Podeley   \n",
              "\n",
              "                                               output  \n",
              "0   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "2   dormitaban al fin se había reforzado su corazó...  \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "4   estaban inmóviles , mirando fijamente el verde...  \n",
              "5   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "6   dormitaban al sol ya caliente rumiando Pero cu...  \n",
              "7   constantemente encapotado y lluvioso , provocá...  \n",
              "8   constantemente encapotado y lluvioso , provocá...  \n",
              "9   de que está todo el piso . Alrededor del mengu...  \n",
              "10  constantemente encapotado y lluvioso , provocá...  \n",
              "11  constantemente encapotado y lluvioso , provocá...  \n",
              "12  constantemente encapotado y lluvioso , provocá...  \n",
              "13  fijo en sequía con chubascos de cinco minutos ...  \n",
              "14  , peones de obraje , volvían a Posadas en el _...  \n",
              "15  , más ansiosa aún . Recurrió entonces a un hom...  \n",
              "16  bajaron tambaleantes de todo el piso . Alreded...  \n",
              "17  , peones de obraje , volvían a Posadas en el _...  \n",
              "18  esperaba una lluvia , y salté de costado , con...  \n",
              "19  , peones de obraje , volvían a Posadas en el _...  \n",
              "20  peones de obraje volvían a Posadas en el _Sile...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pipeline</th>\n",
              "      <th>prompt</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al fin se había reforzado su corazó...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>estaban inmóviles , mirando fijamente el verde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente rumiando Pero cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provocá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provocá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>de que está todo el piso . Alrededor del mengu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provocá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provocá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provocá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>fijo en sequía con chubascos de cinco minutos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, más ansiosa aún . Recurrió entonces a un hom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>bajaron tambaleantes de todo el piso . Alreded...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>esperaba una lluvia , y salté de costado , con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_61cc0c2a-6ea6-468e-a7ae-04dd749864b4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_61cc0c2a-6ea6-468e-a7ae-04dd749864b4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_1",
              "summary": "{\n  \"name\": \"df_1\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"pipeline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\",\n          \"pipeline_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"las vacas\",\n          \"el cielo\",\n          \"Esteban Podeley\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "* Algunos pipelines producen sentencias con \"sentído\" y gramaticalmente correctas (o cerca de serlas). Este es el caso de los pipelines: pipeline_1, pipeline_2, pipeline_4 al pipeline_7.\n",
        "\n",
        "* Algunos pipelines producen sentencias con menor \"sentido\" y gramaticalmente incorrectas. Por ejemplo los pipelines: pipeline_2 y pipeline_3. Se puede observar así que el efecto de reducir el N en los n-gramas tiene un efecto negativo en la generación de sentencias gramaticalmente correctas.\n",
        "\n",
        "* De lo anterior se puede deducir que tomar un N más grande (N=4 o N=5) para los n-gramas tiene un efecto positivo en la generación de sentencias gramaticalmente correctas.\n",
        "\n",
        "* Pasar a minúsculas no parece tener un impacto negativo en la generación (pipeline_5). Por el contrario, se genera una sentencia bastante diferente al resto de los experimentos. Esto puede deberse a que al pasar a lowercase palabras como \"dormitaban\" y \"Dormitaban\" pasan a ser la misma, aumentando la cantidad de ejemplos en el corpus para esa palabra.\n",
        "\n",
        "* Remover los saltos de línea adicionales no parece producir un impacto positivo o negativo por si solo.\n",
        "\n",
        "* Remover los símbolos de puntuación no parece tener un impacto positivo. Lo único que cambia es que generamos sentencias más largas (hay más tokens disponibles) pero podemos lograr lo mismo aumentando el parámetro `length` en el método `language_model_inference`."
      ],
      "metadata": {
        "id": "N4OmYJgX1ebo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKpp9VVe-l-X"
      },
      "source": [
        "### 2️⃣ Mínima distancia de edición\n",
        "\n",
        "Los modelos de lenguaje que entrenaron en la parte anterior aprendieron la distribución estadística a través de secuencias de palabras en el libro de Quiroga. Sin embargo, las inferencias que consiguieron ¿estarán idénticas en el corpus de entrenamiento?\n",
        "\n",
        "Usando la función `edit_distance` de NLTK encuentren, para cada tira generada en la parte anterior, las 3 oraciones del libro original que tienen la menor distancia de edición asociada (es decir, el top 3). Las oraciones del libro están guardadas en la variable `quiroga_sentences`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RHzwkqTjA7pt"
      },
      "outputs": [],
      "source": [
        "quiroga_sentences = nltk.sent_tokenize(quiroga, language='spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qzxQA3Q2BJxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a817660a-2f27-4258-ceb3-b7cd1777913c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La distancia entre \"arbolada\" y \"escapada\" es 5, pero entre \"arbolada\" y \"arbolado\" es 1.\n"
          ]
        }
      ],
      "source": [
        "print(f'La distancia entre \"arbolada\" y \"escapada\" es {nltk.edit_distance(\"arbolada\", \"escapada\")}, pero entre \"arbolada\" y \"arbolado\" es {nltk.edit_distance(\"arbolada\", \"arbolado\")}.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_knn(text: str, k: int = 3, sentences: list[str] = []) -> list[str]:\n",
        "  # Obtengo distancias\n",
        "  distances = [nltk.edit_distance(text, sentence) for sentence in sentences]\n",
        "  # Obtengo indices de los K mas cercanos\n",
        "  closest_indices = np.argsort(distances)[:k]\n",
        "  closest_sentences = [sentences[i] for i in closest_indices]\n",
        "\n",
        "  return closest_sentences\n",
        "\n",
        "# Para guardar los resultados\n",
        "predictions = []\n",
        "\n",
        "for text in texts:\n",
        "\n",
        "  print(f\"\\n\\nGenerando para text='{text}'\")\n",
        "  for i, model in enumerate(models):\n",
        "    # Genero texto\n",
        "    model_name = f\"pipeline_{i+1}\"\n",
        "    output_tokens = language_model_inference(language_model=model, prompt=text)\n",
        "    output_text = \" \".join(output_tokens)\n",
        "\n",
        "    print(f\"model='{model_name}' output='{output_text}'\")\n",
        "\n",
        "    # Obtengo top_k vectores mas cercanos\n",
        "    nearest_k = get_knn(text=output_text, k=3, sentences=quiroga_sentences)\n",
        "    print(f\"neighbors={nearest_k}\")\n",
        "\n",
        "    for idx, neighbor_vec in enumerate(nearest_k):\n",
        "      # Guardo resultados\n",
        "      predictions.append({\n",
        "                  \"prompt\": text,\n",
        "                  \"model_name\": model_name,\n",
        "                  \"output_text\": output_text,\n",
        "                  \"idx\": idx+1,\n",
        "                  \"neighborh\": neighbor_vec\n",
        "              })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnB7arlINSKX",
        "outputId": "26be3b00-55ce-481c-bc4c-e4853226a442"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Generando para text='las vacas'\n",
            "model='pipeline_1' output='dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con'\n",
            "neighbors=['Pero cuando está conmigo, entonces no aparta los ojos de ellos.', 'Arrizabalaga y la señora se reían, volviéndose a menudo, y la joven no apartaba casi sus ojos de Nébel.', 'El caballo, por mayor intimidad de trato, es sensiblemente más afecto al hombre que la vaca.']\n",
            "model='pipeline_2' output='dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso'\n",
            "neighbors=['Celia, mi tía mayor, que había concluído de dormir la siesta, cruzó el patio y Alfonso la llamó en silencio con la mano.', 'Al bajar el sol volvieron, pero Berta quiso saludar un momento a sus vecinas de enfrente.', 'Volvió a su cobertizo, y en el camino sintió un ligero cosquilleo en la espalda.']\n",
            "model='pipeline_3' output='dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del'\n",
            "neighbors=['Como las fieras amaestradas, los perros conocen el menor indicio de borrachera en su amo.', 'Por lo demás, se alternaban con su hija para ir a ver a la enferma.', 'Benincasa se observaba muy de cerca en los pies la placa lívida de la mordedura.']\n",
            "model='pipeline_4' output='dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --'\n",
            "neighbors=['Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\\n\\n--Son los caballos.', 'Tarde ya, cuando el sol acababa de entrarse, los dos caballos se acordaron del maíz y emprendieron el regreso.', 'Luis María, por su parte, se permite pasarle la mano por la barbilla cuando entra y ella está sentada de espaldas.']\n",
            "model='pipeline_5' output='estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien'\n",
            "neighbors=['Las vacas estaban inmóviles, mirando fijamente el verde paraíso inalcanzable.', 'Ayestarain tornó a mirarme fijamente, pero esta vez creí notar un vago, vaguísimo dejo de amargura.', 'Esta vez Vezzera me miró fijamente a los ojos:\\n\\n--¿Por qué no quieres ir?']\n",
            "model='pipeline_6' output='dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con'\n",
            "neighbors=['Pero cuando está conmigo, entonces no aparta los ojos de ellos.', 'Arrizabalaga y la señora se reían, volviéndose a menudo, y la joven no apartaba casi sus ojos de Nébel.', 'El caballo, por mayor intimidad de trato, es sensiblemente más afecto al hombre que la vaca.']\n",
            "model='pipeline_7' output='dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres'\n",
            "neighbors=['Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\\n\\n--Son los caballos.', 'Porque, naturalmente, cuanto más intensos eran los raptos de amor a su marido e hija, más irritable era su humor con los monstruos.', 'Caminando, comiendo, curioseando, el alazán y el malacara cruzaron la capuera hasta que un alambrado los detuvo.']\n",
            "\n",
            "\n",
            "Generando para text='el cielo'\n",
            "model='pipeline_1' output='constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros días mamá pasó crueles angustias por sus hijos que habían besado a la virolenta.', 'Verdad es que no medía sino dos metros de hondura, tendiéndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_2' output='constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Durante tres meses consecutivos raras veces faltó, sin llegar yo jamás a explicarme qué combinaciones de visitas, casamientos y garden party debió hacer para no ser sospechada.', 'Sobre el cielo pálido y frío, sus siluetas se destacaban en negro, en mansa y cabizbaja pareja, el malacara delante, el alazán detrás.']\n",
            "model='pipeline_3' output='de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el'\n",
            "neighbors=['aquí está el buena pieza de tu Eduardo... ¡Te va a sacar canas este hijo, ya verás!', 'Pero sus ojos, así, llenaban aquel semblante en flor con la luz de su belleza.', '--Bueno; haga lo posible porque no entre, porque si pasa se va a lastimar.']\n",
            "model='pipeline_4' output='constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros días mamá pasó crueles angustias por sus hijos que habían besado a la virolenta.', 'Verdad es que no medía sino dos metros de hondura, tendiéndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_5' output='constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros días mamá pasó crueles angustias por sus hijos que habían besado a la virolenta.', 'Se sentó a su lado, y en balde la madre esperó a que se dijeran algo: no hacían sino mirarse y reir.']\n",
            "model='pipeline_6' output='constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros días mamá pasó crueles angustias por sus hijos que habían besado a la virolenta.', 'Verdad es que no medía sino dos metros de hondura, tendiéndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_7' output='fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas'\n",
            "neighbors=['Costeando por adentro el monte del fondo, a doscientos metros aún, el toro avanzaba hacia el avenal.', 'Esto crea así un caso de sicología singular de que un novelista podría sacar algún partido.', 'Pero a los treinta y cinco años proseguía en su pieza, aderezada en taller bajo la ventana.']\n",
            "\n",
            "\n",
            "Generando para text='Esteban Podeley'\n",
            "model='pipeline_1' output=', peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y'\n",
            "neighbors=['Durante el viaje había sido un excelente compañero, admirando por su cuenta y riesgo, y hablando poco.', 'Reverberaba ahora delante de ellos un pequeño páramo de greda que ni siquiera se había intentado arar.', 'Me desperté, y volví a soñar: el tal salón de baile estaba frecuentado por los muertos diarios de una epidemia.']\n",
            "model='pipeline_2' output=', más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores'\n",
            "neighbors=['Pero el calor creciente les hizo presto abandonar aquél por la sombra de los corredores.', 'Pero está perfectamente enterada de lo que pasó, por los cuentos posteriores.', 'Los perros, que en la mañana no habían dejado un momento a su patrón, se quedaron en los corredores.']\n",
            "model='pipeline_3' output='bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el'\n",
            "neighbors=['Lloró largamente todo su espanto callado, redoblando el llanto a la menor tentativa de caricia.', 'Pasaban casi todo el día sentados frente al cerco, abandonados de toda remota caricia.', 'Animábanse sólo al comer, cuando veían colores brillantes u oían truenos.']\n",
            "model='pipeline_4' output=', peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los'\n",
            "neighbors=['El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.', 'Apenas la conozco, vuelvo a repetirle, y no creo que ella se acuerde de haberme visto jamás.', 'Romper, es palabra corta y fácil; pero comenzarlo...\\n\\nNos habíamos sentado y no hablábamos.']\n",
            "model='pipeline_5' output='esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...'\n",
            "neighbors=['El aire faltaba, con angustia cardíaca que no permitía concluir la respiración.', 'Desde las orillas bordeadas de negros bloques de basalto, asciende el bosque, negro también.', 'El cielo, al poniente, se abría ahora en pantalla de oro, y el río se había coloreado también.']\n",
            "model='pipeline_6' output=', peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y'\n",
            "neighbors=['Durante el viaje había sido un excelente compañero, admirando por su cuenta y riesgo, y hablando poco.', 'Reverberaba ahora delante de ellos un pequeño páramo de greda que ni siquiera se había intentado arar.', 'Me desperté, y volví a soñar: el tal salón de baile estaba frecuentado por los muertos diarios de una epidemia.']\n",
            "model='pipeline_7' output='peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y'\n",
            "neighbors=['Sobre la honda ligadura del pañuelo, la carne desbordaba como una monstruosa morcilla.', 'Me desperté, y volví a soñar: el tal salón de baile estaba frecuentado por los muertos diarios de una epidemia.', 'Durante el viaje había sido un excelente compañero, admirando por su cuenta y riesgo, y hablando poco.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo DataFrame\n",
        "df_2 = pd.DataFrame(predictions, columns=[\"prompt\", \"model_name\", \"output_text\", \"idx\", \"neighborh\"])\n",
        "df_2"
      ],
      "metadata": {
        "id": "Sd0-xWGDBlfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4e5469cb-4ff6-4000-f3ee-94bdf396a3fb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             prompt  model_name  \\\n",
              "0         las vacas  pipeline_1   \n",
              "1         las vacas  pipeline_1   \n",
              "2         las vacas  pipeline_1   \n",
              "3         las vacas  pipeline_2   \n",
              "4         las vacas  pipeline_2   \n",
              "..              ...         ...   \n",
              "58  Esteban Podeley  pipeline_6   \n",
              "59  Esteban Podeley  pipeline_6   \n",
              "60  Esteban Podeley  pipeline_7   \n",
              "61  Esteban Podeley  pipeline_7   \n",
              "62  Esteban Podeley  pipeline_7   \n",
              "\n",
              "                                          output_text  idx  \\\n",
              "0   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "2   dormitaban al sol ya caliente , rumiando . Per...    3   \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "4   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "..                                                ...  ...   \n",
              "58  , peones de obraje , volvían a Posadas en el _...    2   \n",
              "59  , peones de obraje , volvían a Posadas en el _...    3   \n",
              "60  peones de obraje volvían a Posadas en el _Sile...    1   \n",
              "61  peones de obraje volvían a Posadas en el _Sile...    2   \n",
              "62  peones de obraje volvían a Posadas en el _Sile...    3   \n",
              "\n",
              "                                            neighborh  \n",
              "0   Pero cuando está conmigo, entonces no aparta l...  \n",
              "1   Arrizabalaga y la señora se reían, volviéndose...  \n",
              "2   El caballo, por mayor intimidad de trato, es s...  \n",
              "3   Celia, mi tía mayor, que había concluído de do...  \n",
              "4   Al bajar el sol volvieron, pero Berta quiso sa...  \n",
              "..                                                ...  \n",
              "58  Reverberaba ahora delante de ellos un pequeño ...  \n",
              "59  Me desperté, y volví a soñar: el tal salón de ...  \n",
              "60  Sobre la honda ligadura del pañuelo, la carne ...  \n",
              "61  Me desperté, y volví a soñar: el tal salón de ...  \n",
              "62  Durante el viaje había sido un excelente compa...  \n",
              "\n",
              "[63 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>model_name</th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighborh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Pero cuando está conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Arrizabalaga y la señora se reían, volviéndose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>El caballo, por mayor intimidad de trato, es s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi tía mayor, que había concluído de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Al bajar el sol volvieron, pero Berta quiso sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>Reverberaba ahora delante de ellos un pequeño ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Me desperté, y volví a soñar: el tal salón de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sobre la honda ligadura del pañuelo, la carne ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>Me desperté, y volví a soñar: el tal salón de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>Durante el viaje había sido un excelente compa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_60ca1286-b960-4f61-9b64-9f5582634840\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60ca1286-b960-4f61-9b64-9f5582634840 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_2",
              "summary": "{\n  \"name\": \"df_2\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"las vacas\",\n          \"el cielo\",\n          \"Esteban Podeley\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\",\n          \"pipeline_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighborh\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"Apenas la conozco, vuelvo a repetirle, y no creo que ella se acuerde de haberme visto jam\\u00e1s.\",\n          \"Se sent\\u00f3 a su lado, y en balde la madre esper\\u00f3 a que se dijeran algo: no hac\\u00edan sino mirarse y reir.\",\n          \"Costeando por adentro el monte del fondo, a doscientos metros a\\u00fan, el toro avanzaba hacia el avenal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "- Observando el top 3 de oraciones más cercanas (en base a la distancia de edición), se puede ver que para algunos preprocesamientos el top 3 de oraciones incluye una oración bastante similar a la generada por el modelo, mientras que en otros casos no.\n",
        "\n",
        "- En particular para los pipelines pipeline_2 y pipeline_3 el top 3 de sentencias NO incluye una sentencia que a simple vista sea similar al texto generado. Estos pipelines tienen en común que toman un N pequeño para la vectorización en n-gramas (N=3, N=2).\n",
        "\n",
        "- Los siguientes pipelines, producen oraciones que a simple vista coinciden en gran medida con alguna de las oraciones en el top 3: pipeline_1, pipeline_4, pipeline_5, pipeline_6 y pipeline_7. Estos pipelines tienen en común el uso de un N moderado para la generación de n-gramas (N=4, N=5).\n",
        "\n",
        "- Pasar a minúsculas, remover símbolos de puntuación y saltos de línea, no parece afectar negativamente las distancias. En particular se aprecia al menos una oración dentro del top 3 muy similar o idéntica al texto generado, cuando se utilizan estos preprocesamientos.\n",
        "\n",
        "Por otro lado, es interesante entender en el contexto del texto original, a que fragmento se puede estar sobre ajustando el texto generado. En particular seleccionando el texto generado con el **pipeline_6**, vemos que el inicio de la oración se encuentra textual en el siguiente pasaje:\n",
        "\n",
        "> Detrás de él, **las vacas**\n",
        "> dormitaban al sol ya caliente, rumiando.\n",
        ">\n",
        "> Pero cuando los pobres caballos pasaron por el camino, ellas abrieron\n",
        ">los ojos despreciativas:\n",
        "\n",
        "Basado en estas observaciones y en las observaciones de la parte anterior, parecería que el **pipeline_6** puede ser un muy buen pipeline a utilizar para el resto de los experimentos (pipeline \"ganador\"). No obstante, notar que estamos optando por un pipeline, por su capacidad de sobre ajustar al texto generado (esto podría no ser la mejor métrica de evaluación)."
      ],
      "metadata": {
        "id": "F-IQLKX-SKtu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2_OrMKFD7l_"
      },
      "source": [
        "### 3️⃣ Modelo neuronal para capturar la semántica\n",
        "\n",
        "Ahora repitan el mismo procedimiento de la parte anterior pero usando el [modelo neuronal E5](https://huggingface.co/intfloat/multilingual-e5-large), basado en la arquitectura BERT, que intenta representar el significado de un texto en un vector de largo fijo.\n",
        "\n",
        "Para hallar los tres vectores más cercanos a un vector dado, utilicen el algoritmo [Nearest Neighbors implementado en Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html).\n",
        "\n",
        "💡Van a tener que codificar (con vectores) tanto lo generado por el modelo de n-gramas como todas las oraciones guardadas en `quiroga_sentences`.\n",
        "\n",
        "💡Asegúrense de estar usando una GPU en el entorno de ejecución de Google Colab, para poder acelerar el procesamiento con E5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "GoafBjWoe1E1"
      },
      "outputs": [],
      "source": [
        "#Completar con la instalación de las bibliotecas necesarias,\n",
        "#el código que halla la representación vectorial de los textos\n",
        "#y el algoritmo para hallar el top 3 con Nearest Neighbors.\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "  last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "  return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def generate_vector_from_text(batch, model, tokenizer, device):\n",
        "  \"\"\"\n",
        "  Inspirado por https://discuss.huggingface.co/t/is-transformers-using-gpu-by-default/8500/2\n",
        "  en como manejar en GPU los vectrores resolviendo algunos problemas que tuve con Colab.\n",
        "  \"\"\"\n",
        "\n",
        "  # Tokenizo el batch\n",
        "  batch_dict = tokenizer(batch, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "  with torch.no_grad():  # Deshabilito gradient calculation\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "      embeddings_cpu = embeddings.cpu()  # Muevo embeddings a CPU para liberar memoria GPU\n",
        "\n",
        "  # Limpio memoria\n",
        "  del outputs, embeddings, batch_dict\n",
        "  torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "  return embeddings_cpu\n",
        "\n",
        "def generate_vectors_from_texts(texts, model, tokenizer, device):\n",
        "  texts_embeddings = []\n",
        "\n",
        "  # Defino data Loader para cargar eficientemente los vectores\n",
        "  batch_size = 16  # Adjust the batch size based on your memory availability\n",
        "  data_loader = DataLoader(texts, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  for batch in data_loader:\n",
        "    batch_embeddings = generate_vector_from_text(batch=batch, model=model, tokenizer=tokenizer, device=device)\n",
        "    texts_embeddings.append(batch_embeddings)\n",
        "\n",
        "  # Concatenate all embeddings after processing\n",
        "  texts_embeddings = torch.cat(texts_embeddings, dim=0)\n",
        "  return texts_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta celda generamos los vectores para todas las sentencias de\n",
        "# quiroga y para los textos de prueba\n",
        "\n",
        "# Device GPU si hay\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Init tokenizer y Modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
        "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')\n",
        "model.to(device)\n",
        "\n",
        "# 1. Texts\n",
        "#input_texts =  [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]\n",
        "input_texts = df_1[\"output\"].to_list()  # Uso todos los textos generados en df_1\n",
        "texts_embeddings = generate_vectors_from_texts(texts=input_texts, model=model, tokenizer=tokenizer, device=device)\n",
        "print(texts_embeddings.shape)\n",
        "\n",
        "# 2. Quiroga Sentences\n",
        "quiroga_embeddings = generate_vectors_from_texts(texts=quiroga_sentences, model=model, tokenizer=tokenizer, device=device)\n",
        "print(quiroga_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpS3_5SdKs0N",
        "outputId": "af4ce968-e4b1-459d-80a8-0d1fa5db72b6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([21, 1024])\n",
            "torch.Size([3540, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta celda calculamos los vecinos más cercanos\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=True):\n",
        "\n",
        "  # 3. Hallo top 3 con Nearest Neighbors.\n",
        "  neigh = NearestNeighbors(n_neighbors=3, radius=0.4)\n",
        "  neigh.fit(quiroga_embeddings)\n",
        "\n",
        "  predictions = []  # Para guardar las predicciones\n",
        "\n",
        "  # Corro knn en batch para todos los texts\n",
        "  if torch_tensor:\n",
        "    distances, indices = neigh.kneighbors(texts_embeddings.cpu().detach().numpy(), 3, return_distance=True)\n",
        "  else:\n",
        "    distances, indices = neigh.kneighbors(texts_embeddings, 3, return_distance=True)\n",
        "\n",
        "  print(f\"Distances: {distances.shape}\")\n",
        "  print(f\"Indices: {indices.shape}\")\n",
        "\n",
        "  for i, (text_distances, text_neighboors) in enumerate(zip(distances, indices)):\n",
        "    for j, (distance, n_idx) in enumerate(zip(text_distances, text_neighboors)):\n",
        "      model_name = f\"pipeline_{i+1}\"\n",
        "      neighboor = quiroga_embeddings[i]\n",
        "      #predictions.append({\"prompt\": input_texts[i], \"idx\": j+1, \"neighborh\": quiroga_sentences[n_idx]})\n",
        "      predictions.append({\n",
        "              \"output_text\": input_texts[i],\n",
        "              \"idx\": j+1,\n",
        "              \"neighbor\": quiroga_sentences[n_idx]}\n",
        "      )\n",
        "\n",
        "      print(f\"Text: {input_texts[i]}\")\n",
        "      print(f\"Neigh: {quiroga_sentences[n_idx]}\")\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "2a00vkDWLSFj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZV-iWbBCsaq",
        "outputId": "5a67b42a-c185-45f8-acac-2e377537269e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances: (21, 3)\n",
            "Indices: (21, 3)\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando está conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneció, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Celia, mi tía mayor, que había concluído de dormir la siesta, cruzó el patio y Alfonso la llamó en silencio con la mano.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Pasábanse horas sin oir el menor ruido.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Los peones que por a o b llegaban a la siesta, admiraron siempre la obstinación del perro, resoplando en cuevitas bajo un sol de fuego, si bien la admiración de aquellos no pasaba del cuadro de caza.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Los perros, entonces, sintieron más el próximo cambio de dueño, y solos, al pie de la casa dormida, comenzaron a llorar.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Cinco cigarrillos dejaron su tabaco adentro; y sentándonos entonces con las rodillas altas, encendí la pipa y aspiré.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: El viento, muy frío, cristalizaba aún más la claridad de la mañana de oro, y los caballos, que sentían de frente el sol, casi horizontal todavía, entrecerraban los ojos al dichoso deslumbramiento.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Las vacas estaban inmóviles, mirando fijamente el verde paraíso inalcanzable.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Se miraron fijamente, insistentemente, aislados del mundo en aquella recta paralela de alma a alma que los mantenía inmóviles.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Quedó inmóvil, toda ojos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando está conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneció, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Los dos caballos, vueltos ya a su pacífica condición de animales a que un solo hilo contiene, se sintieron ingenuamente deslumbrados por aquel héroe capaz de afrontar el alambre de púa, la cosa más terrible que puede hallar el deseo de pasar adelante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Después de trasponer la loma, los caballos vieron de pronto a las vacas detenidas en el camino, y el recuerdo de la tarde anterior excitó sus orejas y su paso: querían ver cómo era el nuevo alambrado.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: Durante tres meses consecutivos raras veces faltó, sin llegar yo jamás a explicarme qué combinaciones de visitas, casamientos y garden party debió hacer para no ser sospechada.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Aquí ha comenzado mi sorpresa.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Lo que primero me chocó, aunque debía haberlo esperado, fué la penumbra del dormitorio.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: ¿Pero estábamos todos locos en la casa, o había allí, proyectado fuera de mí mismo, un eco a mi incesante angustia del _después_?\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "El otoño finalizaba, y el cielo, fijo en sequía con chubascos de cinco minutos, se descomponía por fin en mal tiempo constante, cuya humedad hinchaba el hombro de los mensú.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: Las hojas secas, detenidas en su caída, entretejían el macizo, que llenaba el aire de polvo y briznas al menor contacto.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Allá en el obraje de Castelhum, más arriba de Puerto Felicidad, las lluvias habían comenzado después de setenta y cinco días de seca absoluta que no dejó llanta en las alzaprimas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior había tenido honrado y periódico ritmo, no presagió nada bueno para él de esa galopada de accesos casi sin intermitencia.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: --¿Del médico?--volvió Lidia al rato, más ansiosa aún.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: Por lo cual, mientras el joyero trabajaba doblado sobre sus pinzas, ella, de codos, sostenía sobre su marido una lenta y pesada mirada, para arrancarse luego bruscamente y seguir con la vista tras los vidrios al transeunte de posición que podía haber sido su marido.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: Y con una honda náusea por aquello pegajoso, fofo e inerte que era su marido, se fué a su cuarto.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Y tamborileó bruscamente sobre la mesa.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Ocupábanse entonces los mensú en la planchada, tumbando piezas entre inacabable gritería, que subía de punto cuando las mulas, impotentes para contener la alzaprima, que bajaba a todo escape, rodaban unas sobre otras dando tumbos, vigas, animales, carretas, todo bien mezclado.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Allí abajo, sin embargo, estaba la lagartija.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata concluída, y con pasaje gratis, por lo tanto.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario podía subir a siete pesos, la vida de obraje no era dura.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Bruscamente desaparecí a sus ojos tras las cañas; corriendo siempre, di un empujón a la piedra exploradora que esperaba una lluvia, y salté de costado, hundiéndome bajo la hojarasca.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Desde allí, y de atrás, acechó a su compañero, recogiendo el revólver caído; pero Podeley yacía de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Señalando luego el torrente con un movimiento del capuchón:\n",
            "\n",
            "--¿Las aguas llegarán a cubrir el salto?--preguntó a su compañero.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior había tenido honrado y periódico ritmo, no presagió nada bueno para él de esa galopada de accesos casi sin intermitencia.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata concluída, y con pasaje gratis, por lo tanto.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario podía subir a siete pesos, la vida de obraje no era dura.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [[f\"pipeline_{i}\"] * 3 for i in range(1, 8)] * 3\n",
        "model_names = [item for sublist in model_names for item in sublist]\n",
        "text_values = [[text] * 7*3 for text in [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]]\n",
        "text_values = text_values[0] + text_values[1] + text_values[1]"
      ],
      "metadata": {
        "id": "V6OLUC4seJ8t"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrego valores faltantes\n",
        "predictions_ext = []\n",
        "for p, model_name, text in zip(predictions, model_names, text_values):\n",
        "  p[\"model_name\"] = model_name\n",
        "  p[\"prompt\"] = text\n",
        "  predictions_ext.append(p)\n",
        "\n",
        "# Creo DataFrame\n",
        "df_3 = pd.DataFrame(predictions_ext, columns=[\"prompt\", \"model_name\", \"output_text\", \"idx\", \"neighbor\"])\n",
        "df_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1DCkmPwwTsXY",
        "outputId": "875ba0ca-e2ce-4558-f074-6bc521c283b8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       prompt  model_name                                        output_text  \\\n",
              "0   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "1   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "2   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "3   las vacas  pipeline_2  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "4   las vacas  pipeline_2  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "..        ...         ...                                                ...   \n",
              "58   el cielo  pipeline_6  , peones de obraje , volvían a Posadas en el _...   \n",
              "59   el cielo  pipeline_6  , peones de obraje , volvían a Posadas en el _...   \n",
              "60   el cielo  pipeline_7  peones de obraje volvían a Posadas en el _Sile...   \n",
              "61   el cielo  pipeline_7  peones de obraje volvían a Posadas en el _Sile...   \n",
              "62   el cielo  pipeline_7  peones de obraje volvían a Posadas en el _Sile...   \n",
              "\n",
              "    idx                                           neighbor  \n",
              "0     1  Detrás de él, las vacas dormitaban al sol ya c...  \n",
              "1     2  Pero cuando está conmigo, entonces no aparta l...  \n",
              "2     3  Y juro que fueron fuertes las dos horas que pa...  \n",
              "3     1  Celia, mi tía mayor, que había concluído de do...  \n",
              "4     2  Detrás de él, las vacas dormitaban al sol ya c...  \n",
              "..  ...                                                ...  \n",
              "58    2  El _Silex_ volvió a Posadas, llevando con él a...  \n",
              "59    3  Podeley, cuya fiebre anterior había tenido hon...  \n",
              "60    1  Podeley, labrador de madera, tornaba a los nue...  \n",
              "61    2  #LOS MENSÚ#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...  \n",
              "62    3  *       *       *       *       *\\n\\nPara Pode...  \n",
              "\n",
              "[63 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>model_name</th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighbor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Detrás de él, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Pero cuando está conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>Y juro que fueron fuertes las dos horas que pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi tía mayor, que había concluído de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Detrás de él, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>El _Silex_ volvió a Posadas, llevando con él a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Podeley, cuya fiebre anterior había tenido hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Podeley, labrador de madera, tornaba a los nue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>#LOS MENSÚ#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>*       *       *       *       *\\n\\nPara Pode...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-689abfa4-263d-40be-bf3d-92433234e404\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-689abfa4-263d-40be-bf3d-92433234e404')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-689abfa4-263d-40be-bf3d-92433234e404 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4d16bcb4-1f57-4c56-bcc6-b02831da5828\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d16bcb4-1f57-4c56-bcc6-b02831da5828 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_3",
              "summary": "{\n  \"name\": \"df_3\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"el cielo\",\n          \"las vacas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighbor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"All\\u00ed abajo, sin embargo, estaba la lagartija.\",\n          \"Bruscamente desaparec\\u00ed a sus ojos tras las ca\\u00f1as; corriendo siempre, di un empuj\\u00f3n a la piedra exploradora que esperaba una lluvia, y salt\\u00e9 de costado, hundi\\u00e9ndome bajo la hojarasca.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "* A diferencia de la distancia de edición, las oraciones incluidas en el top 3 están relacionadas al texto generado, fundamentalmente en el significado de la misma, en lugar de simplemente en la combinación de palabras.\n",
        "\n",
        "* A diferencia de la distancia de edición, en algunos ejemplos más de una de las oraciones más cercanas, tiene una similitud alta con el texto generado, tanto en la semántica como en co-ocurrencia de palabras."
      ],
      "metadata": {
        "id": "MOqh33orAHL3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qq0JiQnALx5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach alternativo\n",
        "\n",
        "En base al siguiente [intercambio](https://eva.fing.edu.uy/mod/forum/discuss.php?d=308994) en el foro del laboratorio en EVA, se deduce una forma alternativa (de más alto nivel) para utilizar los embeddings de este modelo mediante la biblioteca sentence-transformers. Por las dudas en la siguiente sección se incluye el código para realizar el mismo experimento, mediante el uso de esta biblioteca, en lugar de inferir utilizando el modelo directamente y PyTorch."
      ],
      "metadata": {
        "id": "PoubJ6DU5KM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "input_texts = df_1[\"output\"].to_list()\n",
        "texts_embeddings = model.encode(input_texts, normalize_embeddings=True)\n",
        "quiroga_embeddings = model.encode(quiroga_sentences, normalize_embeddings=True)\n",
        "\n",
        "predictions = get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=False)\n",
        "\n",
        "# Creo DataFrame\n",
        "df_4 = pd.DataFrame(predictions, columns=[\"output_text\", \"idx\", \"neighbor\"])\n",
        "df_4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kF4kIVTZ59yO",
        "outputId": "73d4fe2d-f103-4437-e631-6e4343eda05a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances: (21, 3)\n",
            "Indices: (21, 3)\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando está conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneció, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Celia, mi tía mayor, que había concluído de dormir la siesta, cruzó el patio y Alfonso la llamó en silencio con la mano.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llamó en silencio . Pasábanse horas sin oir el angustioso\n",
            "Neigh: Pasábanse horas sin oir el menor ruido.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Los peones que por a o b llegaban a la siesta, admiraron siempre la obstinación del perro, resoplando en cuevitas bajo un sol de fuego, si bien la admiración de aquellos no pasaba del cuadro de caza.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Cinco cigarrillos dejaron su tabaco adentro; y sentándonos entonces con las rodillas altas, encendí la pipa y aspiré.\n",
            "Text: dormitaban al fin se había reforzado su corazón siempre en la pipa y el perro había retirado . A media hora en tierra , del\n",
            "Neigh: Los perros, entonces, sintieron más el próximo cambio de dueño, y solos, al pie de la casa dormida, comenzaron a llorar.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: El viento, muy frío, cristalizaba aún más la claridad de la mañana de oro, y los caballos, que sentían de frente el sol, casi horizontal todavía, entrecerraban los ojos al dichoso deslumbramiento.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Las vacas estaban inmóviles, mirando fijamente el verde paraíso inalcanzable.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Se miraron fijamente, insistentemente, aislados del mundo en aquella recta paralela de alma a alma que los mantenía inmóviles.\n",
            "Text: estaban inmóviles , mirando fijamente el verde paraíso inalcanzable . -- ¿por qué ? ¿qué le pasa ? -- nada , sino que está bien\n",
            "Neigh: Quedó inmóvil, toda ojos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detrás de él, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando está conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando está conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneció, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Los dos caballos, vueltos ya a su pacífica condición de animales a que un solo hilo contiene, se sintieron ingenuamente deslumbrados por aquel héroe capaz de afrontar el alambre de púa, la cosa más terrible que puede hallar el deseo de pasar adelante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Después de trasponer la loma, los caballos vieron de pronto a las vacas detenidas en el camino, y el recuerdo de la tarde anterior excitó sus orejas y su paso: querían ver cómo era el nuevo alambrado.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: Durante tres meses consecutivos raras veces faltó, sin llegar yo jamás a explicarme qué combinaciones de visitas, casamientos y garden party debió hacer para no ser sospechada.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que no vaya yo jamás a explicarme qué combinaciones de visitas , casamientos y garden\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Lo que primero me chocó, aunque debía haberlo esperado, fué la penumbra del dormitorio.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Aquí ha comenzado mi sorpresa.\n",
            "Text: de que está todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: ¿Pero estábamos todos locos en la casa, o había allí, proyectado fuera de mí mismo, un eco a mi incesante angustia del _después_?\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el número de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provocáronle verdaderas alucinaciones de perros que entraban al trote por la portera . Había un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "El otoño finalizaba, y el cielo, fijo en sequía con chubascos de cinco minutos, se descomponía por fin en mal tiempo constante, cuya humedad hinchaba el hombro de los mensú.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: Las hojas secas, detenidas en su caída, entretejían el macizo, que llenaba el aire de polvo y briznas al menor contacto.\n",
            "Text: fijo en sequía con chubascos de cinco minutos se descomponía por fin en las lagartijas Aún en noviembre cuando tenía ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Allá en el obraje de Castelhum, más arriba de Puerto Felicidad, las lluvias habían comenzado después de setenta y cinco días de seca absoluta que no dejó llanta en las alzaprimas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior había tenido honrado y periódico ritmo, no presagió nada bueno para él de esa galopada de accesos casi sin intermitencia.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: --¿Del médico?--volvió Lidia al rato, más ansiosa aún.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: Y con una honda náusea por aquello pegajoso, fofo e inerte que era su marido, se fué a su cuarto.\n",
            "Text: , más ansiosa aún . Recurrió entonces a un hombre discreto . Véase : Fuí a lo que es patrimonio específico de los corazones inferiores\n",
            "Neigh: Ella buscó atolondradamente otro, pero no lo tenía.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Y tamborileó bruscamente sobre la mesa.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: La sirvienta lo levantó, pero en seguida lo dejó caer, y se quedó mirando a aquél, lívida y temblando.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero éste : la loma , y bajo el\n",
            "Neigh: Allí abajo, sin embargo, estaba la lagartija.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata concluída, y con pasaje gratis, por lo tanto.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Bruscamente desaparecí a sus ojos tras las cañas; corriendo siempre, di un empujón a la piedra exploradora que esperaba una lluvia, y salté de costado, hundiéndome bajo la hojarasca.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Desde allí, y de atrás, acechó a su compañero, recogiendo el revólver caído; pero Podeley yacía de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\n",
            "Text: esperaba una lluvia , y salté de costado , con las rodillas recogidas hasta el pecho . ¿qué sería ? y la respiración también ...\n",
            "Neigh: Señalando luego el torrente con un movimiento del capuchón:\n",
            "\n",
            "--¿Las aguas llegarán a cubrir el salto?--preguntó a su compañero.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: El _Silex_ volvió a Posadas, llevando con él al mensú empapado aún en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volvían a Posadas en el _Silex_ , con quince compañeros . Podeley , cuya fiebre anterior había tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior había tenido honrado y periódico ritmo, no presagió nada bueno para él de esa galopada de accesos casi sin intermitencia.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata concluída, y con pasaje gratis, por lo tanto.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: #LOS MENSÚ#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volvían a\n",
            "Posadas en el _Silex_, con quince compañeros.\n",
            "Text: peones de obraje volvían a Posadas en el _Silex_ con quince compañeros Podeley labrador de madera tornaba a los nueve meses la contrata concluída y\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario podía subir a siete pesos, la vida de obraje no era dura.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          output_text  idx  \\\n",
              "0   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "2   dormitaban al sol ya caliente , rumiando . Per...    3   \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "4   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "..                                                ...  ...   \n",
              "58  , peones de obraje , volvían a Posadas en el _...    2   \n",
              "59  , peones de obraje , volvían a Posadas en el _...    3   \n",
              "60  peones de obraje volvían a Posadas en el _Sile...    1   \n",
              "61  peones de obraje volvían a Posadas en el _Sile...    2   \n",
              "62  peones de obraje volvían a Posadas en el _Sile...    3   \n",
              "\n",
              "                                             neighbor  \n",
              "0   Detrás de él, las vacas dormitaban al sol ya c...  \n",
              "1   Pero cuando está conmigo, entonces no aparta l...  \n",
              "2   Y juro que fueron fuertes las dos horas que pa...  \n",
              "3   Celia, mi tía mayor, que había concluído de do...  \n",
              "4   Detrás de él, las vacas dormitaban al sol ya c...  \n",
              "..                                                ...  \n",
              "58  El _Silex_ volvió a Posadas, llevando con él a...  \n",
              "59  Podeley, cuya fiebre anterior había tenido hon...  \n",
              "60  Podeley, labrador de madera, tornaba a los nue...  \n",
              "61  #LOS MENSÚ#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...  \n",
              "62  *       *       *       *       *\\n\\nPara Pode...  \n",
              "\n",
              "[63 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c629116a-3e60-4967-ba88-c9bb95af3104\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighbor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Detrás de él, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Pero cuando está conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>Y juro que fueron fuertes las dos horas que pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi tía mayor, que había concluído de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Detrás de él, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>El _Silex_ volvió a Posadas, llevando con él a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>, peones de obraje , volvían a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Podeley, cuya fiebre anterior había tenido hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Podeley, labrador de madera, tornaba a los nue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>#LOS MENSÚ#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>peones de obraje volvían a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>*       *       *       *       *\\n\\nPara Pode...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c629116a-3e60-4967-ba88-c9bb95af3104')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c629116a-3e60-4967-ba88-c9bb95af3104 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c629116a-3e60-4967-ba88-c9bb95af3104');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2700401d-73c1-4d5a-b31d-986f3d878231\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_4')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2700401d-73c1-4d5a-b31d-986f3d878231 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_4');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_4",
              "summary": "{\n  \"name\": \"df_4\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighbor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"All\\u00ed abajo, sin embargo, estaba la lagartija.\",\n          \"Desde all\\u00ed, y de atr\\u00e1s, acech\\u00f3 a su compa\\u00f1ero, recogiendo el rev\\u00f3lver ca\\u00eddo; pero Podeley yac\\u00eda de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\",\n          \"Pas\\u00e1banse horas sin oir el menor ruido.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2pE422l5-HD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distancia de Edición vs. Embeddings\n",
        "\n",
        "Con n-gramas y distancia de edición se obtienen oraciones similares en las palabras y su orden de aparición en la oración (esto es por como se implementa dicha distancia). Como el modelo de generación se sobreajusta al texto de entrenamiento, la distancia de edición suele recuperar una oración muy similar.\n",
        "\n",
        "Por otro lado, con sentence-transformers obtenemos oraciones que significan lo mismo (o que en significado están muy cerca) pero que pueden diferir en largo, palabras y orden de las mismas."
      ],
      "metadata": {
        "id": "2-l6_UQ6BSJo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooPFHBSAS0HW"
      },
      "source": [
        "## Segunda parte: Clasificación de textos por autor\n",
        "\n",
        "En esta segunda parte del laboratorio vamos a usar los datos limpios de `quiroga` y todo lo practicado de manipulación de tiras para hacer experimentos de clasificación.\n",
        "\n",
        "\n",
        "Con el fin de construir modelos que intenten identificar los autores de cada oración según su estilo de escritura, vamos a incorporar dos libros más, una [selección de obras](https://www.gutenberg.org/ebooks/53552) de Gustavo Adolfo Bécquer y [El Gaucho Martín Fierro](https://es.wikipedia.org/wiki/El_Gaucho_Mart%C3%ADn_Fierro) de José Hernández."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "dY8luVJBVBHA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://www.gutenberg.org/cache/epub/53552/pg53552.txt\n",
        "with open(\"pg53552.txt\",\"r\") as f:\n",
        "    becquer_raw = f.read()\n",
        "\n",
        "!wget https://www.gutenberg.org/cache/epub/14765/pg14765.txt\n",
        "with open(\"pg14765.txt\",\"r\") as f:\n",
        "    martin_fierro_raw = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkqDMjAayR3"
      },
      "source": [
        "### 4️⃣ Limpieza básica del nuevo texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbaee-5gn9_"
      },
      "source": [
        "Análogamente a lo hecho en el ejercicio 0️⃣, limpien `becquer_raw` para que en la variable `becquer` quede:\n",
        "\n",
        "\n",
        "* solamente el texto que está entre \"Junio de 1868.\" y \"FIN\\n\"\n",
        "* sin aquellos saltos de línea que tengan a su derecha una palabra que comience con letra minúscula\n",
        "* y borrando todas las subtiras \"[Ilustración]\"\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8YskGZRVb3jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bea387c-b7a8-44d7-86b7-c6e4c5287ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 573195 caracteres. \n",
            "Texto extraído: 527105 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de línea en sentencias...\n",
            "Texto original: 527105 caracteres. \n",
            "Texto extraído: 527105 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "LEYENDAS\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "MAESE PÉREZ EL ORGANISTA\n",
            "\n",
            "\n",
            "En Sevilla, en el mismo atrio de Santa Inés, y mientras esperaba que comenzase la Misa del Gallo, oí esta tradición á una demandadera del convento.\n",
            "\n",
            "Como era natural, después de oirla, aguardé impaciente que comenzara la ceremonia, ansioso de asistir á un prodigio.\n",
            "\n",
            "Nada menos prodigioso, sin embargo, que el órgano de Santa Inés, ni nada más vulgar que los insulsos motetes que nos regaló su organista aquella noche.\n",
            "\n",
            "Al salir de la Misa, no pude por menos de decirle á la demandadera con aire de burla:\n",
            "\n",
            "--¿En qué consiste que el órgano de maese Pérez suena ahora tan mal?\n",
            "\n",
            "--¡Toma!--me contestó la vieja,--en que ese no es el suyo.\n",
            "\n",
            "--¿No es el suyo? ¿Pues qué ha sido de él?\n",
            "\n",
            "--Se cayó á pedazos de puro viejo, hace una porción de años.\n",
            "\n",
            "--¿Y el alma del organista?\n",
            "\n",
            "--No ha vuelto á parecer desde que colocaron el que ahora le sustituye.\n",
            "\n",
            "Si á alguno de mis lectores se le ocurriese hacerme la misma pregunta, después de leer esta historia, ya s\n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignación para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "#becquer = becquer_raw\n",
        "\n",
        "# 1. Extracción del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "becquer_text_extract_pattern = r\"Junio de 1868\\.(.*)FIN\\n\"  # Expresion regular\n",
        "match = re.search(becquer_text_extract_pattern, becquer_raw, re.DOTALL)\n",
        "if match:\n",
        "    becquer_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(becquer_raw)} caracteres. \\nTexto extraído: {len(becquer_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de línea\n",
        "print(\"\\n\\nLimpiando saltos de línea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "becquer = re.sub(breakline_lowercase_pattern, r\" \\1\", becquer_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(becquer_text)} caracteres. \\nTexto extraído: {len(becquer)} caracteres.\")\n",
        "\n",
        "# 3. Borro subturas ilustración\n",
        "becquer = becquer.replace(\"[Ilustración]\", \" \")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(becquer[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kyv62UueSPN"
      },
      "source": [
        "Hagan lo mismo con `martin_fierro_raw`, guardando en la variable `martin_fierro`:\n",
        "* el texto que está entre \"Buenos Aires, diciembre de 1872.\" y \"End of Project\"\n",
        "* sin aquellos saltos de línea que tengan a su derecha una palabra que comience con letra minúscula\n",
        "* y borrando todos los números de entre 1 y 3 cifas, e.g. 7, 12, 178   \n",
        "\n",
        "⚠️ Aclaración: *El Gaucho Martín Fierro* está originalmente escrito como un poema, por lo que los saltos de línea no tienen el mismo fin que en la prosa. Sin embargo, eliminaremos esos saltos de línea seguidos de minúsculas como convención, a fin de facilitar el ejercicio y hacer más parecido el texto a los guardados en `quiroga` y `becquer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOywbgmujD0L",
        "outputId": "ccba08bc-cb98-4bf5-9d88-847732782e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 85812 caracteres. \n",
            "Texto extraído: 62129 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de línea en sentencias...\n",
            "Texto original: 62129 caracteres. \n",
            "Texto extraído: 62129 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            "El Gaucho Martín Fierro\n",
            "\n",
            "\n",
            "I - Cantor y Gaucho.\n",
            "\n",
            " \n",
            "Aquí me pongo a cantar\n",
            "Al compás de la vigüela,\n",
            "Que el hombre que lo desvela\n",
            "Una pena estraordinaria\n",
            "Como la ave solitaria\n",
            "Con el cantar se consuela.\n",
            "\n",
            " \n",
            "Pido a los Santos del Cielo\n",
            "Que ayuden mi pensamiento;\n",
            "Les pido en este momento\n",
            "Que voy a cantar mi historia\n",
            "Me refresquen la memoria\n",
            "Y aclaren mi entendimiento.\n",
            "\n",
            " \n",
            "Vengan Santos milagrosos,\n",
            "Vengan todos en mi ayuda,\n",
            "Que la lengua se me añuda\n",
            "Y se me turba la vista;\n",
            "Pido a Dios que me asista\n",
            "En una ocasión tan ruda.\n",
            "\n",
            " \n",
            "Yo he visto muchos cantores,\n",
            "Con famas bien obtenidas,\n",
            "Y que después de adquiridas\n",
            "No las quieren sustentar\n",
            "Parece que sin largar se cansaron en partidas\n",
            "\n",
            " \n",
            "Mas ande otro criollo pasa\n",
            "Martín Fierro ha de pasar; nada lo hace recular ni los fantasmas lo espantan, y dende que todos cantan yo también quiero cantar.\n",
            "\n",
            " \n",
            "Cantando me he de morir\n",
            "Cantando me han de enterrar,\n",
            "Y cantando he de llegar\n",
            "Al pie del eterno padre:\n",
            "Dende el vientre de mi madre\n",
            "Vine a este mundo a cantar.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignación para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "#martin_fierro = martin_fierro_raw\n",
        "\n",
        "# 1. Extracción del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "martin_fierro_text_extract_pattern = r\"Buenos Aires, diciembre de 1872\\.(.*)End of Project\"  # Expresion regular\n",
        "match = re.search(martin_fierro_text_extract_pattern, martin_fierro_raw, re.DOTALL)\n",
        "if match:\n",
        "    martin_fierro_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(martin_fierro_raw)} caracteres. \\nTexto extraído: {len(martin_fierro_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de línea\n",
        "print(\"\\n\\nLimpiando saltos de línea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "martin_fierro = re.sub(breakline_lowercase_pattern, r\" \\1\", martin_fierro_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(martin_fierro_text)} caracteres. \\nTexto extraído: {len(martin_fierro)} caracteres.\")\n",
        "\n",
        "# 3. Borro numeros de 1-3 cifras\n",
        "martin_fierro = martin_fierro.replace(\"[Ilustración]\", \" \")\n",
        "martin_fierro = re.sub(r'\\b\\d{1,3}\\b', ' ', martin_fierro)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(martin_fierro[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSoCwM63kmoC"
      },
      "source": [
        "### Creación del corpus de clasificación\n",
        "\n",
        "En la siguiente celda, ya implementada, se crea el corpus y se subdivide en conjuntos de entrenamiento (`corpus_sentences_train`, `corpus_authors_train`), desarrollo (`corpus_sentences_dev`, `corpus_authors_dev`) y evaluación  (`corpus_sentences_test`, `corpus_authors_test`).\n",
        "\n",
        "💡Cada conjunto está a su vez subdividido en `corpus_sentences` y `corpus_authors`, donde los textos que pertenecen a `quiroga` están señalizados por el `0`, los de `becquer` por el `1` y los de `martin_fierro` por el `2`. Esto facilita el algoritmo de partición y también la evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "k-ftovt8nXIy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "quiroga_sentences = [x for x in nltk.sent_tokenize(quiroga,  language='spanish') if len(x)>4]\n",
        "corpus_sentences = quiroga_sentences\n",
        "corpus_authors = [0]*len(quiroga_sentences)\n",
        "\n",
        "becquer_sentences = [x for x in nltk.sent_tokenize(becquer,  language='spanish') if len(x)>4]\n",
        "corpus_sentences += becquer_sentences\n",
        "corpus_authors += [1]*len(becquer_sentences)\n",
        "\n",
        "martin_fierro_sentences = [x for x in nltk.sent_tokenize(martin_fierro,  language='spanish') if len(x)>4]\n",
        "corpus_sentences += martin_fierro_sentences\n",
        "corpus_authors += [2]*len(martin_fierro_sentences)\n",
        "\n",
        "corpus_sentences_train, corpus_sentences_other, corpus_authors_train, corpus_authors_other = train_test_split(\n",
        "    corpus_sentences, corpus_authors,\n",
        "    test_size=0.3, train_size=0.7,\n",
        "    random_state=2024, shuffle=True, stratify=corpus_authors)\n",
        "\n",
        "corpus_sentences_dev, corpus_sentences_test, corpus_authors_dev, corpus_authors_test = train_test_split(\n",
        "    corpus_sentences_other, corpus_authors_other,\n",
        "    test_size=0.5, train_size=0.5,\n",
        "    random_state=2024, shuffle=True, stratify=corpus_authors_other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHCjESY9Z8h"
      },
      "source": [
        "### 5️⃣ Análisis del corpus\n",
        "\n",
        "Para entender mejor cómo está compuesto el corpus, hallen:\n",
        "- la cantidad de instancias en los subconjuntos `train`, `dev` y `test`\n",
        "- la cantidad de instancias de cada una de las clases (*quiroga*, *becquer*  y *martin_fierro*) en cada uno de los subconjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "VLnjQRU-_a7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cfcb23-bc29-44ae-ab71-c64233dcb477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- TRAIN ----\n",
            "sentencias=4530\n",
            "quiroga=2469 becquer=1727 martin_fierro=334\n",
            "\n",
            "---- DEV ----\n",
            "971\n",
            "quiroga=529 becquer=370 martin_fierro=72\n",
            "\n",
            "---- TEST ----\n",
            "971\n",
            "quiroga=530 becquer=370 martin_fierro=71\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Completar\n",
        "\n",
        "# Cantidad de instancias en cada corpus\n",
        "print(\"---- TRAIN ----\")\n",
        "print(f\"sentencias={len(corpus_sentences_train)}\")\n",
        "counter_dict = Counter(corpus_authors_train)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n",
        "\n",
        "print(\"\\n---- DEV ----\")\n",
        "print(len(corpus_sentences_dev))\n",
        "counter_dict = Counter(corpus_authors_dev)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n",
        "\n",
        "print(\"\\n---- TEST ----\")\n",
        "print(len(corpus_sentences_test))\n",
        "counter_dict = Counter(corpus_authors_test)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFQ8t9EcFkBT"
      },
      "source": [
        "### Evaluación del clasificador aleatorio (línea base)\n",
        "\n",
        "Ahora que tenemos los conjuntos definidos, ya podemos entrenar modelos. Pero antes, siempre es bueno ver cómo se comportaría un algoritmo sencillo que consista en una heurística con pocas reglas o en una clasificación aleatoria. A este modelo sencillo, que sirve como punto de comparación, le solemos llamar *línea base* (baseline).\n",
        "\n",
        "En la siguiente celda les mostramos la evaluación sobre `dev` de la predicción aleatoria, para que tengan una línea base con la que comparar los modelos que construirán a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "cEenAtv2DQYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f4da51-4077-48ba-8a1c-fcc30ed57255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 30.17\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.57      0.35      0.43       529\n",
            "      becquer       0.38      0.33      0.35       370\n",
            "martin_fierro       0.07      0.33      0.12        72\n",
            "\n",
            "     accuracy                           0.34       971\n",
            "    macro avg       0.34      0.34      0.30       971\n",
            " weighted avg       0.46      0.34      0.38       971\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "random_prediction = [random.choice([0,1,2]) for i in range(len(corpus_authors_dev))]\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, random_prediction, average='macro')*100, 2))) # Se imprime la medida F\n",
        "print(classification_report(corpus_authors_dev, random_prediction, target_names=['quiroga','becquer','martin_fierro'])) # Se evalúa sobre dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKmhc7w1KcV"
      },
      "source": [
        "### 6️⃣ Entrenamiento y evaluación de modelos en el conjunto de desarrollo (dev)\n",
        "\n",
        "Ahora que vimos la medida F1 en `dev` para el clasificador aleatorio, ya pueden entrenar modelos y evaluarlos intentando superar esa línea base. En la siguiente celda mostramos el entrenamiento sobre `train` de un modelo sencillo y su posterior evaluación sobre `dev`, donde usamos [bag of words](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation) para representar numéricamente los textos y [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html) como algoritmo de clasificación.\n",
        "\n",
        "Entrenen con `train` y evalúen sobre `dev` al menos 4 modelos, explorando varios algoritmos de clasificación y, si quieren, también preprocesando los textos usando  pipelines de preprocesamiento con pasos complementarios a los ya desarrollados en 4️⃣.\n",
        "\n",
        "💡Les recomendamos que comiencen probando vectorizar con [bag of words](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation) o [TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), y clasificando con cualquier algoritmo disponible en [sklearn](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html). Sin embargo, vemos positivo que exploren **CUALQUIER** enfoque: pueden probar usando grandes modelos de lenguaje como LLAMA o Mistral, o también vectorizando con vectores contextuales como los *sentence transformers* usados en el ejercicio 3️⃣. En [HuggingFace](https://huggingface.co/) pueden encontrar muchísimos modelos para probar.\n",
        "\n",
        "💡Tengan en cuenta que si usan un pipeline de preprocesamiento para procesar los textos al entrenar, también tendrán que usarlo para transformar los textos al predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de referencia la siguiente tabla enumer alos experimentos que nos proponemos realizar de aquí en adelante:\n",
        "\n",
        "|vectors | model |\n",
        "| ----\t | ------|\n",
        "| BoW    | SVM   |\n",
        "| TF-IDF | SVM   |\n",
        "|BoW     |MLPClassifier|\n",
        "|TF-IDF  |MLPClassifier|\n",
        "|TF-IDF + SMOTE |SVM|\n",
        "|TF-IDF + SMOTE |MLPClassifier|\n",
        "|SentenceTransformers |SVM|\n",
        "|SentenceTransformers |MLPClassifier|\n"
      ],
      "metadata": {
        "id": "Ifq-p2HrDtZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Bow + SVM\n",
        "\n",
        "El siguiente modelo combina Bag-of-Words con un modelo SVM."
      ],
      "metadata": {
        "id": "sGzm1moj5Xu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lSQOhTGK2hpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b4c608-84d9-46f6-8462-d711108b1e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 33.49\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.58      1.00      0.73       529\n",
            "      becquer       1.00      0.16      0.27       370\n",
            "martin_fierro       0.00      0.00      0.00        72\n",
            "\n",
            "     accuracy                           0.60       971\n",
            "    macro avg       0.53      0.39      0.33       971\n",
            " weighted avg       0.70      0.60      0.50       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "clf = SVC() # Prueben acá con varios modelos\n",
        "\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* El modelo se sobre ajusta a los textos de quiroga con un alto recall a costa de una baja precision. Esto es esperable de un modelo sencillo, con un dataset tan desbalanceado.\n",
        "* No se reconoce ningún ejemplo de la clase martin_fierro. Esto es esperable también ya que se tienen muy pocos ejemplos (72).\n",
        "* En resumen el modelo no es bueno"
      ],
      "metadata": {
        "id": "Vfp1UtrFjahL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. TF-IDF + SVM\n",
        "\n",
        "El siguiente modelo combina TF-IDF, que es una estrategia de vectorización complementaria a BoW que permite obtener mejores resultados, sobre todo al considerar palabras menos frecuentes, con un modelo SVM."
      ],
      "metadata": {
        "id": "4ElZrp-15zLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "tf_idf = TfidfTransformer(use_idf=True)\n",
        "clf = SVC() # Prueben acá con varios modelos\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "id": "rZVdQ4BRW0aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93cb42a-d1d4-495f-833f-77653ff9d9f8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 47.7\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.69      0.90      0.78       529\n",
            "      becquer       0.75      0.58      0.65       370\n",
            "martin_fierro       0.00      0.00      0.00        72\n",
            "\n",
            "     accuracy                           0.71       971\n",
            "    macro avg       0.48      0.49      0.48       971\n",
            " weighted avg       0.66      0.71      0.67       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Con TF-IDF se obtienen mejores resultados, en particular tanto la precision como el recall se encuentran más balanceados entre las clases dominantes (quiroga y becquer).\n",
        "* Persiste la no identificación de los textos de martin_fierro"
      ],
      "metadata": {
        "id": "-csRp_9HkTRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. BoW + MLP Classifier\n",
        "\n",
        "El siguiente modelo combina BoW, con un modelo de redes neuronales, capaz de sobre ajustarse mejor a los datos de entrenamiento."
      ],
      "metadata": {
        "id": "DwMlPxea6YQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.0001,\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=50,\n",
        "                    shuffle=True,\n",
        "                    random_state=1,\n",
        "                    verbose=True,\n",
        "                    momentum=0.9,\n",
        "                    nesterovs_momentum=True,\n",
        "                    early_stopping=True,\n",
        "                    validation_fraction=0.1)\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThnXWPMkkwkE",
        "outputId": "84f07e13-e6fd-491e-8c8f-943648c17182"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.12994493\n",
            "Validation score: 0.536424\n",
            "Iteration 2, loss = 0.55404840\n",
            "Validation score: 0.818985\n",
            "Iteration 3, loss = 0.29159150\n",
            "Validation score: 0.801325\n",
            "Iteration 4, loss = 0.18706852\n",
            "Validation score: 0.792494\n",
            "Iteration 5, loss = 0.13609585\n",
            "Validation score: 0.785872\n",
            "Iteration 6, loss = 0.10727612\n",
            "Validation score: 0.779249\n",
            "Iteration 7, loss = 0.08867490\n",
            "Validation score: 0.777042\n",
            "Iteration 8, loss = 0.07604580\n",
            "Validation score: 0.777042\n",
            "Iteration 9, loss = 0.06683892\n",
            "Validation score: 0.777042\n",
            "Iteration 10, loss = 0.05995841\n",
            "Validation score: 0.777042\n",
            "Iteration 11, loss = 0.05452054\n",
            "Validation score: 0.772627\n",
            "Iteration 12, loss = 0.05022459\n",
            "Validation score: 0.768212\n",
            "Iteration 13, loss = 0.04675281\n",
            "Validation score: 0.770419\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 46.14\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.61      0.99      0.76       529\n",
            "      becquer       0.99      0.26      0.42       370\n",
            "martin_fierro       0.64      0.12      0.21        72\n",
            "\n",
            "     accuracy                           0.65       971\n",
            "    macro avg       0.75      0.46      0.46       971\n",
            " weighted avg       0.76      0.65      0.59       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* El modelo demuestra mayor capacidad para sobre ajustar los datos, al punto que logra reconocer algunas sentencias de martin_fierro (muy poquitas).\n",
        "* Por otro se evidencia todavía un sesgo a predecir \"quiroga\" evidentemente por el desbalance de clases.\n",
        "* Si bien la red neuronal parece tener mayor capacidad de modelado que SVM no es una buena alternativa.\n",
        "* Probemos MLP con TF-IDF"
      ],
      "metadata": {
        "id": "etI0-o5mlk8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. TF-IDF + MLP Classifier\n",
        "\n",
        "El siguiente modelo combina TF-IDF (ya vimos que permite obtener mejores resultados), con un modelo de redes neuronales."
      ],
      "metadata": {
        "id": "GRaR4Tzz6vYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "tf_idf = TfidfTransformer(use_idf=True)\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.0001,\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=50,\n",
        "                    shuffle=True,\n",
        "                    random_state=1,\n",
        "                    verbose=True,\n",
        "                    momentum=0.9,\n",
        "                    nesterovs_momentum=True,\n",
        "                    early_stopping=True,\n",
        "                    validation_fraction=0.1)\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhLVobqjZJcv",
        "outputId": "86743f4d-0179-4e50-9f9b-4ade36c60139"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.19801521\n",
            "Validation score: 0.072848\n",
            "Iteration 2, loss = 1.00157398\n",
            "Validation score: 0.576159\n",
            "Iteration 3, loss = 0.77302136\n",
            "Validation score: 0.580574\n",
            "Iteration 4, loss = 0.56690765\n",
            "Validation score: 0.618102\n",
            "Iteration 5, loss = 0.39883285\n",
            "Validation score: 0.673289\n",
            "Iteration 6, loss = 0.28434121\n",
            "Validation score: 0.682119\n",
            "Iteration 7, loss = 0.20937706\n",
            "Validation score: 0.693157\n",
            "Iteration 8, loss = 0.15936651\n",
            "Validation score: 0.697572\n",
            "Iteration 9, loss = 0.12548816\n",
            "Validation score: 0.701987\n",
            "Iteration 10, loss = 0.10222102\n",
            "Validation score: 0.706402\n",
            "Iteration 11, loss = 0.08592488\n",
            "Validation score: 0.706402\n",
            "Iteration 12, loss = 0.07407344\n",
            "Validation score: 0.704194\n",
            "Iteration 13, loss = 0.06519518\n",
            "Validation score: 0.704194\n",
            "Iteration 14, loss = 0.05838758\n",
            "Validation score: 0.706402\n",
            "Iteration 15, loss = 0.05317802\n",
            "Validation score: 0.710817\n",
            "Iteration 16, loss = 0.04899312\n",
            "Validation score: 0.715232\n",
            "Iteration 17, loss = 0.04565946\n",
            "Validation score: 0.715232\n",
            "Iteration 18, loss = 0.04288519\n",
            "Validation score: 0.715232\n",
            "Iteration 19, loss = 0.04061949\n",
            "Validation score: 0.717439\n",
            "Iteration 20, loss = 0.03869362\n",
            "Validation score: 0.715232\n",
            "Iteration 21, loss = 0.03708006\n",
            "Validation score: 0.717439\n",
            "Iteration 22, loss = 0.03564629\n",
            "Validation score: 0.717439\n",
            "Iteration 23, loss = 0.03443779\n",
            "Validation score: 0.717439\n",
            "Iteration 24, loss = 0.03338803\n",
            "Validation score: 0.724062\n",
            "Iteration 25, loss = 0.03246500\n",
            "Validation score: 0.728477\n",
            "Iteration 26, loss = 0.03167890\n",
            "Validation score: 0.730684\n",
            "Iteration 27, loss = 0.03094159\n",
            "Validation score: 0.737307\n",
            "Iteration 28, loss = 0.03029020\n",
            "Validation score: 0.737307\n",
            "Iteration 29, loss = 0.02974803\n",
            "Validation score: 0.737307\n",
            "Iteration 30, loss = 0.02920771\n",
            "Validation score: 0.737307\n",
            "Iteration 31, loss = 0.02872173\n",
            "Validation score: 0.741722\n",
            "Iteration 32, loss = 0.02831222\n",
            "Validation score: 0.741722\n",
            "Iteration 33, loss = 0.02792536\n",
            "Validation score: 0.743929\n",
            "Iteration 34, loss = 0.02757979\n",
            "Validation score: 0.743929\n",
            "Iteration 35, loss = 0.02729291\n",
            "Validation score: 0.743929\n",
            "Iteration 36, loss = 0.02693017\n",
            "Validation score: 0.743929\n",
            "Iteration 37, loss = 0.02666225\n",
            "Validation score: 0.746137\n",
            "Iteration 38, loss = 0.02644206\n",
            "Validation score: 0.750552\n",
            "Iteration 39, loss = 0.02616837\n",
            "Validation score: 0.748344\n",
            "Iteration 40, loss = 0.02596117\n",
            "Validation score: 0.748344\n",
            "Iteration 41, loss = 0.02575110\n",
            "Validation score: 0.750552\n",
            "Iteration 42, loss = 0.02558907\n",
            "Validation score: 0.757174\n",
            "Iteration 43, loss = 0.02538675\n",
            "Validation score: 0.752759\n",
            "Iteration 44, loss = 0.02524385\n",
            "Validation score: 0.754967\n",
            "Iteration 45, loss = 0.02508598\n",
            "Validation score: 0.754967\n",
            "Iteration 46, loss = 0.02495800\n",
            "Validation score: 0.750552\n",
            "Iteration 47, loss = 0.02485950\n",
            "Validation score: 0.768212\n",
            "Iteration 48, loss = 0.02475669\n",
            "Validation score: 0.759382\n",
            "Iteration 49, loss = 0.02459294\n",
            "Validation score: 0.763797\n",
            "Iteration 50, loss = 0.02446816\n",
            "Validation score: 0.763797\n",
            "F-Score macro: 60.1\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.82      0.88      0.85       529\n",
            "      becquer       0.77      0.83      0.80       370\n",
            "martin_fierro       1.00      0.08      0.15        72\n",
            "\n",
            "     accuracy                           0.80       971\n",
            "    macro avg       0.86      0.60      0.60       971\n",
            " weighted avg       0.82      0.80      0.78       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Resultados mucho mejores y balanceados para Quiroga y Becquer\n",
        "* Aun no resolvemos el problema con martin_fierro"
      ],
      "metadata": {
        "id": "_-miPDPnrlsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. TF-IDF + SMOTE + MLP Classifier\n",
        "\n",
        "El principal problema que tienen hasta ahora los modelos entrenados, es que no son capaces de modelar con cierto grado de equidad las diferentes clases. En particular son muy buenos prediciendo textos de la clase \"Quiroga\", mediocres prediciendo textos de la clase \"Becquer\" y muy malos prediciendo los textos de la clase \"Martin Fierro\". Esto se puede deber a que el corpus se encuentra desbalanceado, con muy pocos ejemplos de estas dos últimas clases.\n",
        "\n",
        "Una forma de solventar este problema, es mediante técnicas de undersampling/oversampling, para balancear el dataset. En el siguiente experimento utilizamos SMOTE de `imblearn` para entrenar un modelo TF-IDF + MLP Classifier sobre un dataset más balanceado.\n"
      ],
      "metadata": {
        "id": "-gUi4mSQ7ef7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def featurize_model_5(corpus_sentences):\n",
        "  features = bow_vectorizer.fit_transform(corpus_sentences) # Se vectorizan los textos de train con BoW\n",
        "  features = tf_idf.fit_transform(features)  # Se mejoran con TF-IDF\n",
        "  return features\n",
        "\n",
        "def train_model_5(corpus_sentences_train, corpus_authors_train):\n",
        "\n",
        "  # Setup\n",
        "  bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "  tf_idf = TfidfTransformer(use_idf=True)\n",
        "\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=0.0001,\n",
        "                      batch_size='auto',\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=0.001,\n",
        "                      max_iter=100,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      verbose=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      validation_fraction=0.1)\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "  training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Train model 5\n",
        "model_5 = train_model_5(corpus_sentences_train, corpus_authors_train)\n",
        "\n",
        "# Eval model 5\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = model_5.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8kWrlVE-qlp",
        "outputId": "2f194964-c56d-478d-8412-9d49c72efb0b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.06232207\n",
            "Validation score: 0.423752\n",
            "Iteration 2, loss = 0.79477710\n",
            "Validation score: 0.796221\n",
            "Iteration 3, loss = 0.51857686\n",
            "Validation score: 0.851552\n",
            "Iteration 4, loss = 0.33732659\n",
            "Validation score: 0.866397\n",
            "Iteration 5, loss = 0.23591078\n",
            "Validation score: 0.887989\n",
            "Iteration 6, loss = 0.17978490\n",
            "Validation score: 0.894737\n",
            "Iteration 7, loss = 0.14581278\n",
            "Validation score: 0.904184\n",
            "Iteration 8, loss = 0.12342339\n",
            "Validation score: 0.910931\n",
            "Iteration 9, loss = 0.10762175\n",
            "Validation score: 0.914980\n",
            "Iteration 10, loss = 0.09600583\n",
            "Validation score: 0.909582\n",
            "Iteration 11, loss = 0.08711447\n",
            "Validation score: 0.910931\n",
            "Iteration 12, loss = 0.08019881\n",
            "Validation score: 0.904184\n",
            "Iteration 13, loss = 0.07468790\n",
            "Validation score: 0.900135\n",
            "Iteration 14, loss = 0.07017213\n",
            "Validation score: 0.860999\n",
            "Iteration 15, loss = 0.06650776\n",
            "Validation score: 0.851552\n",
            "Iteration 16, loss = 0.06342872\n",
            "Validation score: 0.850202\n",
            "Iteration 17, loss = 0.06082376\n",
            "Validation score: 0.850202\n",
            "Iteration 18, loss = 0.05861617\n",
            "Validation score: 0.850202\n",
            "Iteration 19, loss = 0.05668848\n",
            "Validation score: 0.850202\n",
            "Iteration 20, loss = 0.05498454\n",
            "Validation score: 0.850202\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 69.5\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.84      0.82      0.83       529\n",
            "      becquer       0.75      0.83      0.79       370\n",
            "martin_fierro       0.61      0.38      0.47        72\n",
            "\n",
            "     accuracy                           0.79       971\n",
            "    macro avg       0.73      0.68      0.70       971\n",
            " weighted avg       0.79      0.79      0.79       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Hermoso"
      ],
      "metadata": {
        "id": "9c5LkNibrrA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Sentence Transformers + SMOTE + SVM"
      ],
      "metadata": {
        "id": "Jk6ZwxXg8RgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def featurize_model_6(corpus_sentences, model_vectorize):\n",
        "  features = model_vectorize.encode(corpus_sentences, normalize_embeddings=True)\n",
        "  return features\n",
        "\n",
        "def train_model_6(corpus_sentences_train, corpus_authors_train, model_vectorize):\n",
        "  clf = SVC() # Prueben acá con varios modelos\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = featurize_model_6(corpus_sentences_train, model_vectorize)\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  # 3. Fit model\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Para vectorize\n",
        "model_vectorize = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "# Train model 6\n",
        "model_6 = train_model_6(corpus_sentences_train, corpus_authors_train, model_vectorize)\n",
        "\n",
        "# 3. Eval Modelo\n",
        "dev_features = featurize_model_6(corpus_sentences_dev, model_vectorize)\n",
        "prediction = model_6.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJE_btqD8bBP",
        "outputId": "36dc8f76-5bae-421f-f6b1-013708fcd573"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 85.48\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.93      0.89       529\n",
            "      becquer       0.90      0.80      0.85       370\n",
            "martin_fierro       0.83      0.82      0.83        72\n",
            "\n",
            "     accuracy                           0.87       971\n",
            "    macro avg       0.86      0.85      0.85       971\n",
            " weighted avg       0.87      0.87      0.87       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**"
      ],
      "metadata": {
        "id": "xziCDTzAAk1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def featurize_model_7(corpus_sentences, model_vectorize):\n",
        "  features = model_vectorize.encode(corpus_sentences, normalize_embeddings=True)\n",
        "  return features\n",
        "\n",
        "def train_model_7(corpus_sentences_train, corpus_authors_train, model_vectorize):\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=0.0001,\n",
        "                      batch_size='auto',\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=0.001,\n",
        "                      max_iter=50,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      verbose=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      validation_fraction=0.1)\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = model.encode(corpus_sentences_train, normalize_embeddings=True)\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Para vectorize\n",
        "model_vectorize = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "# Train model 7\n",
        "model_7 = train_model_7(corpus_sentences_train, corpus_authors_train, model_vectorize)\n",
        "\n",
        "# 3. Eval Modelo\n",
        "dev_features = featurize_model_6(corpus_sentences_dev, model_vectorize)\n",
        "prediction = model_7.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHQMpNhjAqX2",
        "outputId": "2c8a6c5f-7103-4d6a-82b0-25fc317f3bdd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.07346558\n",
            "Validation score: 0.705803\n",
            "Iteration 2, loss = 0.98381915\n",
            "Validation score: 0.790823\n",
            "Iteration 3, loss = 0.87534139\n",
            "Validation score: 0.800270\n",
            "Iteration 4, loss = 0.76244772\n",
            "Validation score: 0.801619\n",
            "Iteration 5, loss = 0.66241874\n",
            "Validation score: 0.807018\n",
            "Iteration 6, loss = 0.58138941\n",
            "Validation score: 0.839406\n",
            "Iteration 7, loss = 0.52062089\n",
            "Validation score: 0.848853\n",
            "Iteration 8, loss = 0.47123973\n",
            "Validation score: 0.859649\n",
            "Iteration 9, loss = 0.43545546\n",
            "Validation score: 0.854251\n",
            "Iteration 10, loss = 0.40727798\n",
            "Validation score: 0.870445\n",
            "Iteration 11, loss = 0.38169067\n",
            "Validation score: 0.866397\n",
            "Iteration 12, loss = 0.36258079\n",
            "Validation score: 0.875843\n",
            "Iteration 13, loss = 0.34320657\n",
            "Validation score: 0.885290\n",
            "Iteration 14, loss = 0.32929227\n",
            "Validation score: 0.892038\n",
            "Iteration 15, loss = 0.31589525\n",
            "Validation score: 0.901484\n",
            "Iteration 16, loss = 0.30321333\n",
            "Validation score: 0.905533\n",
            "Iteration 17, loss = 0.29305392\n",
            "Validation score: 0.906883\n",
            "Iteration 18, loss = 0.28460352\n",
            "Validation score: 0.901484\n",
            "Iteration 19, loss = 0.27513220\n",
            "Validation score: 0.905533\n",
            "Iteration 20, loss = 0.26873580\n",
            "Validation score: 0.908232\n",
            "Iteration 21, loss = 0.26034123\n",
            "Validation score: 0.913630\n",
            "Iteration 22, loss = 0.25463913\n",
            "Validation score: 0.908232\n",
            "Iteration 23, loss = 0.24747563\n",
            "Validation score: 0.910931\n",
            "Iteration 24, loss = 0.24177001\n",
            "Validation score: 0.913630\n",
            "Iteration 25, loss = 0.23727225\n",
            "Validation score: 0.906883\n",
            "Iteration 26, loss = 0.23464602\n",
            "Validation score: 0.909582\n",
            "Iteration 27, loss = 0.22744651\n",
            "Validation score: 0.912281\n",
            "Iteration 28, loss = 0.22370049\n",
            "Validation score: 0.909582\n",
            "Iteration 29, loss = 0.21895205\n",
            "Validation score: 0.908232\n",
            "Iteration 30, loss = 0.21651430\n",
            "Validation score: 0.913630\n",
            "Iteration 31, loss = 0.21225264\n",
            "Validation score: 0.905533\n",
            "Iteration 32, loss = 0.20828550\n",
            "Validation score: 0.912281\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 83.0\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.88      0.88      0.88       529\n",
            "      becquer       0.84      0.80      0.82       370\n",
            "martin_fierro       0.71      0.89      0.79        72\n",
            "\n",
            "     accuracy                           0.85       971\n",
            "    macro avg       0.81      0.86      0.83       971\n",
            " weighted avg       0.85      0.85      0.85       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**"
      ],
      "metadata": {
        "id": "SuiqsvFKAln9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# import numpy as np\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# # Setup\n",
        "# bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "# tf_idf = TfidfTransformer(use_idf=True)\n",
        "# clf = SVC() # Prueben acá con varios modelos\n",
        "\n",
        "# # 1. Fit Modelo\n",
        "# training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "# training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "\n",
        "# # 2. Apply SMOTE to the training set\n",
        "# smote = SMOTE(random_state=42)\n",
        "# training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "# clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# # 3. Eval Modelo\n",
        "# dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "# dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "# prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "# print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "# print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "id": "SOulGBpjNboc"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-U00FBqJfE6"
      },
      "source": [
        "### 7️⃣Evaluación final de modelos en el conjunto de evaluación (test)\n",
        "\n",
        "Como última actividad del laboratorio, elijan los tres modelos que mejores predicciones hayan logrado sobre `dev` y evalúenlos sobre `test`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtFEgAtuChgZ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. TF-IDF + SMOTE + MLP Classifier"
      ],
      "metadata": {
        "id": "ZMtkUktpCiNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = bow_vectorizer.transform(corpus_sentences_test) # Se vectorizan los textos de dev con BoW\n",
        "test_features = tf_idf.fit_transform(test_features)  # Se mejoran con TF-IDF\n",
        "prediction = model_5.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKuoSZ2WNcai",
        "outputId": "2ffc9f9f-505e-4184-fd74-9d0e7a462de4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 76.61\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.85      0.86       530\n",
            "      becquer       0.78      0.84      0.81       370\n",
            "martin_fierro       0.75      0.55      0.63        71\n",
            "\n",
            "     accuracy                           0.82       971\n",
            "    macro avg       0.80      0.75      0.77       971\n",
            " weighted avg       0.82      0.82      0.82       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Sentence Transformers + SMOTE + SVM\n",
        "\n"
      ],
      "metadata": {
        "id": "4cf24Ol8HKD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = featurize_model_6(corpus_sentences_test, model_vectorize)\n",
        "prediction = model_6.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dmRYsUAHKRn",
        "outputId": "61f03170-4e57-46a7-8a04-d9c76ce43c5d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 86.6\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.93      0.89       530\n",
            "      becquer       0.88      0.77      0.82       370\n",
            "martin_fierro       0.86      0.90      0.88        71\n",
            "\n",
            "     accuracy                           0.87       971\n",
            "    macro avg       0.87      0.87      0.87       971\n",
            " weighted avg       0.87      0.87      0.87       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Sentence Transformers + SMOTE + MLP Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "_Vg8ghSlIHo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = featurize_model_7(corpus_sentences_test, model_vectorize)\n",
        "prediction = model_7.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhggAi27IHzj",
        "outputId": "9e5e7ba1-659b-43ad-fb2d-3279279afded"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 83.73\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.89      0.88       530\n",
            "      becquer       0.85      0.77      0.81       370\n",
            "martin_fierro       0.74      0.93      0.82        71\n",
            "\n",
            "     accuracy                           0.85       971\n",
            "    macro avg       0.82      0.86      0.84       971\n",
            " weighted avg       0.85      0.85      0.85       971\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}