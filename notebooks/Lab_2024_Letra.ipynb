{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141_gIDbKDD2"
      },
      "source": [
        "# Laboratorio de Introducci√≥n al Procesamiento de Lenguaje Natural (2024)\n",
        "\n",
        "**Grupo**: PG01\n",
        "\n",
        "**Integrantes**: Emiliano Viotti\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "En este laboratorio vamos a poner en pr√°ctica algunos de los conceptos vistos en el curso, como la *m√≠nima distancia de edici√≥n* para medir la cercan√≠a entre dos tiras, los *embeddings* como representaci√≥n sem√°ntica de los textos, los *modelos de n-gramas* para generar texto y un problema de clasificaci√≥n de tres clases.\n",
        "\n",
        "Los ejercicios que tienen que resolver est√°n se√±alizados por n√∫meros del 0Ô∏è‚É£al 7Ô∏è‚É£. Los resultados y conclusiones que surjan de esos ejercicios los van a comunicar en un informe (con un **m√°ximo de 6 p√°ginas**). En la secci√≥n \"¬øQu√© se espera del informe?\" de la letra del laboratorio van a encontrar una gu√≠a para escribirlo.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL5ExO6_R3p3"
      },
      "source": [
        "Antes que nada, vamos a instalar e importar NLTK y descargar [\"Cuentos de Amor de Locura y de Muerte\"](https://es.wikipedia.org/wiki/Cuentos_de_amor_de_locura_y_de_muerte) de Horacio Quiroga del [repositorio Gutemberg](https://www.gutenberg.org/ebooks/13507). Esto ya est√° implementado, y el libro va a quedar guardado en la variable `quiroga_raw`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KGxxKdjB2-kq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "\n",
        "!wget https://www.gutenberg.org/cache/epub/13507/pg13507.txt\n",
        "with open(\"pg13507.txt\",\"r\") as f:\n",
        "    quiroga_raw = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8D1kdiz8Zj"
      },
      "source": [
        "## 0Ô∏è‚É£Limpieza b√°sica del corpus\n",
        "\n",
        "Si examinamos el string cargado en `quiroga_raw`, vemos que al inicio y al final hay texto en ingl√©s, adem√°s de que algunos saltos de l√≠nea ocurren a mitad de las oraciones.\n",
        "\n",
        "Como primer paso, dise√±e expesiones regulares que limpien `quiroga_raw` para que:\n",
        "\n",
        "\n",
        "* quede solamente el texto que est√° entre \"#Cuentos de Amor de Locura y de Muerte#\" y \"FIN\\n\"\n",
        "* saquen aquellos saltos de l√≠nea que tengan a su derecha una palabra que comience con letra min√∫scula  \n",
        "\n",
        "El texto limpio resultante deber√° quedar guardado en la variable `quiroga`. M√°s adelante van a poder probar con otros preprocesamientos complementarios a esta limpieza b√°sica.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "xkn6j08tV9Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c933449-6613-460f-a2fc-e575c1a4167e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 312980 caracteres. \n",
            "Texto extra√≠do: 293434 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de l√≠nea en sentencias...\n",
            "Texto original: 293434 caracteres. \n",
            "Texto extra√≠do: 293434 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            "HORACIO QUIROGA\n",
            "\n",
            "1917\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#INDICE#\n",
            "\n",
            "\n",
            "Una estaci√≥n de amor\n",
            "Los ojos sombr√≠os\n",
            "El solitario\n",
            "La muerte de Isolda\n",
            "El infierno artificial\n",
            "La gallina degollada\n",
            "Los buques suicidantes\n",
            "El almohad√≥n de pluma\n",
            "El perro rabioso\n",
            "A la deriva\n",
            "La insolaci√≥n\n",
            "El alambre de p√∫a\n",
            "Los Mens√∫\n",
            "Yagua√≠\n",
            "Los pescadores de vigas\n",
            "La miel silvestre\n",
            "Nuestro primer cigarro\n",
            "La meningitis y su sombra\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#UNA ESTACION DE AMOR#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#Primavera#\n",
            "\n",
            "\n",
            "Era el martes de carnaval. N√©bel acababa de entrar en el corso, ya al oscurecer, y mientras deshac√≠a un paquete de serpentinas, mir√≥ al carruaje de delante. Extra√±ado de una cara que no hab√≠a visto la tarde anterior, pregunt√≥ a sus compa√±eros:\n",
            "\n",
            "\n",
            "--¬øQui√©n es? No parece fea.\n",
            "\n",
            "--¬°Un demonio! Es lind√≠sima. Creo que sobrina, o cosa as√≠, del doctor\n",
            "Arrizabalaga. Lleg√≥ ayer, me parece...\n",
            "\n",
            "N√©bel fij√≥ entonces atentamente los ojos en la hermosa criatura. Era una chica muy joven a√∫n, acaso no m√°s de catorce a√±os, pero completamente n√∫bil. Ten√≠a, bajo el cabello muy oscuro, un rostro de \n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignaci√≥n para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "\n",
        "# 1. Extracci√≥n del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "quiroga_text_extract_pattern = r\"#Cuentos de Amor de Locura y de Muerte#(.*)FIN\\n\"  # Expresion regular\n",
        "match = re.search(quiroga_text_extract_pattern, quiroga_raw, re.DOTALL)\n",
        "if match:\n",
        "    quiroga_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(quiroga_raw)} caracteres. \\nTexto extra√≠do: {len(quiroga_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de l√≠nea\n",
        "print(\"\\n\\nLimpiando saltos de l√≠nea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "quiroga = re.sub(breakline_lowercase_pattern, r\" \\1\", quiroga_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(quiroga_text)} caracteres. \\nTexto extra√≠do: {len(quiroga)} caracteres.\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(quiroga[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2qociraM_qD"
      },
      "source": [
        "## Primera parte: Modelos de lenguaje de n-gramas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVvptUo5Sz2t"
      },
      "source": [
        "Ahora que tenemos el texto m√°s limpio, vamos a entrenar modelos de lenguaje de n-gramas sobre √©l. Para eso, les vamos a dar definidas e implementadas las funciones:\n",
        "- `train_language_model`, que dado un natural `n` y un `corpus`, entrena un modelo de lenguaje basado en n-gramas. El par√°metro `n` tiene el valor 4 por defecto.\n",
        "- `language_model_inference`, que dado un modelo de lenguaje ya entrenado y una `prompt`, da como salida tantos tokens sucesivos como indique la variable `length`. Este largo tiene por defecto el valor 25, y la semilla `seed` tiene por defecto el valor 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hGg_YS617cXP"
      },
      "outputs": [],
      "source": [
        "def train_language_model (corpus, n = 4):\n",
        "  padded_tokens = [list(nltk.lm.preprocessing.pad_both_ends(nltk.tokenize.word_tokenize(corpus, language='spanish'), n=n))]\n",
        "\n",
        "  train, vocab = nltk.lm.preprocessing.padded_everygram_pipeline(n, padded_tokens)\n",
        "\n",
        "  language_model = nltk.lm.MLE(n)\n",
        "  language_model.fit(train,vocab)\n",
        "\n",
        "  return language_model\n",
        "\n",
        "def language_model_inference (language_model, prompt, length = 25, seed = 2024):\n",
        "  tokens = language_model.generate(length, text_seed=nltk.tokenize.word_tokenize(prompt), random_seed=seed)\n",
        "  return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmhOy1TrYA6q"
      },
      "source": [
        "### 1Ô∏è‚É£Entrenamiento e inferencia\n",
        "\n",
        "Ahora que ya est√°n definidas las funciones de entrenamiento e inferencia de los modelos de lenguaje, entrenen diferentes modelos variando:\n",
        "- el par√°metro `n`, por ejemplo con `n=3`, `n=2` y el valor por defecto, `n=4`\n",
        "- el par√°metro `corpus`, que se consigue al probar con diferentes pipelines de preprocesamieto. Pueden intentar pasar todo a min√∫sculas, sustituir los saltos de l√≠nea por espacios en blanco y todo lo que tengan ganas de probar. Tambi√©n pueden incluir el experimento de no preprocesar; es decir, que el pipeline de preprocesamiento sea la identidad.\n",
        "\n",
        "Luego, con cada uno de esos modelos, generen texto pas√°ndole como `prompt`,  \"las vacas\", \"el cielo\", y una opci√≥n m√°s que encuentren interesante. Aunque no es necesario, pueden probar otros valores de `length` y `seed`, m√°s all√° de los que est√°n por defecto.\n",
        "\n",
        "üí° Les recomendamos que cada pipeline de preprocesamiento sea una funci√≥n independiente. De esa manera, se facilita la reproducibilidad de los experimentos y su comparaci√≥n, e.g. `n=3` preprocesando con `pipeline1()`, `n=3` con `pipeline2()`, `n=2` con `pipeline1()` y `n=2` con `pipeline2()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-procesamientos a probar\n",
        "\n",
        "Se propone experimentar con los siguientes pipelines de datos, que combinan diferentes pre procesamientos y par√°metros en la etapa de vectorizaci√≥n del texto.\n",
        "\n",
        "| Nombre      | Par√°metros                                      | Objetivo                                           |\n",
        "|-------------|-------------------------------------------------|----------------------------------------------------|\n",
        "| pipeline_1  | n=4                                             | Probar el efecto de n grande                       |\n",
        "| pipeline_2  | n=3                                             | Probar el efecto reducir n                         |\n",
        "| pipeline_3  | n=2                                             | Probar el efecto reducir n                         |\n",
        "| pipeline_4  | n=5                                             | Probar el efecto n m√°s grande                      |\n",
        "| pipeline_5  | n=4, lowercase()                                | Para un n fijo, agregar convertir a min√∫sculas                     |\n",
        "| pipeline_6  | n=4, lowercase(), replace(‚Äú\\n‚Äù, ‚Äú ‚Äù)            | Para un n fijo, agregar eliminar todos los saltos                  |\n",
        "| pipeline_7  | n=4, lowercase(), replace(‚Äú\\n‚Äù, ‚Äú ‚Äù), replace(punc_symbols, ‚Äú ‚Äú) | Para un n fijo, adem√°s eliminar s√≠mbolos de puntuaci√≥n y caracteres especiales |\n"
      ],
      "metadata": {
        "id": "SsIiNkGz1Nlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_1q_yvT_IVyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69901ee7-8375-4b79-94af-c486f603e91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_1 -- Par√°metros: n=4, pre-process=None\n",
            "pipeline_2 -- Par√°metros: n=3, pre-process=None\n",
            "pipeline_3 -- Par√°metros: n=2, pre-process=None\n",
            "pipeline_4 -- Par√°metros: n=5, pre-process=None\n",
            "pipeline_5 -- Par√°metros: n=4, pre-process=lowercase()\n",
            "pipeline_6 -- Par√°metros: n=4, pre-process=[lowercase(), replace(\n",
            ", ' ')]\n",
            "pipeline_7 -- Par√°metros: n=4, pre-process=[lowercase(), replace([\n",
            ", pubc_symbols], ' ')]\n",
            "\n",
            "Generando para text='las vacas'\n",
            "model='pipeline_1' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'est√°', 'conmigo', ',', 'entonces', 'no', 'aparta', 'los', 'ojos', 'de', 'mi', 'mujer', 'y', 'yo', ',', 'con']\n",
            "model='pipeline_2' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'en', 'el', 'patio', 'y', 'Alfonso', 'la', 'llam√≥', 'en', 'silencio', '.', 'Pas√°banse', 'horas', 'sin', 'oir', 'el', 'angustioso']\n",
            "model='pipeline_3' output=['dormitaban', 'al', 'fin', 'se', 'hab√≠a', 'reforzado', 'su', 'coraz√≥n', 'siempre', 'en', 'la', 'pipa', 'y', 'el', 'perro', 'hab√≠a', 'retirado', '.', 'A', 'media', 'hora', 'en', 'tierra', ',', 'del']\n",
            "model='pipeline_4' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'los', 'pobres', 'caballos', 'pasaron', 'por', 'el', 'camino', ',', 'ellas', 'abrieron', 'los', 'ojos', 'despreciativas', ':', '--']\n",
            "model='pipeline_5' output=['estaban', 'inm√≥viles', ',', 'mirando', 'fijamente', 'el', 'verde', 'para√≠so', 'inalcanzable', '.', '--', '¬øpor', 'qu√©', '?', '¬øqu√©', 'le', 'pasa', '?', '--', 'nada', ',', 'sino', 'que', 'est√°', 'bien']\n",
            "model='pipeline_6' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', ',', 'rumiando', '.', 'Pero', 'cuando', 'est√°', 'conmigo', ',', 'entonces', 'no', 'aparta', 'los', 'ojos', 'de', 'mi', 'mujer', 'y', 'yo', ',', 'con']\n",
            "model='pipeline_7' output=['dormitaban', 'al', 'sol', 'ya', 'caliente', 'rumiando', 'Pero', 'cuando', 'los', 'pobres', 'caballos', 'pasaron', 'por', 'el', 'camino', 'ellas', 'abrieron', 'los', 'ojos', 'despreciativas', 'Son', 'los', 'caballos', 'Los', 'alambres']\n",
            "\n",
            "Generando para text='el cielo'\n",
            "model='pipeline_1' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provoc√°ronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Hab√≠a', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_2' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provoc√°ronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'no', 'vaya', 'yo', 'jam√°s', 'a', 'explicarme', 'qu√©', 'combinaciones', 'de', 'visitas', ',', 'casamientos', 'y', 'garden']\n",
            "model='pipeline_3' output=['de', 'que', 'est√°', 'todo', 'el', 'piso', '.', 'Alrededor', 'del', 'menguante', '.', 'Pero', 'yo', 'con', 'sorpresa', '.', 'Pero', '√©ste', ':', 'la', 'loma', ',', 'y', 'bajo', 'el']\n",
            "model='pipeline_4' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provoc√°ronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Hab√≠a', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_5' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provoc√°ronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'hab√≠a', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_6' output=['constantemente', 'encapotado', 'y', 'lluvioso', ',', 'provoc√°ronle', 'verdaderas', 'alucinaciones', 'de', 'perros', 'que', 'entraban', 'al', 'trote', 'por', 'la', 'portera', '.', 'Hab√≠a', 'un', 'motivo', 'real', 'para', 'este', 'temor']\n",
            "model='pipeline_7' output=['fijo', 'en', 'sequ√≠a', 'con', 'chubascos', 'de', 'cinco', 'minutos', 'se', 'descompon√≠a', 'por', 'fin', 'en', 'las', 'lagartijas', 'A√∫n', 'en', 'noviembre', 'cuando', 'ten√≠a', 'ya', 'en', 'jaque', 'a', 'todas']\n",
            "\n",
            "Generando para text='Esteban Podeley'\n",
            "model='pipeline_1' output=[',', 'peones', 'de', 'obraje', ',', 'volv√≠an', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compa√±eros', '.', 'Podeley', ',', 'cuya', 'fiebre', 'anterior', 'hab√≠a', 'tenido', 'honrado', 'y']\n",
            "model='pipeline_2' output=[',', 'm√°s', 'ansiosa', 'a√∫n', '.', 'Recurri√≥', 'entonces', 'a', 'un', 'hombre', 'discreto', '.', 'V√©ase', ':', 'Fu√≠', 'a', 'lo', 'que', 'es', 'patrimonio', 'espec√≠fico', 'de', 'los', 'corazones', 'inferiores']\n",
            "model='pipeline_3' output=['bajaron', 'tambaleantes', 'de', 'todo', 'el', 'piso', '.', 'Alrededor', 'del', 'menguante', '.', 'Pero', 'yo', 'con', 'sorpresa', '.', 'Pero', '√©ste', ':', 'la', 'loma', ',', 'y', 'bajo', 'el']\n",
            "model='pipeline_4' output=[',', 'peones', 'de', 'obraje', ',', 'volv√≠an', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compa√±eros', '.', 'Podeley', ',', 'labrador', 'de', 'madera', ',', 'tornaba', 'a', 'los']\n",
            "model='pipeline_5' output=['esperaba', 'una', 'lluvia', ',', 'y', 'salt√©', 'de', 'costado', ',', 'con', 'las', 'rodillas', 'recogidas', 'hasta', 'el', 'pecho', '.', '¬øqu√©', 'ser√≠a', '?', 'y', 'la', 'respiraci√≥n', 'tambi√©n', '...']\n",
            "model='pipeline_6' output=[',', 'peones', 'de', 'obraje', ',', 'volv√≠an', 'a', 'Posadas', 'en', 'el', '_Silex_', ',', 'con', 'quince', 'compa√±eros', '.', 'Podeley', ',', 'cuya', 'fiebre', 'anterior', 'hab√≠a', 'tenido', 'honrado', 'y']\n",
            "model='pipeline_7' output=['peones', 'de', 'obraje', 'volv√≠an', 'a', 'Posadas', 'en', 'el', '_Silex_', 'con', 'quince', 'compa√±eros', 'Podeley', 'labrador', 'de', 'madera', 'tornaba', 'a', 'los', 'nueve', 'meses', 'la', 'contrata', 'conclu√≠da', 'y']\n"
          ]
        }
      ],
      "source": [
        "#Completar con los diferentes experimentos, llamando a las funciones train_language_model y language_model_inference\n",
        "\n",
        "\"\"\"\n",
        "Experimentos a realizar:\n",
        "\n",
        "1. Variar n en [4, 3, 2]\n",
        "2. Jugar con pre-procesamientos.\n",
        "\n",
        "Pre-procesamientos:\n",
        "1. Nada\n",
        "2. lowercase\n",
        "3. replace(\\n, \" \")\n",
        "\"\"\"\n",
        "\n",
        "def pipeline_1():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=4 y sin pre-procesamiento al corpus (m√°s all√° del inicial).\n",
        "  Esto nos permite observar la capacidad del modelo cuando se toman n-gramas de a cuatro palabras, lo cual por el\n",
        "  tama√±o del corpus, es probable que genere sobre ajustes.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_1 -- Par√°metros: n={4}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_2():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=3 y sin pre-procesamiento al corpus (m√°s all√° del inicial).\n",
        "  Esto nos permite observar como el modelo gana generalidad al no sobre ajustarse tanto pero seguramente\n",
        "  pierde capacidad de generaci√≥n al tomar contexto de palabras reducido.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_2 -- Par√°metros: n={3}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=3)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_3():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=2 y sin pre-procesamiento al corpus (m√°s all√° del inicial).\n",
        "  Similar al anterior.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_3 -- Par√°metros: n={2}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=2)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_4():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=5 y sin pre-procesamiento al corpus (m√°s all√° del inicial).\n",
        "  Esto nos permite terminar de afianzar la idea de que se est√° sobre ajustando el modelo al texto provisto.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_4 -- Par√°metros: n={5}, pre-process=None\")\n",
        "  language_model = train_language_model(corpus=quiroga, n=5)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_5():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo con n=4 y lowercase al corpus\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_5 -- Par√°metros: n={4}, pre-process=lowercase()\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.lower()\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_6():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo combinando: n=4, lowercase y replace(\\n, \" \").\n",
        "\n",
        "  Al ser un texto peque√±o, pasar a min√∫sculas y eliminar saltos de l√≠nea nos permite manejar\n",
        "  varias palabras como la misma, mejorando la capacidad de comprensi√≥n de un modelo simple como n-gramas.\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_6 -- Par√°metros: n={4}, pre-process=[lowercase(), replace(\\n, ' ')]\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.replace(\"\\n\", \" \")\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "def pipeline_7():\n",
        "  \"\"\"\n",
        "  Este pipeline entrena modelo combinando: n=4, lowercase y replace(\\n, \" \").\n",
        "  \"\"\"\n",
        "  print(f\"pipeline_7 -- Par√°metros: n={4}, pre-process=[lowercase(), replace([\\n, pubc_symbols], ' ')]\")\n",
        "\n",
        "  # Pre-procesamiento\n",
        "  pre_process_corpus = quiroga.replace(\"\\n\", \" \")  # Elimino saltos de l√≠nea\n",
        "  pre_process_corpus = re.sub(r\"[^\\w\\s]\", \" \", pre_process_corpus)  # Elimino s√≠mbolos de puntuaci√≥n\n",
        "  pre_process_corpus = re.sub(r\"\\s+\", \" \", pre_process_corpus).strip()  # Elimino espacios en blanco repetidos\n",
        "\n",
        "  # Entrenamiento\n",
        "  language_model = train_language_model(corpus=pre_process_corpus, n=4)\n",
        "  return language_model\n",
        "\n",
        "\n",
        "# Generamos los language models\n",
        "models = [pipeline_1(), pipeline_2(), pipeline_3(), pipeline_4(), pipeline_5(), pipeline_6(), pipeline_7()]\n",
        "#models = [pipeline_5()]\n",
        "\n",
        "# Generamos textos\n",
        "results = []\n",
        "texts = [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]\n",
        "#texts = [\"las vacas\"]\n",
        "\n",
        "for text in texts:\n",
        "\n",
        "  print(f\"\\nGenerando para text='{text}'\")\n",
        "  text_results = []\n",
        "  for i, model in enumerate(models):\n",
        "    output_tokens = language_model_inference(language_model=model, prompt=text)\n",
        "    model_name = f\"pipeline_{i+1}\"\n",
        "    print(f\"model='{model_name}' output={output_tokens}\")\n",
        "    results.append({\"pipeline\": model_name, \"prompt\": text, \"output\": \" \".join(output_tokens)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestro los resultados en un dataframe para visualizarlos en formato tabla\n",
        "df_1 = pd.DataFrame(results)\n",
        "df_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "EpPn6kPtu80i",
        "outputId": "c4cbe7fb-43fb-4687-f6c7-ddf8ea1e4561"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pipeline           prompt  \\\n",
              "0   pipeline_1        las vacas   \n",
              "1   pipeline_2        las vacas   \n",
              "2   pipeline_3        las vacas   \n",
              "3   pipeline_4        las vacas   \n",
              "4   pipeline_5        las vacas   \n",
              "5   pipeline_6        las vacas   \n",
              "6   pipeline_7        las vacas   \n",
              "7   pipeline_1         el cielo   \n",
              "8   pipeline_2         el cielo   \n",
              "9   pipeline_3         el cielo   \n",
              "10  pipeline_4         el cielo   \n",
              "11  pipeline_5         el cielo   \n",
              "12  pipeline_6         el cielo   \n",
              "13  pipeline_7         el cielo   \n",
              "14  pipeline_1  Esteban Podeley   \n",
              "15  pipeline_2  Esteban Podeley   \n",
              "16  pipeline_3  Esteban Podeley   \n",
              "17  pipeline_4  Esteban Podeley   \n",
              "18  pipeline_5  Esteban Podeley   \n",
              "19  pipeline_6  Esteban Podeley   \n",
              "20  pipeline_7  Esteban Podeley   \n",
              "\n",
              "                                               output  \n",
              "0   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "2   dormitaban al fin se hab√≠a reforzado su coraz√≥...  \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "4   estaban inm√≥viles , mirando fijamente el verde...  \n",
              "5   dormitaban al sol ya caliente , rumiando . Per...  \n",
              "6   dormitaban al sol ya caliente rumiando Pero cu...  \n",
              "7   constantemente encapotado y lluvioso , provoc√°...  \n",
              "8   constantemente encapotado y lluvioso , provoc√°...  \n",
              "9   de que est√° todo el piso . Alrededor del mengu...  \n",
              "10  constantemente encapotado y lluvioso , provoc√°...  \n",
              "11  constantemente encapotado y lluvioso , provoc√°...  \n",
              "12  constantemente encapotado y lluvioso , provoc√°...  \n",
              "13  fijo en sequ√≠a con chubascos de cinco minutos ...  \n",
              "14  , peones de obraje , volv√≠an a Posadas en el _...  \n",
              "15  , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hom...  \n",
              "16  bajaron tambaleantes de todo el piso . Alreded...  \n",
              "17  , peones de obraje , volv√≠an a Posadas en el _...  \n",
              "18  esperaba una lluvia , y salt√© de costado , con...  \n",
              "19  , peones de obraje , volv√≠an a Posadas en el _...  \n",
              "20  peones de obraje volv√≠an a Posadas en el _Sile...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pipeline</th>\n",
              "      <th>prompt</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al fin se hab√≠a reforzado su coraz√≥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>estaban inm√≥viles , mirando fijamente el verde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>las vacas</td>\n",
              "      <td>dormitaban al sol ya caliente rumiando Pero cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provoc√°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provoc√°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>de que est√° todo el piso . Alrededor del mengu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provoc√°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provoc√°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>constantemente encapotado y lluvioso , provoc√°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>el cielo</td>\n",
              "      <td>fijo en sequ√≠a con chubascos de cinco minutos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, m√°s ansiosa a√∫n . Recurri√≥ entonces a un hom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>pipeline_3</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>bajaron tambaleantes de todo el piso . Alreded...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>pipeline_4</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>pipeline_5</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>esperaba una lluvia , y salt√© de costado , con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19192c87-94b1-4fa4-97b4-b3f59d1efaf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e1beb1d-c8dd-4dd8-bcdc-0cb78bf3eb30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_61cc0c2a-6ea6-468e-a7ae-04dd749864b4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_61cc0c2a-6ea6-468e-a7ae-04dd749864b4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_1",
              "summary": "{\n  \"name\": \"df_1\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"pipeline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\",\n          \"pipeline_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"las vacas\",\n          \"el cielo\",\n          \"Esteban Podeley\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "* Algunos pipelines producen sentencias con \"sent√≠do\" y gramaticalmente correctas (o cerca de serlas). Este es el caso de los pipelines: pipeline_1, pipeline_2, pipeline_4 al pipeline_7.\n",
        "\n",
        "* Algunos pipelines producen sentencias con menor \"sentido\" y gramaticalmente incorrectas. Por ejemplo los pipelines: pipeline_2 y pipeline_3. Se puede observar as√≠ que el efecto de reducir el N en los n-gramas tiene un efecto negativo en la generaci√≥n de sentencias gramaticalmente correctas.\n",
        "\n",
        "* De lo anterior se puede deducir que tomar un N m√°s grande (N=4 o N=5) para los n-gramas tiene un efecto positivo en la generaci√≥n de sentencias gramaticalmente correctas.\n",
        "\n",
        "* Pasar a min√∫sculas no parece tener un impacto negativo en la generaci√≥n (pipeline_5). Por el contrario, se genera una sentencia bastante diferente al resto de los experimentos. Esto puede deberse a que al pasar a lowercase palabras como \"dormitaban\" y \"Dormitaban\" pasan a ser la misma, aumentando la cantidad de ejemplos en el corpus para esa palabra.\n",
        "\n",
        "* Remover los saltos de l√≠nea adicionales no parece producir un impacto positivo o negativo por si solo.\n",
        "\n",
        "* Remover los s√≠mbolos de puntuaci√≥n no parece tener un impacto positivo. Lo √∫nico que cambia es que generamos sentencias m√°s largas (hay m√°s tokens disponibles) pero podemos lograr lo mismo aumentando el par√°metro `length` en el m√©todo `language_model_inference`."
      ],
      "metadata": {
        "id": "N4OmYJgX1ebo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKpp9VVe-l-X"
      },
      "source": [
        "### 2Ô∏è‚É£ M√≠nima distancia de edici√≥n\n",
        "\n",
        "Los modelos de lenguaje que entrenaron en la parte anterior aprendieron la distribuci√≥n estad√≠stica a trav√©s de secuencias de palabras en el libro de Quiroga. Sin embargo, las inferencias que consiguieron ¬øestar√°n id√©nticas en el corpus de entrenamiento?\n",
        "\n",
        "Usando la funci√≥n `edit_distance` de NLTK encuentren, para cada tira generada en la parte anterior, las 3 oraciones del libro original que tienen la menor distancia de edici√≥n asociada (es decir, el top 3). Las oraciones del libro est√°n guardadas en la variable `quiroga_sentences`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RHzwkqTjA7pt"
      },
      "outputs": [],
      "source": [
        "quiroga_sentences = nltk.sent_tokenize(quiroga, language='spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qzxQA3Q2BJxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a817660a-2f27-4258-ceb3-b7cd1777913c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La distancia entre \"arbolada\" y \"escapada\" es 5, pero entre \"arbolada\" y \"arbolado\" es 1.\n"
          ]
        }
      ],
      "source": [
        "print(f'La distancia entre \"arbolada\" y \"escapada\" es {nltk.edit_distance(\"arbolada\", \"escapada\")}, pero entre \"arbolada\" y \"arbolado\" es {nltk.edit_distance(\"arbolada\", \"arbolado\")}.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_knn(text: str, k: int = 3, sentences: list[str] = []) -> list[str]:\n",
        "  # Obtengo distancias\n",
        "  distances = [nltk.edit_distance(text, sentence) for sentence in sentences]\n",
        "  # Obtengo indices de los K mas cercanos\n",
        "  closest_indices = np.argsort(distances)[:k]\n",
        "  closest_sentences = [sentences[i] for i in closest_indices]\n",
        "\n",
        "  return closest_sentences\n",
        "\n",
        "# Para guardar los resultados\n",
        "predictions = []\n",
        "\n",
        "for text in texts:\n",
        "\n",
        "  print(f\"\\n\\nGenerando para text='{text}'\")\n",
        "  for i, model in enumerate(models):\n",
        "    # Genero texto\n",
        "    model_name = f\"pipeline_{i+1}\"\n",
        "    output_tokens = language_model_inference(language_model=model, prompt=text)\n",
        "    output_text = \" \".join(output_tokens)\n",
        "\n",
        "    print(f\"model='{model_name}' output='{output_text}'\")\n",
        "\n",
        "    # Obtengo top_k vectores mas cercanos\n",
        "    nearest_k = get_knn(text=output_text, k=3, sentences=quiroga_sentences)\n",
        "    print(f\"neighbors={nearest_k}\")\n",
        "\n",
        "    for idx, neighbor_vec in enumerate(nearest_k):\n",
        "      # Guardo resultados\n",
        "      predictions.append({\n",
        "                  \"prompt\": text,\n",
        "                  \"model_name\": model_name,\n",
        "                  \"output_text\": output_text,\n",
        "                  \"idx\": idx+1,\n",
        "                  \"neighborh\": neighbor_vec\n",
        "              })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnB7arlINSKX",
        "outputId": "26be3b00-55ce-481c-bc4c-e4853226a442"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Generando para text='las vacas'\n",
            "model='pipeline_1' output='dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con'\n",
            "neighbors=['Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.', 'Arrizabalaga y la se√±ora se re√≠an, volvi√©ndose a menudo, y la joven no apartaba casi sus ojos de N√©bel.', 'El caballo, por mayor intimidad de trato, es sensiblemente m√°s afecto al hombre que la vaca.']\n",
            "model='pipeline_2' output='dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso'\n",
            "neighbors=['Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de dormir la siesta, cruz√≥ el patio y Alfonso la llam√≥ en silencio con la mano.', 'Al bajar el sol volvieron, pero Berta quiso saludar un momento a sus vecinas de enfrente.', 'Volvi√≥ a su cobertizo, y en el camino sinti√≥ un ligero cosquilleo en la espalda.']\n",
            "model='pipeline_3' output='dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del'\n",
            "neighbors=['Como las fieras amaestradas, los perros conocen el menor indicio de borrachera en su amo.', 'Por lo dem√°s, se alternaban con su hija para ir a ver a la enferma.', 'Benincasa se observaba muy de cerca en los pies la placa l√≠vida de la mordedura.']\n",
            "model='pipeline_4' output='dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --'\n",
            "neighbors=['Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\\n\\n--Son los caballos.', 'Tarde ya, cuando el sol acababa de entrarse, los dos caballos se acordaron del ma√≠z y emprendieron el regreso.', 'Luis Mar√≠a, por su parte, se permite pasarle la mano por la barbilla cuando entra y ella est√° sentada de espaldas.']\n",
            "model='pipeline_5' output='estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien'\n",
            "neighbors=['Las vacas estaban inm√≥viles, mirando fijamente el verde para√≠so inalcanzable.', 'Ayestarain torn√≥ a mirarme fijamente, pero esta vez cre√≠ notar un vago, vagu√≠simo dejo de amargura.', 'Esta vez Vezzera me mir√≥ fijamente a los ojos:\\n\\n--¬øPor qu√© no quieres ir?']\n",
            "model='pipeline_6' output='dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con'\n",
            "neighbors=['Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.', 'Arrizabalaga y la se√±ora se re√≠an, volvi√©ndose a menudo, y la joven no apartaba casi sus ojos de N√©bel.', 'El caballo, por mayor intimidad de trato, es sensiblemente m√°s afecto al hombre que la vaca.']\n",
            "model='pipeline_7' output='dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres'\n",
            "neighbors=['Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\\n\\n--Son los caballos.', 'Porque, naturalmente, cuanto m√°s intensos eran los raptos de amor a su marido e hija, m√°s irritable era su humor con los monstruos.', 'Caminando, comiendo, curioseando, el alaz√°n y el malacara cruzaron la capuera hasta que un alambrado los detuvo.']\n",
            "\n",
            "\n",
            "Generando para text='el cielo'\n",
            "model='pipeline_1' output='constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros d√≠as mam√° pas√≥ crueles angustias por sus hijos que hab√≠an besado a la virolenta.', 'Verdad es que no med√≠a sino dos metros de hondura, tendi√©ndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_2' output='constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Durante tres meses consecutivos raras veces falt√≥, sin llegar yo jam√°s a explicarme qu√© combinaciones de visitas, casamientos y garden party debi√≥ hacer para no ser sospechada.', 'Sobre el cielo p√°lido y fr√≠o, sus siluetas se destacaban en negro, en mansa y cabizbaja pareja, el malacara delante, el alaz√°n detr√°s.']\n",
            "model='pipeline_3' output='de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el'\n",
            "neighbors=['aqu√≠ est√° el buena pieza de tu Eduardo... ¬°Te va a sacar canas este hijo, ya ver√°s!', 'Pero sus ojos, as√≠, llenaban aquel semblante en flor con la luz de su belleza.', '--Bueno; haga lo posible porque no entre, porque si pasa se va a lastimar.']\n",
            "model='pipeline_4' output='constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros d√≠as mam√° pas√≥ crueles angustias por sus hijos que hab√≠an besado a la virolenta.', 'Verdad es que no med√≠a sino dos metros de hondura, tendi√©ndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_5' output='constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros d√≠as mam√° pas√≥ crueles angustias por sus hijos que hab√≠an besado a la virolenta.', 'Se sent√≥ a su lado, y en balde la madre esper√≥ a que se dijeran algo: no hac√≠an sino mirarse y reir.']\n",
            "model='pipeline_6' output='constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor'\n",
            "neighbors=['Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.', 'Seguramente en los primeros d√≠as mam√° pas√≥ crueles angustias por sus hijos que hab√≠an besado a la virolenta.', 'Verdad es que no med√≠a sino dos metros de hondura, tendi√©ndose en larga escarpa por un lado, a modo de tajamar.']\n",
            "model='pipeline_7' output='fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas'\n",
            "neighbors=['Costeando por adentro el monte del fondo, a doscientos metros a√∫n, el toro avanzaba hacia el avenal.', 'Esto crea as√≠ un caso de sicolog√≠a singular de que un novelista podr√≠a sacar alg√∫n partido.', 'Pero a los treinta y cinco a√±os prosegu√≠a en su pieza, aderezada en taller bajo la ventana.']\n",
            "\n",
            "\n",
            "Generando para text='Esteban Podeley'\n",
            "model='pipeline_1' output=', peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y'\n",
            "neighbors=['Durante el viaje hab√≠a sido un excelente compa√±ero, admirando por su cuenta y riesgo, y hablando poco.', 'Reverberaba ahora delante de ellos un peque√±o p√°ramo de greda que ni siquiera se hab√≠a intentado arar.', 'Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de baile estaba frecuentado por los muertos diarios de una epidemia.']\n",
            "model='pipeline_2' output=', m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores'\n",
            "neighbors=['Pero el calor creciente les hizo presto abandonar aqu√©l por la sombra de los corredores.', 'Pero est√° perfectamente enterada de lo que pas√≥, por los cuentos posteriores.', 'Los perros, que en la ma√±ana no hab√≠an dejado un momento a su patr√≥n, se quedaron en los corredores.']\n",
            "model='pipeline_3' output='bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el'\n",
            "neighbors=['Llor√≥ largamente todo su espanto callado, redoblando el llanto a la menor tentativa de caricia.', 'Pasaban casi todo el d√≠a sentados frente al cerco, abandonados de toda remota caricia.', 'Anim√°banse s√≥lo al comer, cuando ve√≠an colores brillantes u o√≠an truenos.']\n",
            "model='pipeline_4' output=', peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los'\n",
            "neighbors=['El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.', 'Apenas la conozco, vuelvo a repetirle, y no creo que ella se acuerde de haberme visto jam√°s.', 'Romper, es palabra corta y f√°cil; pero comenzarlo...\\n\\nNos hab√≠amos sentado y no habl√°bamos.']\n",
            "model='pipeline_5' output='esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...'\n",
            "neighbors=['El aire faltaba, con angustia card√≠aca que no permit√≠a concluir la respiraci√≥n.', 'Desde las orillas bordeadas de negros bloques de basalto, asciende el bosque, negro tambi√©n.', 'El cielo, al poniente, se abr√≠a ahora en pantalla de oro, y el r√≠o se hab√≠a coloreado tambi√©n.']\n",
            "model='pipeline_6' output=', peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y'\n",
            "neighbors=['Durante el viaje hab√≠a sido un excelente compa√±ero, admirando por su cuenta y riesgo, y hablando poco.', 'Reverberaba ahora delante de ellos un peque√±o p√°ramo de greda que ni siquiera se hab√≠a intentado arar.', 'Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de baile estaba frecuentado por los muertos diarios de una epidemia.']\n",
            "model='pipeline_7' output='peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y'\n",
            "neighbors=['Sobre la honda ligadura del pa√±uelo, la carne desbordaba como una monstruosa morcilla.', 'Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de baile estaba frecuentado por los muertos diarios de una epidemia.', 'Durante el viaje hab√≠a sido un excelente compa√±ero, admirando por su cuenta y riesgo, y hablando poco.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo DataFrame\n",
        "df_2 = pd.DataFrame(predictions, columns=[\"prompt\", \"model_name\", \"output_text\", \"idx\", \"neighborh\"])\n",
        "df_2"
      ],
      "metadata": {
        "id": "Sd0-xWGDBlfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4e5469cb-4ff6-4000-f3ee-94bdf396a3fb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             prompt  model_name  \\\n",
              "0         las vacas  pipeline_1   \n",
              "1         las vacas  pipeline_1   \n",
              "2         las vacas  pipeline_1   \n",
              "3         las vacas  pipeline_2   \n",
              "4         las vacas  pipeline_2   \n",
              "..              ...         ...   \n",
              "58  Esteban Podeley  pipeline_6   \n",
              "59  Esteban Podeley  pipeline_6   \n",
              "60  Esteban Podeley  pipeline_7   \n",
              "61  Esteban Podeley  pipeline_7   \n",
              "62  Esteban Podeley  pipeline_7   \n",
              "\n",
              "                                          output_text  idx  \\\n",
              "0   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "2   dormitaban al sol ya caliente , rumiando . Per...    3   \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "4   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "..                                                ...  ...   \n",
              "58  , peones de obraje , volv√≠an a Posadas en el _...    2   \n",
              "59  , peones de obraje , volv√≠an a Posadas en el _...    3   \n",
              "60  peones de obraje volv√≠an a Posadas en el _Sile...    1   \n",
              "61  peones de obraje volv√≠an a Posadas en el _Sile...    2   \n",
              "62  peones de obraje volv√≠an a Posadas en el _Sile...    3   \n",
              "\n",
              "                                            neighborh  \n",
              "0   Pero cuando est√° conmigo, entonces no aparta l...  \n",
              "1   Arrizabalaga y la se√±ora se re√≠an, volvi√©ndose...  \n",
              "2   El caballo, por mayor intimidad de trato, es s...  \n",
              "3   Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...  \n",
              "4   Al bajar el sol volvieron, pero Berta quiso sa...  \n",
              "..                                                ...  \n",
              "58  Reverberaba ahora delante de ellos un peque√±o ...  \n",
              "59  Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de ...  \n",
              "60  Sobre la honda ligadura del pa√±uelo, la carne ...  \n",
              "61  Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de ...  \n",
              "62  Durante el viaje hab√≠a sido un excelente compa...  \n",
              "\n",
              "[63 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>model_name</th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighborh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Pero cuando est√° conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Arrizabalaga y la se√±ora se re√≠an, volvi√©ndose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>El caballo, por mayor intimidad de trato, es s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Al bajar el sol volvieron, pero Berta quiso sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>Reverberaba ahora delante de ellos un peque√±o ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sobre la honda ligadura del pa√±uelo, la carne ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>Me despert√©, y volv√≠ a so√±ar: el tal sal√≥n de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Esteban Podeley</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>Durante el viaje hab√≠a sido un excelente compa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows √ó 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e12c6c71-6ca2-4a28-a0aa-10b9f9d10012');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a08a1b3-8325-41fc-ae41-ea8a043c1a43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_60ca1286-b960-4f61-9b64-9f5582634840\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60ca1286-b960-4f61-9b64-9f5582634840 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_2",
              "summary": "{\n  \"name\": \"df_2\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"las vacas\",\n          \"el cielo\",\n          \"Esteban Podeley\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\",\n          \"pipeline_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighborh\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"Apenas la conozco, vuelvo a repetirle, y no creo que ella se acuerde de haberme visto jam\\u00e1s.\",\n          \"Se sent\\u00f3 a su lado, y en balde la madre esper\\u00f3 a que se dijeran algo: no hac\\u00edan sino mirarse y reir.\",\n          \"Costeando por adentro el monte del fondo, a doscientos metros a\\u00fan, el toro avanzaba hacia el avenal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "- Observando el top 3 de oraciones m√°s cercanas (en base a la distancia de edici√≥n), se puede ver que para algunos preprocesamientos el top 3 de oraciones incluye una oraci√≥n bastante similar a la generada por el modelo, mientras que en otros casos no.\n",
        "\n",
        "- En particular para los pipelines pipeline_2 y pipeline_3 el top 3 de sentencias NO incluye una sentencia que a simple vista sea similar al texto generado. Estos pipelines tienen en com√∫n que toman un N peque√±o para la vectorizaci√≥n en n-gramas (N=3, N=2).\n",
        "\n",
        "- Los siguientes pipelines, producen oraciones que a simple vista coinciden en gran medida con alguna de las oraciones en el top 3: pipeline_1, pipeline_4, pipeline_5, pipeline_6 y pipeline_7. Estos pipelines tienen en com√∫n el uso de un N moderado para la generaci√≥n de n-gramas (N=4, N=5).\n",
        "\n",
        "- Pasar a min√∫sculas, remover s√≠mbolos de puntuaci√≥n y saltos de l√≠nea, no parece afectar negativamente las distancias. En particular se aprecia al menos una oraci√≥n dentro del top 3 muy similar o id√©ntica al texto generado, cuando se utilizan estos preprocesamientos.\n",
        "\n",
        "Por otro lado, es interesante entender en el contexto del texto original, a que fragmento se puede estar sobre ajustando el texto generado. En particular seleccionando el texto generado con el **pipeline_6**, vemos que el inicio de la oraci√≥n se encuentra textual en el siguiente pasaje:\n",
        "\n",
        "> Detr√°s de √©l, **las vacas**\n",
        "> dormitaban al sol ya caliente, rumiando.\n",
        ">\n",
        "> Pero cuando los pobres caballos pasaron por el camino, ellas abrieron\n",
        ">los ojos despreciativas:\n",
        "\n",
        "Basado en estas observaciones y en las observaciones de la parte anterior, parecer√≠a que el **pipeline_6** puede ser un muy buen pipeline a utilizar para el resto de los experimentos (pipeline \"ganador\"). No obstante, notar que estamos optando por un pipeline, por su capacidad de sobre ajustar al texto generado (esto podr√≠a no ser la mejor m√©trica de evaluaci√≥n)."
      ],
      "metadata": {
        "id": "F-IQLKX-SKtu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2_OrMKFD7l_"
      },
      "source": [
        "### 3Ô∏è‚É£ Modelo neuronal para capturar la sem√°ntica\n",
        "\n",
        "Ahora repitan el mismo procedimiento de la parte anterior pero usando el [modelo neuronal E5](https://huggingface.co/intfloat/multilingual-e5-large), basado en la arquitectura BERT, que intenta representar el significado de un texto en un vector de largo fijo.\n",
        "\n",
        "Para hallar los tres vectores m√°s cercanos a un vector dado, utilicen el algoritmo [Nearest Neighbors implementado en Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html).\n",
        "\n",
        "üí°Van a tener que codificar (con vectores) tanto lo generado por el modelo de n-gramas como todas las oraciones guardadas en `quiroga_sentences`.\n",
        "\n",
        "üí°Aseg√∫rense de estar usando una GPU en el entorno de ejecuci√≥n de Google Colab, para poder acelerar el procesamiento con E5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "GoafBjWoe1E1"
      },
      "outputs": [],
      "source": [
        "#Completar con la instalaci√≥n de las bibliotecas necesarias,\n",
        "#el c√≥digo que halla la representaci√≥n vectorial de los textos\n",
        "#y el algoritmo para hallar el top 3 con Nearest Neighbors.\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "  last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "  return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def generate_vector_from_text(batch, model, tokenizer, device):\n",
        "  \"\"\"\n",
        "  Inspirado por https://discuss.huggingface.co/t/is-transformers-using-gpu-by-default/8500/2\n",
        "  en como manejar en GPU los vectrores resolviendo algunos problemas que tuve con Colab.\n",
        "  \"\"\"\n",
        "\n",
        "  # Tokenizo el batch\n",
        "  batch_dict = tokenizer(batch, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "  with torch.no_grad():  # Deshabilito gradient calculation\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "      embeddings_cpu = embeddings.cpu()  # Muevo embeddings a CPU para liberar memoria GPU\n",
        "\n",
        "  # Limpio memoria\n",
        "  del outputs, embeddings, batch_dict\n",
        "  torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "  return embeddings_cpu\n",
        "\n",
        "def generate_vectors_from_texts(texts, model, tokenizer, device):\n",
        "  texts_embeddings = []\n",
        "\n",
        "  # Defino data Loader para cargar eficientemente los vectores\n",
        "  batch_size = 16  # Adjust the batch size based on your memory availability\n",
        "  data_loader = DataLoader(texts, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  for batch in data_loader:\n",
        "    batch_embeddings = generate_vector_from_text(batch=batch, model=model, tokenizer=tokenizer, device=device)\n",
        "    texts_embeddings.append(batch_embeddings)\n",
        "\n",
        "  # Concatenate all embeddings after processing\n",
        "  texts_embeddings = torch.cat(texts_embeddings, dim=0)\n",
        "  return texts_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta celda generamos los vectores para todas las sentencias de\n",
        "# quiroga y para los textos de prueba\n",
        "\n",
        "# Device GPU si hay\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Init tokenizer y Modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
        "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')\n",
        "model.to(device)\n",
        "\n",
        "# 1. Texts\n",
        "#input_texts =  [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]\n",
        "input_texts = df_1[\"output\"].to_list()  # Uso todos los textos generados en df_1\n",
        "texts_embeddings = generate_vectors_from_texts(texts=input_texts, model=model, tokenizer=tokenizer, device=device)\n",
        "print(texts_embeddings.shape)\n",
        "\n",
        "# 2. Quiroga Sentences\n",
        "quiroga_embeddings = generate_vectors_from_texts(texts=quiroga_sentences, model=model, tokenizer=tokenizer, device=device)\n",
        "print(quiroga_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpS3_5SdKs0N",
        "outputId": "af4ce968-e4b1-459d-80a8-0d1fa5db72b6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([21, 1024])\n",
            "torch.Size([3540, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta celda calculamos los vecinos m√°s cercanos\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=True):\n",
        "\n",
        "  # 3. Hallo top 3 con Nearest Neighbors.\n",
        "  neigh = NearestNeighbors(n_neighbors=3, radius=0.4)\n",
        "  neigh.fit(quiroga_embeddings)\n",
        "\n",
        "  predictions = []  # Para guardar las predicciones\n",
        "\n",
        "  # Corro knn en batch para todos los texts\n",
        "  if torch_tensor:\n",
        "    distances, indices = neigh.kneighbors(texts_embeddings.cpu().detach().numpy(), 3, return_distance=True)\n",
        "  else:\n",
        "    distances, indices = neigh.kneighbors(texts_embeddings, 3, return_distance=True)\n",
        "\n",
        "  print(f\"Distances: {distances.shape}\")\n",
        "  print(f\"Indices: {indices.shape}\")\n",
        "\n",
        "  for i, (text_distances, text_neighboors) in enumerate(zip(distances, indices)):\n",
        "    for j, (distance, n_idx) in enumerate(zip(text_distances, text_neighboors)):\n",
        "      model_name = f\"pipeline_{i+1}\"\n",
        "      neighboor = quiroga_embeddings[i]\n",
        "      #predictions.append({\"prompt\": input_texts[i], \"idx\": j+1, \"neighborh\": quiroga_sentences[n_idx]})\n",
        "      predictions.append({\n",
        "              \"output_text\": input_texts[i],\n",
        "              \"idx\": j+1,\n",
        "              \"neighbor\": quiroga_sentences[n_idx]}\n",
        "      )\n",
        "\n",
        "      print(f\"Text: {input_texts[i]}\")\n",
        "      print(f\"Neigh: {quiroga_sentences[n_idx]}\")\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "2a00vkDWLSFj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZV-iWbBCsaq",
        "outputId": "5a67b42a-c185-45f8-acac-2e377537269e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances: (21, 3)\n",
            "Indices: (21, 3)\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneci√≥, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de dormir la siesta, cruz√≥ el patio y Alfonso la llam√≥ en silencio con la mano.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Pas√°banse horas sin oir el menor ruido.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Los peones que por a o b llegaban a la siesta, admiraron siempre la obstinaci√≥n del perro, resoplando en cuevitas bajo un sol de fuego, si bien la admiraci√≥n de aquellos no pasaba del cuadro de caza.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Los perros, entonces, sintieron m√°s el pr√≥ximo cambio de due√±o, y solos, al pie de la casa dormida, comenzaron a llorar.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Cinco cigarrillos dejaron su tabaco adentro; y sent√°ndonos entonces con las rodillas altas, encend√≠ la pipa y aspir√©.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: El viento, muy fr√≠o, cristalizaba a√∫n m√°s la claridad de la ma√±ana de oro, y los caballos, que sent√≠an de frente el sol, casi horizontal todav√≠a, entrecerraban los ojos al dichoso deslumbramiento.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Las vacas estaban inm√≥viles, mirando fijamente el verde para√≠so inalcanzable.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Se miraron fijamente, insistentemente, aislados del mundo en aquella recta paralela de alma a alma que los manten√≠a inm√≥viles.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Qued√≥ inm√≥vil, toda ojos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneci√≥, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Los dos caballos, vueltos ya a su pac√≠fica condici√≥n de animales a que un solo hilo contiene, se sintieron ingenuamente deslumbrados por aquel h√©roe capaz de afrontar el alambre de p√∫a, la cosa m√°s terrible que puede hallar el deseo de pasar adelante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Despu√©s de trasponer la loma, los caballos vieron de pronto a las vacas detenidas en el camino, y el recuerdo de la tarde anterior excit√≥ sus orejas y su paso: quer√≠an ver c√≥mo era el nuevo alambrado.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: Durante tres meses consecutivos raras veces falt√≥, sin llegar yo jam√°s a explicarme qu√© combinaciones de visitas, casamientos y garden party debi√≥ hacer para no ser sospechada.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Aqu√≠ ha comenzado mi sorpresa.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Lo que primero me choc√≥, aunque deb√≠a haberlo esperado, fu√© la penumbra del dormitorio.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: ¬øPero est√°bamos todos locos en la casa, o hab√≠a all√≠, proyectado fuera de m√≠ mismo, un eco a mi incesante angustia del _despu√©s_?\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "El oto√±o finalizaba, y el cielo, fijo en sequ√≠a con chubascos de cinco minutos, se descompon√≠a por fin en mal tiempo constante, cuya humedad hinchaba el hombro de los mens√∫.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: Las hojas secas, detenidas en su ca√≠da, entretej√≠an el macizo, que llenaba el aire de polvo y briznas al menor contacto.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "All√° en el obraje de Castelhum, m√°s arriba de Puerto Felicidad, las lluvias hab√≠an comenzado despu√©s de setenta y cinco d√≠as de seca absoluta que no dej√≥ llanta en las alzaprimas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior hab√≠a tenido honrado y peri√≥dico ritmo, no presagi√≥ nada bueno para √©l de esa galopada de accesos casi sin intermitencia.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: --¬øDel m√©dico?--volvi√≥ Lidia al rato, m√°s ansiosa a√∫n.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: Por lo cual, mientras el joyero trabajaba doblado sobre sus pinzas, ella, de codos, sosten√≠a sobre su marido una lenta y pesada mirada, para arrancarse luego bruscamente y seguir con la vista tras los vidrios al transeunte de posici√≥n que pod√≠a haber sido su marido.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: Y con una honda n√°usea por aquello pegajoso, fofo e inerte que era su marido, se fu√© a su cuarto.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Y tamborile√≥ bruscamente sobre la mesa.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Ocup√°banse entonces los mens√∫ en la planchada, tumbando piezas entre inacabable griter√≠a, que sub√≠a de punto cuando las mulas, impotentes para contener la alzaprima, que bajaba a todo escape, rodaban unas sobre otras dando tumbos, vigas, animales, carretas, todo bien mezclado.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: All√≠ abajo, sin embargo, estaba la lagartija.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata conclu√≠da, y con pasaje gratis, por lo tanto.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario pod√≠a subir a siete pesos, la vida de obraje no era dura.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Bruscamente desaparec√≠ a sus ojos tras las ca√±as; corriendo siempre, di un empuj√≥n a la piedra exploradora que esperaba una lluvia, y salt√© de costado, hundi√©ndome bajo la hojarasca.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Desde all√≠, y de atr√°s, acech√≥ a su compa√±ero, recogiendo el rev√≥lver ca√≠do; pero Podeley yac√≠a de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Se√±alando luego el torrente con un movimiento del capuch√≥n:\n",
            "\n",
            "--¬øLas aguas llegar√°n a cubrir el salto?--pregunt√≥ a su compa√±ero.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior hab√≠a tenido honrado y peri√≥dico ritmo, no presagi√≥ nada bueno para √©l de esa galopada de accesos casi sin intermitencia.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata conclu√≠da, y con pasaje gratis, por lo tanto.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario pod√≠a subir a siete pesos, la vida de obraje no era dura.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [[f\"pipeline_{i}\"] * 3 for i in range(1, 8)] * 3\n",
        "model_names = [item for sublist in model_names for item in sublist]\n",
        "text_values = [[text] * 7*3 for text in [\"las vacas\", \"el cielo\", \"Esteban Podeley\"]]\n",
        "text_values = text_values[0] + text_values[1] + text_values[1]"
      ],
      "metadata": {
        "id": "V6OLUC4seJ8t"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrego valores faltantes\n",
        "predictions_ext = []\n",
        "for p, model_name, text in zip(predictions, model_names, text_values):\n",
        "  p[\"model_name\"] = model_name\n",
        "  p[\"prompt\"] = text\n",
        "  predictions_ext.append(p)\n",
        "\n",
        "# Creo DataFrame\n",
        "df_3 = pd.DataFrame(predictions_ext, columns=[\"prompt\", \"model_name\", \"output_text\", \"idx\", \"neighbor\"])\n",
        "df_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1DCkmPwwTsXY",
        "outputId": "875ba0ca-e2ce-4558-f074-6bc521c283b8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       prompt  model_name                                        output_text  \\\n",
              "0   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "1   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "2   las vacas  pipeline_1  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "3   las vacas  pipeline_2  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "4   las vacas  pipeline_2  dormitaban al sol ya caliente , rumiando . Per...   \n",
              "..        ...         ...                                                ...   \n",
              "58   el cielo  pipeline_6  , peones de obraje , volv√≠an a Posadas en el _...   \n",
              "59   el cielo  pipeline_6  , peones de obraje , volv√≠an a Posadas en el _...   \n",
              "60   el cielo  pipeline_7  peones de obraje volv√≠an a Posadas en el _Sile...   \n",
              "61   el cielo  pipeline_7  peones de obraje volv√≠an a Posadas en el _Sile...   \n",
              "62   el cielo  pipeline_7  peones de obraje volv√≠an a Posadas en el _Sile...   \n",
              "\n",
              "    idx                                           neighbor  \n",
              "0     1  Detr√°s de √©l, las vacas dormitaban al sol ya c...  \n",
              "1     2  Pero cuando est√° conmigo, entonces no aparta l...  \n",
              "2     3  Y juro que fueron fuertes las dos horas que pa...  \n",
              "3     1  Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...  \n",
              "4     2  Detr√°s de √©l, las vacas dormitaban al sol ya c...  \n",
              "..  ...                                                ...  \n",
              "58    2  El _Silex_ volvi√≥ a Posadas, llevando con √©l a...  \n",
              "59    3  Podeley, cuya fiebre anterior hab√≠a tenido hon...  \n",
              "60    1  Podeley, labrador de madera, tornaba a los nue...  \n",
              "61    2  #LOS MENS√ö#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...  \n",
              "62    3  *       *       *       *       *\\n\\nPara Pode...  \n",
              "\n",
              "[63 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>model_name</th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighbor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Detr√°s de √©l, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Pero cuando est√° conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_1</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>Y juro que fueron fuertes las dos horas que pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>las vacas</td>\n",
              "      <td>pipeline_2</td>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Detr√°s de √©l, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>El _Silex_ volvi√≥ a Posadas, llevando con √©l a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_6</td>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Podeley, cuya fiebre anterior hab√≠a tenido hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Podeley, labrador de madera, tornaba a los nue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>#LOS MENS√ö#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>el cielo</td>\n",
              "      <td>pipeline_7</td>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>*       *       *       *       *\\n\\nPara Pode...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows √ó 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7ca59af-2adc-4170-a7e2-d0857bbb31cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-689abfa4-263d-40be-bf3d-92433234e404\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-689abfa4-263d-40be-bf3d-92433234e404')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-689abfa4-263d-40be-bf3d-92433234e404 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4d16bcb4-1f57-4c56-bcc6-b02831da5828\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d16bcb4-1f57-4c56-bcc6-b02831da5828 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_3",
              "summary": "{\n  \"name\": \"df_3\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"el cielo\",\n          \"las vacas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"pipeline_1\",\n          \"pipeline_2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighbor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"All\\u00ed abajo, sin embargo, estaba la lagartija.\",\n          \"Bruscamente desaparec\\u00ed a sus ojos tras las ca\\u00f1as; corriendo siempre, di un empuj\\u00f3n a la piedra exploradora que esperaba una lluvia, y salt\\u00e9 de costado, hundi\\u00e9ndome bajo la hojarasca.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**\n",
        "\n",
        "* A diferencia de la distancia de edici√≥n, las oraciones incluidas en el top 3 est√°n relacionadas al texto generado, fundamentalmente en el significado de la misma, en lugar de simplemente en la combinaci√≥n de palabras.\n",
        "\n",
        "* A diferencia de la distancia de edici√≥n, en algunos ejemplos m√°s de una de las oraciones m√°s cercanas, tiene una similitud alta con el texto generado, tanto en la sem√°ntica como en co-ocurrencia de palabras."
      ],
      "metadata": {
        "id": "MOqh33orAHL3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qq0JiQnALx5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach alternativo\n",
        "\n",
        "En base al siguiente [intercambio](https://eva.fing.edu.uy/mod/forum/discuss.php?d=308994) en el foro del laboratorio en EVA, se deduce una forma alternativa (de m√°s alto nivel) para utilizar los embeddings de este modelo mediante la biblioteca sentence-transformers. Por las dudas en la siguiente secci√≥n se incluye el c√≥digo para realizar el mismo experimento, mediante el uso de esta biblioteca, en lugar de inferir utilizando el modelo directamente y PyTorch."
      ],
      "metadata": {
        "id": "PoubJ6DU5KM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "input_texts = df_1[\"output\"].to_list()\n",
        "texts_embeddings = model.encode(input_texts, normalize_embeddings=True)\n",
        "quiroga_embeddings = model.encode(quiroga_sentences, normalize_embeddings=True)\n",
        "\n",
        "predictions = get_knn_using_sklearn(texts_embeddings, quiroga_embeddings, torch_tensor=False)\n",
        "\n",
        "# Creo DataFrame\n",
        "df_4 = pd.DataFrame(predictions, columns=[\"output_text\", \"idx\", \"neighbor\"])\n",
        "df_4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kF4kIVTZ59yO",
        "outputId": "73d4fe2d-f103-4437-e631-6e4343eda05a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances: (21, 3)\n",
            "Indices: (21, 3)\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneci√≥, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de dormir la siesta, cruz√≥ el patio y Alfonso la llam√≥ en silencio con la mano.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam√≥ en silencio . Pas√°banse horas sin oir el angustioso\n",
            "Neigh: Pas√°banse horas sin oir el menor ruido.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Los peones que por a o b llegaban a la siesta, admiraron siempre la obstinaci√≥n del perro, resoplando en cuevitas bajo un sol de fuego, si bien la admiraci√≥n de aquellos no pasaba del cuadro de caza.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Cinco cigarrillos dejaron su tabaco adentro; y sent√°ndonos entonces con las rodillas altas, encend√≠ la pipa y aspir√©.\n",
            "Text: dormitaban al fin se hab√≠a reforzado su coraz√≥n siempre en la pipa y el perro hab√≠a retirado . A media hora en tierra , del\n",
            "Neigh: Los perros, entonces, sintieron m√°s el pr√≥ximo cambio de due√±o, y solos, al pie de la casa dormida, comenzaron a llorar.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando los pobres caballos pasaron por el camino , ellas abrieron los ojos despreciativas : --\n",
            "Neigh: El viento, muy fr√≠o, cristalizaba a√∫n m√°s la claridad de la ma√±ana de oro, y los caballos, que sent√≠an de frente el sol, casi horizontal todav√≠a, entrecerraban los ojos al dichoso deslumbramiento.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Las vacas estaban inm√≥viles, mirando fijamente el verde para√≠so inalcanzable.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Se miraron fijamente, insistentemente, aislados del mundo en aquella recta paralela de alma a alma que los manten√≠a inm√≥viles.\n",
            "Text: estaban inm√≥viles , mirando fijamente el verde para√≠so inalcanzable . -- ¬øpor qu√© ? ¬øqu√© le pasa ? -- nada , sino que est√° bien\n",
            "Neigh: Qued√≥ inm√≥vil, toda ojos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Detr√°s de √©l, las vacas dormitaban al sol ya caliente, rumiando.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Pero cuando est√° conmigo, entonces no aparta los ojos de ellos.\n",
            "Text: dormitaban al sol ya caliente , rumiando . Pero cuando est√° conmigo , entonces no aparta los ojos de mi mujer y yo , con\n",
            "Neigh: Y juro que fueron fuertes las dos horas que pasamos mi mujer y yo, con la luz prendida hasta que amaneci√≥, ella acostada, yo sentado en la cama, vigilando sin cesar la arpillera flotante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Pero cuando los pobres caballos pasaron por el camino, ellas abrieron los ojos despreciativas:\n",
            "\n",
            "--Son los caballos.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Los dos caballos, vueltos ya a su pac√≠fica condici√≥n de animales a que un solo hilo contiene, se sintieron ingenuamente deslumbrados por aquel h√©roe capaz de afrontar el alambre de p√∫a, la cosa m√°s terrible que puede hallar el deseo de pasar adelante.\n",
            "Text: dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\n",
            "Neigh: Despu√©s de trasponer la loma, los caballos vieron de pronto a las vacas detenidas en el camino, y el recuerdo de la tarde anterior excit√≥ sus orejas y su paso: quer√≠an ver c√≥mo era el nuevo alambrado.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: Durante tres meses consecutivos raras veces falt√≥, sin llegar yo jam√°s a explicarme qu√© combinaciones de visitas, casamientos y garden party debi√≥ hacer para no ser sospechada.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que no vaya yo jam√°s a explicarme qu√© combinaciones de visitas , casamientos y garden\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Lo que primero me choc√≥, aunque deb√≠a haberlo esperado, fu√© la penumbra del dormitorio.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Aqu√≠ ha comenzado mi sorpresa.\n",
            "Text: de que est√° todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: ¬øPero est√°bamos todos locos en la casa, o hab√≠a all√≠, proyectado fuera de m√≠ mismo, un eco a mi incesante angustia del _despu√©s_?\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Sus nervios, ya enfermos por el cielo constantemente encapotado y lluvioso, provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: El campo continuaba desolado de lluvia y tristeza, mientras el n√∫mero de perros rabiosos aumentaba.\n",
            "Text: constantemente encapotado y lluvioso , provoc√°ronle verdaderas alucinaciones de perros que entraban al trote por la portera . Hab√≠a un motivo real para este temor\n",
            "Neigh: Mientras se lavaba, los perros se acercaron y le olfatearon las botas, meneando con pereza el rabo.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "El oto√±o finalizaba, y el cielo, fijo en sequ√≠a con chubascos de cinco minutos, se descompon√≠a por fin en mal tiempo constante, cuya humedad hinchaba el hombro de los mens√∫.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: Las hojas secas, detenidas en su ca√≠da, entretej√≠an el macizo, que llenaba el aire de polvo y briznas al menor contacto.\n",
            "Text: fijo en sequ√≠a con chubascos de cinco minutos se descompon√≠a por fin en las lagartijas A√∫n en noviembre cuando ten√≠a ya en jaque a todas\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "All√° en el obraje de Castelhum, m√°s arriba de Puerto Felicidad, las lluvias hab√≠an comenzado despu√©s de setenta y cinco d√≠as de seca absoluta que no dej√≥ llanta en las alzaprimas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior hab√≠a tenido honrado y peri√≥dico ritmo, no presagi√≥ nada bueno para √©l de esa galopada de accesos casi sin intermitencia.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: --¬øDel m√©dico?--volvi√≥ Lidia al rato, m√°s ansiosa a√∫n.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: Y con una honda n√°usea por aquello pegajoso, fofo e inerte que era su marido, se fu√© a su cuarto.\n",
            "Text: , m√°s ansiosa a√∫n . Recurri√≥ entonces a un hombre discreto . V√©ase : Fu√≠ a lo que es patrimonio espec√≠fico de los corazones inferiores\n",
            "Neigh: Ella busc√≥ atolondradamente otro, pero no lo ten√≠a.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: Y tamborile√≥ bruscamente sobre la mesa.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: La sirvienta lo levant√≥, pero en seguida lo dej√≥ caer, y se qued√≥ mirando a aqu√©l, l√≠vida y temblando.\n",
            "Text: bajaron tambaleantes de todo el piso . Alrededor del menguante . Pero yo con sorpresa . Pero √©ste : la loma , y bajo el\n",
            "Neigh: All√≠ abajo, sin embargo, estaba la lagartija.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata conclu√≠da, y con pasaje gratis, por lo tanto.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , labrador de madera , tornaba a los\n",
            "Neigh: El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Bruscamente desaparec√≠ a sus ojos tras las ca√±as; corriendo siempre, di un empuj√≥n a la piedra exploradora que esperaba una lluvia, y salt√© de costado, hundi√©ndome bajo la hojarasca.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Desde all√≠, y de atr√°s, acech√≥ a su compa√±ero, recogiendo el rev√≥lver ca√≠do; pero Podeley yac√≠a de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\n",
            "Text: esperaba una lluvia , y salt√© de costado , con las rodillas recogidas hasta el pecho . ¬øqu√© ser√≠a ? y la respiraci√≥n tambi√©n ...\n",
            "Neigh: Se√±alando luego el torrente con un movimiento del capuch√≥n:\n",
            "\n",
            "--¬øLas aguas llegar√°n a cubrir el salto?--pregunt√≥ a su compa√±ero.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: El _Silex_ volvi√≥ a Posadas, llevando con √©l al mens√∫ empapado a√∫n en pesadillas nocturnas.\n",
            "Text: , peones de obraje , volv√≠an a Posadas en el _Silex_ , con quince compa√±eros . Podeley , cuya fiebre anterior hab√≠a tenido honrado y\n",
            "Neigh: Podeley, cuya fiebre anterior hab√≠a tenido honrado y peri√≥dico ritmo, no presagi√≥ nada bueno para √©l de esa galopada de accesos casi sin intermitencia.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: Podeley, labrador de madera, tornaba a los nueve meses, la contrata conclu√≠da, y con pasaje gratis, por lo tanto.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: #LOS MENS√ö#\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cayetano Maidana y Esteban Podeley, peones de obraje, volv√≠an a\n",
            "Posadas en el _Silex_, con quince compa√±eros.\n",
            "Text: peones de obraje volv√≠an a Posadas en el _Silex_ con quince compa√±eros Podeley labrador de madera tornaba a los nueve meses la contrata conclu√≠da y\n",
            "Neigh: *       *       *       *       *\n",
            "\n",
            "Para Podeley, labrador de madera, cuyo diario pod√≠a subir a siete pesos, la vida de obraje no era dura.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          output_text  idx  \\\n",
              "0   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "1   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "2   dormitaban al sol ya caliente , rumiando . Per...    3   \n",
              "3   dormitaban al sol ya caliente , rumiando . Per...    1   \n",
              "4   dormitaban al sol ya caliente , rumiando . Per...    2   \n",
              "..                                                ...  ...   \n",
              "58  , peones de obraje , volv√≠an a Posadas en el _...    2   \n",
              "59  , peones de obraje , volv√≠an a Posadas en el _...    3   \n",
              "60  peones de obraje volv√≠an a Posadas en el _Sile...    1   \n",
              "61  peones de obraje volv√≠an a Posadas en el _Sile...    2   \n",
              "62  peones de obraje volv√≠an a Posadas en el _Sile...    3   \n",
              "\n",
              "                                             neighbor  \n",
              "0   Detr√°s de √©l, las vacas dormitaban al sol ya c...  \n",
              "1   Pero cuando est√° conmigo, entonces no aparta l...  \n",
              "2   Y juro que fueron fuertes las dos horas que pa...  \n",
              "3   Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...  \n",
              "4   Detr√°s de √©l, las vacas dormitaban al sol ya c...  \n",
              "..                                                ...  \n",
              "58  El _Silex_ volvi√≥ a Posadas, llevando con √©l a...  \n",
              "59  Podeley, cuya fiebre anterior hab√≠a tenido hon...  \n",
              "60  Podeley, labrador de madera, tornaba a los nue...  \n",
              "61  #LOS MENS√ö#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...  \n",
              "62  *       *       *       *       *\\n\\nPara Pode...  \n",
              "\n",
              "[63 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c629116a-3e60-4967-ba88-c9bb95af3104\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output_text</th>\n",
              "      <th>idx</th>\n",
              "      <th>neighbor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Detr√°s de √©l, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Pero cuando est√° conmigo, entonces no aparta l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>3</td>\n",
              "      <td>Y juro que fueron fuertes las dos horas que pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>1</td>\n",
              "      <td>Celia, mi t√≠a mayor, que hab√≠a conclu√≠do de do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dormitaban al sol ya caliente , rumiando . Per...</td>\n",
              "      <td>2</td>\n",
              "      <td>Detr√°s de √©l, las vacas dormitaban al sol ya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>2</td>\n",
              "      <td>El _Silex_ volvi√≥ a Posadas, llevando con √©l a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>, peones de obraje , volv√≠an a Posadas en el _...</td>\n",
              "      <td>3</td>\n",
              "      <td>Podeley, cuya fiebre anterior hab√≠a tenido hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>1</td>\n",
              "      <td>Podeley, labrador de madera, tornaba a los nue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>2</td>\n",
              "      <td>#LOS MENS√ö#\\n\\n\\n\\n\\nCayetano Maidana y Esteba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>peones de obraje volv√≠an a Posadas en el _Sile...</td>\n",
              "      <td>3</td>\n",
              "      <td>*       *       *       *       *\\n\\nPara Pode...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c629116a-3e60-4967-ba88-c9bb95af3104')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c629116a-3e60-4967-ba88-c9bb95af3104 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c629116a-3e60-4967-ba88-c9bb95af3104');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8599e2f8-0b91-4fd4-b5fe-9c1206e0c8e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2700401d-73c1-4d5a-b31d-986f3d878231\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_4')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2700401d-73c1-4d5a-b31d-986f3d878231 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_4');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_4",
              "summary": "{\n  \"name\": \"df_4\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"dormitaban al sol ya caliente , rumiando . Pero cuando est\\u00e1 conmigo , entonces no aparta los ojos de mi mujer y yo , con\",\n          \"dormitaban al sol ya caliente , rumiando . Pero en el patio y Alfonso la llam\\u00f3 en silencio . Pas\\u00e1banse horas sin oir el angustioso\",\n          \"dormitaban al sol ya caliente rumiando Pero cuando los pobres caballos pasaron por el camino ellas abrieron los ojos despreciativas Son los caballos Los alambres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neighbor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"All\\u00ed abajo, sin embargo, estaba la lagartija.\",\n          \"Desde all\\u00ed, y de atr\\u00e1s, acech\\u00f3 a su compa\\u00f1ero, recogiendo el rev\\u00f3lver ca\\u00eddo; pero Podeley yac\\u00eda de nuevo de costado, con las rodillas recogidas hasta el pecho, bajo la lluvia incesante.\",\n          \"Pas\\u00e1banse horas sin oir el menor ruido.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2pE422l5-HD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distancia de Edici√≥n vs. Embeddings\n",
        "\n",
        "Con n-gramas y distancia de edici√≥n se obtienen oraciones similares en las palabras y su orden de aparici√≥n en la oraci√≥n (esto es por como se implementa dicha distancia). Como el modelo de generaci√≥n se sobreajusta al texto de entrenamiento, la distancia de edici√≥n suele recuperar una oraci√≥n muy similar.\n",
        "\n",
        "Por otro lado, con sentence-transformers obtenemos oraciones que significan lo mismo (o que en significado est√°n muy cerca) pero que pueden diferir en largo, palabras y orden de las mismas."
      ],
      "metadata": {
        "id": "2-l6_UQ6BSJo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooPFHBSAS0HW"
      },
      "source": [
        "## Segunda parte: Clasificaci√≥n de textos por autor\n",
        "\n",
        "En esta segunda parte del laboratorio vamos a usar los datos limpios de `quiroga` y todo lo practicado de manipulaci√≥n de tiras para hacer experimentos de clasificaci√≥n.\n",
        "\n",
        "\n",
        "Con el fin de construir modelos que intenten identificar los autores de cada oraci√≥n seg√∫n su estilo de escritura, vamos a incorporar dos libros m√°s, una [selecci√≥n de obras](https://www.gutenberg.org/ebooks/53552) de Gustavo Adolfo B√©cquer y [El Gaucho Mart√≠n Fierro](https://es.wikipedia.org/wiki/El_Gaucho_Mart%C3%ADn_Fierro) de Jos√© Hern√°ndez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "dY8luVJBVBHA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://www.gutenberg.org/cache/epub/53552/pg53552.txt\n",
        "with open(\"pg53552.txt\",\"r\") as f:\n",
        "    becquer_raw = f.read()\n",
        "\n",
        "!wget https://www.gutenberg.org/cache/epub/14765/pg14765.txt\n",
        "with open(\"pg14765.txt\",\"r\") as f:\n",
        "    martin_fierro_raw = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkqDMjAayR3"
      },
      "source": [
        "### 4Ô∏è‚É£ Limpieza b√°sica del nuevo texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbaee-5gn9_"
      },
      "source": [
        "An√°logamente a lo hecho en el ejercicio 0Ô∏è‚É£, limpien `becquer_raw` para que en la variable `becquer` quede:\n",
        "\n",
        "\n",
        "* solamente el texto que est√° entre \"Junio de 1868.\" y \"FIN\\n\"\n",
        "* sin aquellos saltos de l√≠nea que tengan a su derecha una palabra que comience con letra min√∫scula\n",
        "* y borrando todas las subtiras \"[Ilustraci√≥n]\"\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8YskGZRVb3jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bea387c-b7a8-44d7-86b7-c6e4c5287ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 573195 caracteres. \n",
            "Texto extra√≠do: 527105 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de l√≠nea en sentencias...\n",
            "Texto original: 527105 caracteres. \n",
            "Texto extra√≠do: 527105 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "LEYENDAS\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "MAESE P√âREZ EL ORGANISTA\n",
            "\n",
            "\n",
            "En Sevilla, en el mismo atrio de Santa In√©s, y mientras esperaba que comenzase la Misa del Gallo, o√≠ esta tradici√≥n √° una demandadera del convento.\n",
            "\n",
            "Como era natural, despu√©s de oirla, aguard√© impaciente que comenzara la ceremonia, ansioso de asistir √° un prodigio.\n",
            "\n",
            "Nada menos prodigioso, sin embargo, que el √≥rgano de Santa In√©s, ni nada m√°s vulgar que los insulsos motetes que nos regal√≥ su organista aquella noche.\n",
            "\n",
            "Al salir de la Misa, no pude por menos de decirle √° la demandadera con aire de burla:\n",
            "\n",
            "--¬øEn qu√© consiste que el √≥rgano de maese P√©rez suena ahora tan mal?\n",
            "\n",
            "--¬°Toma!--me contest√≥ la vieja,--en que ese no es el suyo.\n",
            "\n",
            "--¬øNo es el suyo? ¬øPues qu√© ha sido de √©l?\n",
            "\n",
            "--Se cay√≥ √° pedazos de puro viejo, hace una porci√≥n de a√±os.\n",
            "\n",
            "--¬øY el alma del organista?\n",
            "\n",
            "--No ha vuelto √° parecer desde que colocaron el que ahora le sustituye.\n",
            "\n",
            "Si √° alguno de mis lectores se le ocurriese hacerme la misma pregunta, despu√©s de leer esta historia, ya s\n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignaci√≥n para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "#becquer = becquer_raw\n",
        "\n",
        "# 1. Extracci√≥n del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "becquer_text_extract_pattern = r\"Junio de 1868\\.(.*)FIN\\n\"  # Expresion regular\n",
        "match = re.search(becquer_text_extract_pattern, becquer_raw, re.DOTALL)\n",
        "if match:\n",
        "    becquer_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(becquer_raw)} caracteres. \\nTexto extra√≠do: {len(becquer_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de l√≠nea\n",
        "print(\"\\n\\nLimpiando saltos de l√≠nea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "becquer = re.sub(breakline_lowercase_pattern, r\" \\1\", becquer_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(becquer_text)} caracteres. \\nTexto extra√≠do: {len(becquer)} caracteres.\")\n",
        "\n",
        "# 3. Borro subturas ilustraci√≥n\n",
        "becquer = becquer.replace(\"[Ilustraci√≥n]\", \" \")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(becquer[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kyv62UueSPN"
      },
      "source": [
        "Hagan lo mismo con `martin_fierro_raw`, guardando en la variable `martin_fierro`:\n",
        "* el texto que est√° entre \"Buenos Aires, diciembre de 1872.\" y \"End of Project\"\n",
        "* sin aquellos saltos de l√≠nea que tengan a su derecha una palabra que comience con letra min√∫scula\n",
        "* y borrando todos los n√∫meros de entre 1 y 3 cifas, e.g. 7, 12, 178   \n",
        "\n",
        "‚ö†Ô∏è Aclaraci√≥n: *El Gaucho Mart√≠n Fierro* est√° originalmente escrito como un poema, por lo que los saltos de l√≠nea no tienen el mismo fin que en la prosa. Sin embargo, eliminaremos esos saltos de l√≠nea seguidos de min√∫sculas como convenci√≥n, a fin de facilitar el ejercicio y hacer m√°s parecido el texto a los guardados en `quiroga` y `becquer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOywbgmujD0L",
        "outputId": "ccba08bc-cb98-4bf5-9d88-847732782e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo texto...\n",
            "Texto original: 85812 caracteres. \n",
            "Texto extra√≠do: 62129 caracteres.\n",
            "\n",
            "\n",
            "Limpiando saltos de l√≠nea en sentencias...\n",
            "Texto original: 62129 caracteres. \n",
            "Texto extra√≠do: 62129 caracteres.\n",
            "\n",
            "\n",
            "\n",
            "Texto Limpio\n",
            "\n",
            "El Gaucho Mart√≠n Fierro\n",
            "\n",
            "\n",
            "I - Cantor y Gaucho.\n",
            "\n",
            " \n",
            "Aqu√≠ me pongo a cantar\n",
            "Al comp√°s de la vig√ºela,\n",
            "Que el hombre que lo desvela\n",
            "Una pena estraordinaria\n",
            "Como la ave solitaria\n",
            "Con el cantar se consuela.\n",
            "\n",
            " \n",
            "Pido a los Santos del Cielo\n",
            "Que ayuden mi pensamiento;\n",
            "Les pido en este momento\n",
            "Que voy a cantar mi historia\n",
            "Me refresquen la memoria\n",
            "Y aclaren mi entendimiento.\n",
            "\n",
            " \n",
            "Vengan Santos milagrosos,\n",
            "Vengan todos en mi ayuda,\n",
            "Que la lengua se me a√±uda\n",
            "Y se me turba la vista;\n",
            "Pido a Dios que me asista\n",
            "En una ocasi√≥n tan ruda.\n",
            "\n",
            " \n",
            "Yo he visto muchos cantores,\n",
            "Con famas bien obtenidas,\n",
            "Y que despu√©s de adquiridas\n",
            "No las quieren sustentar\n",
            "Parece que sin largar se cansaron en partidas\n",
            "\n",
            " \n",
            "Mas ande otro criollo pasa\n",
            "Mart√≠n Fierro ha de pasar; nada lo hace recular ni los fantasmas lo espantan, y dende que todos cantan yo tambi√©n quiero cantar.\n",
            "\n",
            " \n",
            "Cantando me he de morir\n",
            "Cantando me han de enterrar,\n",
            "Y cantando he de llegar\n",
            "Al pie del eterno padre:\n",
            "Dende el vientre de mi madre\n",
            "Vine a este mundo a cantar.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#En esta celda les dejamos esta asignaci√≥n para que el notebook sea funcional.\n",
        "#Implementen en esta celda la limpieza correspondiente.\n",
        "#martin_fierro = martin_fierro_raw\n",
        "\n",
        "# 1. Extracci√≥n del texto\n",
        "print(\"Extrayendo texto...\")\n",
        "martin_fierro_text_extract_pattern = r\"Buenos Aires, diciembre de 1872\\.(.*)End of Project\"  # Expresion regular\n",
        "match = re.search(martin_fierro_text_extract_pattern, martin_fierro_raw, re.DOTALL)\n",
        "if match:\n",
        "    martin_fierro_text = match.group(1).strip()  # Remuevo espacios en blanco\n",
        "    print(f\"Texto original: {len(martin_fierro_raw)} caracteres. \\nTexto extra√≠do: {len(martin_fierro_text)} caracteres.\")\n",
        "else:\n",
        "    print(\"Algo anda mal!\")\n",
        "\n",
        "# 2. Limpieza saltos de l√≠nea\n",
        "print(\"\\n\\nLimpiando saltos de l√≠nea en sentencias...\")\n",
        "breakline_lowercase_pattern = r\"\\n([a-z])\"\n",
        "martin_fierro = re.sub(breakline_lowercase_pattern, r\" \\1\", martin_fierro_text)  # Reemplazo \\n por un ' '\n",
        "print(f\"Texto original: {len(martin_fierro_text)} caracteres. \\nTexto extra√≠do: {len(martin_fierro)} caracteres.\")\n",
        "\n",
        "# 3. Borro numeros de 1-3 cifras\n",
        "martin_fierro = martin_fierro.replace(\"[Ilustraci√≥n]\", \" \")\n",
        "martin_fierro = re.sub(r'\\b\\d{1,3}\\b', ' ', martin_fierro)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"Texto Limpio\\n\")\n",
        "print(martin_fierro[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSoCwM63kmoC"
      },
      "source": [
        "### Creaci√≥n del corpus de clasificaci√≥n\n",
        "\n",
        "En la siguiente celda, ya implementada, se crea el corpus y se subdivide en conjuntos de entrenamiento (`corpus_sentences_train`, `corpus_authors_train`), desarrollo (`corpus_sentences_dev`, `corpus_authors_dev`) y evaluaci√≥n  (`corpus_sentences_test`, `corpus_authors_test`).\n",
        "\n",
        "üí°Cada conjunto est√° a su vez subdividido en `corpus_sentences` y `corpus_authors`, donde los textos que pertenecen a `quiroga` est√°n se√±alizados por el `0`, los de `becquer` por el `1` y los de `martin_fierro` por el `2`. Esto facilita el algoritmo de partici√≥n y tambi√©n la evaluaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "k-ftovt8nXIy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "quiroga_sentences = [x for x in nltk.sent_tokenize(quiroga,  language='spanish') if len(x)>4]\n",
        "corpus_sentences = quiroga_sentences\n",
        "corpus_authors = [0]*len(quiroga_sentences)\n",
        "\n",
        "becquer_sentences = [x for x in nltk.sent_tokenize(becquer,  language='spanish') if len(x)>4]\n",
        "corpus_sentences += becquer_sentences\n",
        "corpus_authors += [1]*len(becquer_sentences)\n",
        "\n",
        "martin_fierro_sentences = [x for x in nltk.sent_tokenize(martin_fierro,  language='spanish') if len(x)>4]\n",
        "corpus_sentences += martin_fierro_sentences\n",
        "corpus_authors += [2]*len(martin_fierro_sentences)\n",
        "\n",
        "corpus_sentences_train, corpus_sentences_other, corpus_authors_train, corpus_authors_other = train_test_split(\n",
        "    corpus_sentences, corpus_authors,\n",
        "    test_size=0.3, train_size=0.7,\n",
        "    random_state=2024, shuffle=True, stratify=corpus_authors)\n",
        "\n",
        "corpus_sentences_dev, corpus_sentences_test, corpus_authors_dev, corpus_authors_test = train_test_split(\n",
        "    corpus_sentences_other, corpus_authors_other,\n",
        "    test_size=0.5, train_size=0.5,\n",
        "    random_state=2024, shuffle=True, stratify=corpus_authors_other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHCjESY9Z8h"
      },
      "source": [
        "### 5Ô∏è‚É£ An√°lisis del corpus\n",
        "\n",
        "Para entender mejor c√≥mo est√° compuesto el corpus, hallen:\n",
        "- la cantidad de instancias en los subconjuntos `train`, `dev` y `test`\n",
        "- la cantidad de instancias de cada una de las clases (*quiroga*, *becquer*  y *martin_fierro*) en cada uno de los subconjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "VLnjQRU-_a7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cfcb23-bc29-44ae-ab71-c64233dcb477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- TRAIN ----\n",
            "sentencias=4530\n",
            "quiroga=2469 becquer=1727 martin_fierro=334\n",
            "\n",
            "---- DEV ----\n",
            "971\n",
            "quiroga=529 becquer=370 martin_fierro=72\n",
            "\n",
            "---- TEST ----\n",
            "971\n",
            "quiroga=530 becquer=370 martin_fierro=71\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Completar\n",
        "\n",
        "# Cantidad de instancias en cada corpus\n",
        "print(\"---- TRAIN ----\")\n",
        "print(f\"sentencias={len(corpus_sentences_train)}\")\n",
        "counter_dict = Counter(corpus_authors_train)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n",
        "\n",
        "print(\"\\n---- DEV ----\")\n",
        "print(len(corpus_sentences_dev))\n",
        "counter_dict = Counter(corpus_authors_dev)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n",
        "\n",
        "print(\"\\n---- TEST ----\")\n",
        "print(len(corpus_sentences_test))\n",
        "counter_dict = Counter(corpus_authors_test)\n",
        "print(f\"quiroga={counter_dict.get(0, 0)} becquer={counter_dict.get(1, 0)} martin_fierro={counter_dict.get(2, 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFQ8t9EcFkBT"
      },
      "source": [
        "### Evaluaci√≥n del clasificador aleatorio (l√≠nea base)\n",
        "\n",
        "Ahora que tenemos los conjuntos definidos, ya podemos entrenar modelos. Pero antes, siempre es bueno ver c√≥mo se comportar√≠a un algoritmo sencillo que consista en una heur√≠stica con pocas reglas o en una clasificaci√≥n aleatoria. A este modelo sencillo, que sirve como punto de comparaci√≥n, le solemos llamar *l√≠nea base* (baseline).\n",
        "\n",
        "En la siguiente celda les mostramos la evaluaci√≥n sobre `dev` de la predicci√≥n aleatoria, para que tengan una l√≠nea base con la que comparar los modelos que construir√°n a continuaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "cEenAtv2DQYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f4da51-4077-48ba-8a1c-fcc30ed57255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 30.17\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.57      0.35      0.43       529\n",
            "      becquer       0.38      0.33      0.35       370\n",
            "martin_fierro       0.07      0.33      0.12        72\n",
            "\n",
            "     accuracy                           0.34       971\n",
            "    macro avg       0.34      0.34      0.30       971\n",
            " weighted avg       0.46      0.34      0.38       971\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "random_prediction = [random.choice([0,1,2]) for i in range(len(corpus_authors_dev))]\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, random_prediction, average='macro')*100, 2))) # Se imprime la medida F\n",
        "print(classification_report(corpus_authors_dev, random_prediction, target_names=['quiroga','becquer','martin_fierro'])) # Se eval√∫a sobre dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKmhc7w1KcV"
      },
      "source": [
        "### 6Ô∏è‚É£ Entrenamiento y evaluaci√≥n de modelos en el conjunto de desarrollo (dev)\n",
        "\n",
        "Ahora que vimos la medida F1 en `dev` para el clasificador aleatorio, ya pueden entrenar modelos y evaluarlos intentando superar esa l√≠nea base. En la siguiente celda mostramos el entrenamiento sobre `train` de un modelo sencillo y su posterior evaluaci√≥n sobre `dev`, donde usamos [bag of words](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation) para representar num√©ricamente los textos y [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html) como algoritmo de clasificaci√≥n.\n",
        "\n",
        "Entrenen con `train` y eval√∫en sobre `dev` al menos 4 modelos, explorando varios algoritmos de clasificaci√≥n y, si quieren, tambi√©n preprocesando los textos usando  pipelines de preprocesamiento con pasos complementarios a los ya desarrollados en 4Ô∏è‚É£.\n",
        "\n",
        "üí°Les recomendamos que comiencen probando vectorizar con [bag of words](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation) o [TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), y clasificando con cualquier algoritmo disponible en [sklearn](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html). Sin embargo, vemos positivo que exploren **CUALQUIER** enfoque: pueden probar usando grandes modelos de lenguaje como LLAMA o Mistral, o tambi√©n vectorizando con vectores contextuales como los *sentence transformers* usados en el ejercicio 3Ô∏è‚É£. En [HuggingFace](https://huggingface.co/) pueden encontrar much√≠simos modelos para probar.\n",
        "\n",
        "üí°Tengan en cuenta que si usan un pipeline de preprocesamiento para procesar los textos al entrenar, tambi√©n tendr√°n que usarlo para transformar los textos al predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de referencia la siguiente tabla enumer alos experimentos que nos proponemos realizar de aqu√≠ en adelante:\n",
        "\n",
        "|vectors | model |\n",
        "| ----\t | ------|\n",
        "| BoW    | SVM   |\n",
        "| TF-IDF | SVM   |\n",
        "|BoW     |MLPClassifier|\n",
        "|TF-IDF  |MLPClassifier|\n",
        "|TF-IDF + SMOTE |SVM|\n",
        "|TF-IDF + SMOTE |MLPClassifier|\n",
        "|SentenceTransformers |SVM|\n",
        "|SentenceTransformers |MLPClassifier|\n"
      ],
      "metadata": {
        "id": "Ifq-p2HrDtZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Bow + SVM\n",
        "\n",
        "El siguiente modelo combina Bag-of-Words con un modelo SVM."
      ],
      "metadata": {
        "id": "sGzm1moj5Xu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lSQOhTGK2hpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b4c608-84d9-46f6-8462-d711108b1e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 33.49\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.58      1.00      0.73       529\n",
            "      becquer       1.00      0.16      0.27       370\n",
            "martin_fierro       0.00      0.00      0.00        72\n",
            "\n",
            "     accuracy                           0.60       971\n",
            "    macro avg       0.53      0.39      0.33       971\n",
            " weighted avg       0.70      0.60      0.50       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "clf = SVC() # Prueben ac√° con varios modelos\n",
        "\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* El modelo se sobre ajusta a los textos de quiroga con un alto recall a costa de una baja precision. Esto es esperable de un modelo sencillo, con un dataset tan desbalanceado.\n",
        "* No se reconoce ning√∫n ejemplo de la clase martin_fierro. Esto es esperable tambi√©n ya que se tienen muy pocos ejemplos (72).\n",
        "* En resumen el modelo no es bueno"
      ],
      "metadata": {
        "id": "Vfp1UtrFjahL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. TF-IDF + SVM\n",
        "\n",
        "El siguiente modelo combina TF-IDF, que es una estrategia de vectorizaci√≥n complementaria a BoW que permite obtener mejores resultados, sobre todo al considerar palabras menos frecuentes, con un modelo SVM."
      ],
      "metadata": {
        "id": "4ElZrp-15zLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "tf_idf = TfidfTransformer(use_idf=True)\n",
        "clf = SVC() # Prueben ac√° con varios modelos\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "id": "rZVdQ4BRW0aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93cb42a-d1d4-495f-833f-77653ff9d9f8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 47.7\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.69      0.90      0.78       529\n",
            "      becquer       0.75      0.58      0.65       370\n",
            "martin_fierro       0.00      0.00      0.00        72\n",
            "\n",
            "     accuracy                           0.71       971\n",
            "    macro avg       0.48      0.49      0.48       971\n",
            " weighted avg       0.66      0.71      0.67       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Con TF-IDF se obtienen mejores resultados, en particular tanto la precision como el recall se encuentran m√°s balanceados entre las clases dominantes (quiroga y becquer).\n",
        "* Persiste la no identificaci√≥n de los textos de martin_fierro"
      ],
      "metadata": {
        "id": "-csRp_9HkTRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. BoW + MLP Classifier\n",
        "\n",
        "El siguiente modelo combina BoW, con un modelo de redes neuronales, capaz de sobre ajustarse mejor a los datos de entrenamiento."
      ],
      "metadata": {
        "id": "DwMlPxea6YQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.0001,\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=50,\n",
        "                    shuffle=True,\n",
        "                    random_state=1,\n",
        "                    verbose=True,\n",
        "                    momentum=0.9,\n",
        "                    nesterovs_momentum=True,\n",
        "                    early_stopping=True,\n",
        "                    validation_fraction=0.1)\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThnXWPMkkwkE",
        "outputId": "84f07e13-e6fd-491e-8c8f-943648c17182"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.12994493\n",
            "Validation score: 0.536424\n",
            "Iteration 2, loss = 0.55404840\n",
            "Validation score: 0.818985\n",
            "Iteration 3, loss = 0.29159150\n",
            "Validation score: 0.801325\n",
            "Iteration 4, loss = 0.18706852\n",
            "Validation score: 0.792494\n",
            "Iteration 5, loss = 0.13609585\n",
            "Validation score: 0.785872\n",
            "Iteration 6, loss = 0.10727612\n",
            "Validation score: 0.779249\n",
            "Iteration 7, loss = 0.08867490\n",
            "Validation score: 0.777042\n",
            "Iteration 8, loss = 0.07604580\n",
            "Validation score: 0.777042\n",
            "Iteration 9, loss = 0.06683892\n",
            "Validation score: 0.777042\n",
            "Iteration 10, loss = 0.05995841\n",
            "Validation score: 0.777042\n",
            "Iteration 11, loss = 0.05452054\n",
            "Validation score: 0.772627\n",
            "Iteration 12, loss = 0.05022459\n",
            "Validation score: 0.768212\n",
            "Iteration 13, loss = 0.04675281\n",
            "Validation score: 0.770419\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 46.14\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.61      0.99      0.76       529\n",
            "      becquer       0.99      0.26      0.42       370\n",
            "martin_fierro       0.64      0.12      0.21        72\n",
            "\n",
            "     accuracy                           0.65       971\n",
            "    macro avg       0.75      0.46      0.46       971\n",
            " weighted avg       0.76      0.65      0.59       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* El modelo demuestra mayor capacidad para sobre ajustar los datos, al punto que logra reconocer algunas sentencias de martin_fierro (muy poquitas).\n",
        "* Por otro se evidencia todav√≠a un sesgo a predecir \"quiroga\" evidentemente por el desbalance de clases.\n",
        "* Si bien la red neuronal parece tener mayor capacidad de modelado que SVM no es una buena alternativa.\n",
        "* Probemos MLP con TF-IDF"
      ],
      "metadata": {
        "id": "etI0-o5mlk8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. TF-IDF + MLP Classifier\n",
        "\n",
        "El siguiente modelo combina TF-IDF (ya vimos que permite obtener mejores resultados), con un modelo de redes neuronales."
      ],
      "metadata": {
        "id": "GRaR4Tzz6vYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "tf_idf = TfidfTransformer(use_idf=True)\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.0001,\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=50,\n",
        "                    shuffle=True,\n",
        "                    random_state=1,\n",
        "                    verbose=True,\n",
        "                    momentum=0.9,\n",
        "                    nesterovs_momentum=True,\n",
        "                    early_stopping=True,\n",
        "                    validation_fraction=0.1)\n",
        "\n",
        "# 1. Fit Modelo\n",
        "training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "clf.fit(training_features, corpus_authors_train) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# 2. Eval Modelo\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhLVobqjZJcv",
        "outputId": "86743f4d-0179-4e50-9f9b-4ade36c60139"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.19801521\n",
            "Validation score: 0.072848\n",
            "Iteration 2, loss = 1.00157398\n",
            "Validation score: 0.576159\n",
            "Iteration 3, loss = 0.77302136\n",
            "Validation score: 0.580574\n",
            "Iteration 4, loss = 0.56690765\n",
            "Validation score: 0.618102\n",
            "Iteration 5, loss = 0.39883285\n",
            "Validation score: 0.673289\n",
            "Iteration 6, loss = 0.28434121\n",
            "Validation score: 0.682119\n",
            "Iteration 7, loss = 0.20937706\n",
            "Validation score: 0.693157\n",
            "Iteration 8, loss = 0.15936651\n",
            "Validation score: 0.697572\n",
            "Iteration 9, loss = 0.12548816\n",
            "Validation score: 0.701987\n",
            "Iteration 10, loss = 0.10222102\n",
            "Validation score: 0.706402\n",
            "Iteration 11, loss = 0.08592488\n",
            "Validation score: 0.706402\n",
            "Iteration 12, loss = 0.07407344\n",
            "Validation score: 0.704194\n",
            "Iteration 13, loss = 0.06519518\n",
            "Validation score: 0.704194\n",
            "Iteration 14, loss = 0.05838758\n",
            "Validation score: 0.706402\n",
            "Iteration 15, loss = 0.05317802\n",
            "Validation score: 0.710817\n",
            "Iteration 16, loss = 0.04899312\n",
            "Validation score: 0.715232\n",
            "Iteration 17, loss = 0.04565946\n",
            "Validation score: 0.715232\n",
            "Iteration 18, loss = 0.04288519\n",
            "Validation score: 0.715232\n",
            "Iteration 19, loss = 0.04061949\n",
            "Validation score: 0.717439\n",
            "Iteration 20, loss = 0.03869362\n",
            "Validation score: 0.715232\n",
            "Iteration 21, loss = 0.03708006\n",
            "Validation score: 0.717439\n",
            "Iteration 22, loss = 0.03564629\n",
            "Validation score: 0.717439\n",
            "Iteration 23, loss = 0.03443779\n",
            "Validation score: 0.717439\n",
            "Iteration 24, loss = 0.03338803\n",
            "Validation score: 0.724062\n",
            "Iteration 25, loss = 0.03246500\n",
            "Validation score: 0.728477\n",
            "Iteration 26, loss = 0.03167890\n",
            "Validation score: 0.730684\n",
            "Iteration 27, loss = 0.03094159\n",
            "Validation score: 0.737307\n",
            "Iteration 28, loss = 0.03029020\n",
            "Validation score: 0.737307\n",
            "Iteration 29, loss = 0.02974803\n",
            "Validation score: 0.737307\n",
            "Iteration 30, loss = 0.02920771\n",
            "Validation score: 0.737307\n",
            "Iteration 31, loss = 0.02872173\n",
            "Validation score: 0.741722\n",
            "Iteration 32, loss = 0.02831222\n",
            "Validation score: 0.741722\n",
            "Iteration 33, loss = 0.02792536\n",
            "Validation score: 0.743929\n",
            "Iteration 34, loss = 0.02757979\n",
            "Validation score: 0.743929\n",
            "Iteration 35, loss = 0.02729291\n",
            "Validation score: 0.743929\n",
            "Iteration 36, loss = 0.02693017\n",
            "Validation score: 0.743929\n",
            "Iteration 37, loss = 0.02666225\n",
            "Validation score: 0.746137\n",
            "Iteration 38, loss = 0.02644206\n",
            "Validation score: 0.750552\n",
            "Iteration 39, loss = 0.02616837\n",
            "Validation score: 0.748344\n",
            "Iteration 40, loss = 0.02596117\n",
            "Validation score: 0.748344\n",
            "Iteration 41, loss = 0.02575110\n",
            "Validation score: 0.750552\n",
            "Iteration 42, loss = 0.02558907\n",
            "Validation score: 0.757174\n",
            "Iteration 43, loss = 0.02538675\n",
            "Validation score: 0.752759\n",
            "Iteration 44, loss = 0.02524385\n",
            "Validation score: 0.754967\n",
            "Iteration 45, loss = 0.02508598\n",
            "Validation score: 0.754967\n",
            "Iteration 46, loss = 0.02495800\n",
            "Validation score: 0.750552\n",
            "Iteration 47, loss = 0.02485950\n",
            "Validation score: 0.768212\n",
            "Iteration 48, loss = 0.02475669\n",
            "Validation score: 0.759382\n",
            "Iteration 49, loss = 0.02459294\n",
            "Validation score: 0.763797\n",
            "Iteration 50, loss = 0.02446816\n",
            "Validation score: 0.763797\n",
            "F-Score macro: 60.1\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.82      0.88      0.85       529\n",
            "      becquer       0.77      0.83      0.80       370\n",
            "martin_fierro       1.00      0.08      0.15        72\n",
            "\n",
            "     accuracy                           0.80       971\n",
            "    macro avg       0.86      0.60      0.60       971\n",
            " weighted avg       0.82      0.80      0.78       971\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Resultados mucho mejores y balanceados para Quiroga y Becquer\n",
        "* Aun no resolvemos el problema con martin_fierro"
      ],
      "metadata": {
        "id": "_-miPDPnrlsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. TF-IDF + SMOTE + MLP Classifier\n",
        "\n",
        "El principal problema que tienen hasta ahora los modelos entrenados, es que no son capaces de modelar con cierto grado de equidad las diferentes clases. En particular son muy buenos prediciendo textos de la clase \"Quiroga\", mediocres prediciendo textos de la clase \"Becquer\" y muy malos prediciendo los textos de la clase \"Martin Fierro\". Esto se puede deber a que el corpus se encuentra desbalanceado, con muy pocos ejemplos de estas dos √∫ltimas clases.\n",
        "\n",
        "Una forma de solventar este problema, es mediante t√©cnicas de undersampling/oversampling, para balancear el dataset. En el siguiente experimento utilizamos SMOTE de `imblearn` para entrenar un modelo TF-IDF + MLP Classifier sobre un dataset m√°s balanceado.\n"
      ],
      "metadata": {
        "id": "-gUi4mSQ7ef7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def featurize_model_5(corpus_sentences):\n",
        "  features = bow_vectorizer.fit_transform(corpus_sentences) # Se vectorizan los textos de train con BoW\n",
        "  features = tf_idf.fit_transform(features)  # Se mejoran con TF-IDF\n",
        "  return features\n",
        "\n",
        "def train_model_5(corpus_sentences_train, corpus_authors_train):\n",
        "\n",
        "  # Setup\n",
        "  bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "  tf_idf = TfidfTransformer(use_idf=True)\n",
        "\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=0.0001,\n",
        "                      batch_size='auto',\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=0.001,\n",
        "                      max_iter=100,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      verbose=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      validation_fraction=0.1)\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "  training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Train model 5\n",
        "model_5 = train_model_5(corpus_sentences_train, corpus_authors_train)\n",
        "\n",
        "# Eval model 5\n",
        "dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "prediction = model_5.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8kWrlVE-qlp",
        "outputId": "2f194964-c56d-478d-8412-9d49c72efb0b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.06232207\n",
            "Validation score: 0.423752\n",
            "Iteration 2, loss = 0.79477710\n",
            "Validation score: 0.796221\n",
            "Iteration 3, loss = 0.51857686\n",
            "Validation score: 0.851552\n",
            "Iteration 4, loss = 0.33732659\n",
            "Validation score: 0.866397\n",
            "Iteration 5, loss = 0.23591078\n",
            "Validation score: 0.887989\n",
            "Iteration 6, loss = 0.17978490\n",
            "Validation score: 0.894737\n",
            "Iteration 7, loss = 0.14581278\n",
            "Validation score: 0.904184\n",
            "Iteration 8, loss = 0.12342339\n",
            "Validation score: 0.910931\n",
            "Iteration 9, loss = 0.10762175\n",
            "Validation score: 0.914980\n",
            "Iteration 10, loss = 0.09600583\n",
            "Validation score: 0.909582\n",
            "Iteration 11, loss = 0.08711447\n",
            "Validation score: 0.910931\n",
            "Iteration 12, loss = 0.08019881\n",
            "Validation score: 0.904184\n",
            "Iteration 13, loss = 0.07468790\n",
            "Validation score: 0.900135\n",
            "Iteration 14, loss = 0.07017213\n",
            "Validation score: 0.860999\n",
            "Iteration 15, loss = 0.06650776\n",
            "Validation score: 0.851552\n",
            "Iteration 16, loss = 0.06342872\n",
            "Validation score: 0.850202\n",
            "Iteration 17, loss = 0.06082376\n",
            "Validation score: 0.850202\n",
            "Iteration 18, loss = 0.05861617\n",
            "Validation score: 0.850202\n",
            "Iteration 19, loss = 0.05668848\n",
            "Validation score: 0.850202\n",
            "Iteration 20, loss = 0.05498454\n",
            "Validation score: 0.850202\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 69.5\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.84      0.82      0.83       529\n",
            "      becquer       0.75      0.83      0.79       370\n",
            "martin_fierro       0.61      0.38      0.47        72\n",
            "\n",
            "     accuracy                           0.79       971\n",
            "    macro avg       0.73      0.68      0.70       971\n",
            " weighted avg       0.79      0.79      0.79       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones**\n",
        "* Hermoso"
      ],
      "metadata": {
        "id": "9c5LkNibrrA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Sentence Transformers + SMOTE + SVM"
      ],
      "metadata": {
        "id": "Jk6ZwxXg8RgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def featurize_model_6(corpus_sentences, model_vectorize):\n",
        "  features = model_vectorize.encode(corpus_sentences, normalize_embeddings=True)\n",
        "  return features\n",
        "\n",
        "def train_model_6(corpus_sentences_train, corpus_authors_train, model_vectorize):\n",
        "  clf = SVC() # Prueben ac√° con varios modelos\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = featurize_model_6(corpus_sentences_train, model_vectorize)\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  # 3. Fit model\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Para vectorize\n",
        "model_vectorize = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "# Train model 6\n",
        "model_6 = train_model_6(corpus_sentences_train, corpus_authors_train, model_vectorize)\n",
        "\n",
        "# 3. Eval Modelo\n",
        "dev_features = featurize_model_6(corpus_sentences_dev, model_vectorize)\n",
        "prediction = model_6.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJE_btqD8bBP",
        "outputId": "36dc8f76-5bae-421f-f6b1-013708fcd573"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 85.48\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.93      0.89       529\n",
            "      becquer       0.90      0.80      0.85       370\n",
            "martin_fierro       0.83      0.82      0.83        72\n",
            "\n",
            "     accuracy                           0.87       971\n",
            "    macro avg       0.86      0.85      0.85       971\n",
            " weighted avg       0.87      0.87      0.87       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**"
      ],
      "metadata": {
        "id": "xziCDTzAAk1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def featurize_model_7(corpus_sentences, model_vectorize):\n",
        "  features = model_vectorize.encode(corpus_sentences, normalize_embeddings=True)\n",
        "  return features\n",
        "\n",
        "def train_model_7(corpus_sentences_train, corpus_authors_train, model_vectorize):\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(50,),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=0.0001,\n",
        "                      batch_size='auto',\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=0.001,\n",
        "                      max_iter=50,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      verbose=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      validation_fraction=0.1)\n",
        "\n",
        "  # 1. Fit Modelo\n",
        "  training_features = model.encode(corpus_sentences_train, normalize_embeddings=True)\n",
        "\n",
        "  # 2. Apply SMOTE to the training set\n",
        "  smote = SMOTE(random_state=42)\n",
        "  training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "\n",
        "  clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "  return clf\n",
        "\n",
        "# Para vectorize\n",
        "model_vectorize = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "# Train model 7\n",
        "model_7 = train_model_7(corpus_sentences_train, corpus_authors_train, model_vectorize)\n",
        "\n",
        "# 3. Eval Modelo\n",
        "dev_features = featurize_model_6(corpus_sentences_dev, model_vectorize)\n",
        "prediction = model_7.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHQMpNhjAqX2",
        "outputId": "2c8a6c5f-7103-4d6a-82b0-25fc317f3bdd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.07346558\n",
            "Validation score: 0.705803\n",
            "Iteration 2, loss = 0.98381915\n",
            "Validation score: 0.790823\n",
            "Iteration 3, loss = 0.87534139\n",
            "Validation score: 0.800270\n",
            "Iteration 4, loss = 0.76244772\n",
            "Validation score: 0.801619\n",
            "Iteration 5, loss = 0.66241874\n",
            "Validation score: 0.807018\n",
            "Iteration 6, loss = 0.58138941\n",
            "Validation score: 0.839406\n",
            "Iteration 7, loss = 0.52062089\n",
            "Validation score: 0.848853\n",
            "Iteration 8, loss = 0.47123973\n",
            "Validation score: 0.859649\n",
            "Iteration 9, loss = 0.43545546\n",
            "Validation score: 0.854251\n",
            "Iteration 10, loss = 0.40727798\n",
            "Validation score: 0.870445\n",
            "Iteration 11, loss = 0.38169067\n",
            "Validation score: 0.866397\n",
            "Iteration 12, loss = 0.36258079\n",
            "Validation score: 0.875843\n",
            "Iteration 13, loss = 0.34320657\n",
            "Validation score: 0.885290\n",
            "Iteration 14, loss = 0.32929227\n",
            "Validation score: 0.892038\n",
            "Iteration 15, loss = 0.31589525\n",
            "Validation score: 0.901484\n",
            "Iteration 16, loss = 0.30321333\n",
            "Validation score: 0.905533\n",
            "Iteration 17, loss = 0.29305392\n",
            "Validation score: 0.906883\n",
            "Iteration 18, loss = 0.28460352\n",
            "Validation score: 0.901484\n",
            "Iteration 19, loss = 0.27513220\n",
            "Validation score: 0.905533\n",
            "Iteration 20, loss = 0.26873580\n",
            "Validation score: 0.908232\n",
            "Iteration 21, loss = 0.26034123\n",
            "Validation score: 0.913630\n",
            "Iteration 22, loss = 0.25463913\n",
            "Validation score: 0.908232\n",
            "Iteration 23, loss = 0.24747563\n",
            "Validation score: 0.910931\n",
            "Iteration 24, loss = 0.24177001\n",
            "Validation score: 0.913630\n",
            "Iteration 25, loss = 0.23727225\n",
            "Validation score: 0.906883\n",
            "Iteration 26, loss = 0.23464602\n",
            "Validation score: 0.909582\n",
            "Iteration 27, loss = 0.22744651\n",
            "Validation score: 0.912281\n",
            "Iteration 28, loss = 0.22370049\n",
            "Validation score: 0.909582\n",
            "Iteration 29, loss = 0.21895205\n",
            "Validation score: 0.908232\n",
            "Iteration 30, loss = 0.21651430\n",
            "Validation score: 0.913630\n",
            "Iteration 31, loss = 0.21225264\n",
            "Validation score: 0.905533\n",
            "Iteration 32, loss = 0.20828550\n",
            "Validation score: 0.912281\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "F-Score macro: 83.0\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.88      0.88      0.88       529\n",
            "      becquer       0.84      0.80      0.82       370\n",
            "martin_fierro       0.71      0.89      0.79        72\n",
            "\n",
            "     accuracy                           0.85       971\n",
            "    macro avg       0.81      0.86      0.83       971\n",
            " weighted avg       0.85      0.85      0.85       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**"
      ],
      "metadata": {
        "id": "SuiqsvFKAln9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# import numpy as np\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# # Setup\n",
        "# bow_vectorizer = CountVectorizer(ngram_range=(2,4), strip_accents= 'unicode') # n-gramas a nivel de palabra\n",
        "# tf_idf = TfidfTransformer(use_idf=True)\n",
        "# clf = SVC() # Prueben ac√° con varios modelos\n",
        "\n",
        "# # 1. Fit Modelo\n",
        "# training_features = bow_vectorizer.fit_transform(corpus_sentences_train) # Se vectorizan los textos de train con BoW\n",
        "# training_features = tf_idf.fit_transform(training_features)  # Se mejoran con TF-IDF\n",
        "\n",
        "# # 2. Apply SMOTE to the training set\n",
        "# smote = SMOTE(random_state=42)\n",
        "# training_features_resampled, corpus_authors_train_resampled = smote.fit_resample(training_features, corpus_authors_train)\n",
        "# clf.fit(training_features_resampled, corpus_authors_train_resampled) # Se entrena el clasificador usando los textos vectorizados\n",
        "\n",
        "# # 3. Eval Modelo\n",
        "# dev_features = bow_vectorizer.transform(corpus_sentences_dev) # Se vectorizan los textos de dev con BoW\n",
        "# dev_features = tf_idf.fit_transform(dev_features)  # Se mejoran con TF-IDF\n",
        "# prediction = clf.predict(dev_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "# print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_dev, prediction, average='macro')*100, 2)))\n",
        "# print(classification_report(corpus_authors_dev, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "id": "SOulGBpjNboc"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-U00FBqJfE6"
      },
      "source": [
        "### 7Ô∏è‚É£Evaluaci√≥n final de modelos en el conjunto de evaluaci√≥n (test)\n",
        "\n",
        "Como √∫ltima actividad del laboratorio, elijan los tres modelos que mejores predicciones hayan logrado sobre `dev` y eval√∫enlos sobre `test`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtFEgAtuChgZ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. TF-IDF + SMOTE + MLP Classifier"
      ],
      "metadata": {
        "id": "ZMtkUktpCiNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = bow_vectorizer.transform(corpus_sentences_test) # Se vectorizan los textos de dev con BoW\n",
        "test_features = tf_idf.fit_transform(test_features)  # Se mejoran con TF-IDF\n",
        "prediction = model_5.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKuoSZ2WNcai",
        "outputId": "2ffc9f9f-505e-4184-fd74-9d0e7a462de4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 76.61\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.85      0.86       530\n",
            "      becquer       0.78      0.84      0.81       370\n",
            "martin_fierro       0.75      0.55      0.63        71\n",
            "\n",
            "     accuracy                           0.82       971\n",
            "    macro avg       0.80      0.75      0.77       971\n",
            " weighted avg       0.82      0.82      0.82       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Sentence Transformers + SMOTE + SVM\n",
        "\n"
      ],
      "metadata": {
        "id": "4cf24Ol8HKD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = featurize_model_6(corpus_sentences_test, model_vectorize)\n",
        "prediction = model_6.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dmRYsUAHKRn",
        "outputId": "61f03170-4e57-46a7-8a04-d9c76ce43c5d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 86.6\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.93      0.89       530\n",
            "      becquer       0.88      0.77      0.82       370\n",
            "martin_fierro       0.86      0.90      0.88        71\n",
            "\n",
            "     accuracy                           0.87       971\n",
            "    macro avg       0.87      0.87      0.87       971\n",
            " weighted avg       0.87      0.87      0.87       971\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Sentence Transformers + SMOTE + MLP Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "_Vg8ghSlIHo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval Modelo\n",
        "test_features = featurize_model_7(corpus_sentences_test, model_vectorize)\n",
        "prediction = model_7.predict(test_features) # Se predicen los autores de cada texto (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score macro: \" + str(round(f1_score(corpus_authors_test, prediction, average='macro')*100, 2)))\n",
        "print(classification_report(corpus_authors_test, prediction, target_names=['quiroga','becquer','martin_fierro']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhggAi27IHzj",
        "outputId": "9e5e7ba1-659b-43ad-fb2d-3279279afded"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score macro: 83.73\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      quiroga       0.86      0.89      0.88       530\n",
            "      becquer       0.85      0.77      0.81       370\n",
            "martin_fierro       0.74      0.93      0.82        71\n",
            "\n",
            "     accuracy                           0.85       971\n",
            "    macro avg       0.82      0.86      0.84       971\n",
            " weighted avg       0.85      0.85      0.85       971\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}